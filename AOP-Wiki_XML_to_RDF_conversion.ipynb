{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>AOP-Wiki XML conversion to RDF</b>\n",
    "Author: Marvin Martens\n",
    "\n",
    "The [AOP-Wiki](https://aopwiki.org/) is the central repository for qualitative descriptions of AOPs, and releases its database every three months in XML format. This Jupyter notebook makes the conversion of the AOP-Wiki XML into RDF with Turtle (ttl) syntax. \n",
    "\n",
    "It downloads and parses the AOP-Wiki XML file with the ElementTree XML API Python library, and stores all its components in nested dictionaries for the all subjects which form the basis of the existing AOP-Wiki, being the AOPs, KEs,  KERs,  stressors,  chemicals,  taxonomy,  cell-terms,  organ-terms,  and  the  KE  components, which comprise of Biological Processes (BPs),  Biological Objects (BOs) and Biological Actions (BAs).  During the filling of those dictionaries, semantic annotations are being added for  the  subjects,  the  relationship  (predicate)  to  their  property  (object),  and  for  the  properties themselves when meant to represent an identifier or ontology term.\n",
    "\n",
    "<img src=\"Overview AOP-Wiki RDF.svg\" style=\"width: 650px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #1: imports</b>\n",
    "First, all required Python libraries are imported. It will `pip install` libraries if the imports are not found on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Library Imports ---\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import stat\n",
    "import gzip\n",
    "import shutil\n",
    "import datetime\n",
    "from xml.etree.ElementTree import parse\n",
    "import urllib.request\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# --- Constants / Compiled Patterns ---\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the mapping of identifiers for chemicals and genes. To make this possible, the URL to the BridgeDb service should be defined in the `bridgedb` variable, and include the `/Human/`. The quickest way to execute the code is by using a local BridgeDb service launched with the BridgeDb Docker image using the [instructions](https://github.com/bridgedb/docker). Alternatively, the live web version can be used by defining the `bridgedb` variable as 'https://webservice.bridgedb.org/Human/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridgedb = 'https://webservice.bridgedb.org/Human/' #'http://localhost:8183/Human/'#'https://webservice.bridgedb.org/Human/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #2: Getting the AOP-Wiki XML</b>\n",
    "Next, the last version of the AOP-Wiki XML is defined in the `aopwikixmlfilename` variable, which can be found in the [download page of the AOP-Wiki](https://aopwiki.org/downloads/). This file is downloaded, unzipped, and opened, after which the ElementTree XML API parses it, making it ready for extracting its contents from the `root`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-05-05\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aopwiki.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "aopwikixmlfilename = 'aop-wiki-xml-'+str(today)\n",
    "response = requests.get('https://aopwiki.org/downloads/aop-wiki-xml.gz', verify=False)\n",
    "with open(aopwikixmlfilename, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XML will be extracted to the folder defined within the variable `filepath` in the next block of code, which is by defailt `/data` relative to the location of the Jupyter notebook. All datafiles used and produced with this notebook will be placed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/aop-wiki-xml-2025-05-05 opened\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with gzip.open(aopwikixmlfilename, 'rb') as f_in:\n",
    "        with open(filepath+aopwikixmlfilename, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            print('File ' + filepath+aopwikixmlfilename + ' opened')\n",
    "except:\n",
    "    print('Check if the filepath is correct:\\n' + filepath+aopwikixmlfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AOP-Wiki XML is parsed correctly, and contains 6580 entities\n"
     ]
    }
   ],
   "source": [
    "tree = parse(filepath + aopwikixmlfilename)\n",
    "root = tree.getroot()\n",
    "print('The AOP-Wiki XML is parsed correctly, and contains ' + str(len(root)) + ' entities')\n",
    "\n",
    "aopxml = '{http://www.aopkb.org/aop-xml}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #3: extracting information from the XML</b>\n",
    "The next section extracts all information from the main 11 AOP-Wiki entities shown in Figure 1. These are stored in nested dictionaries, while using ontological annotations as keys for semantic mapping of the information. Note that the cell-terms and organ-terms are included in the KE block of code.\n",
    "\n",
    "First, all reference identifiers for AOPs, KEs, KERs and stressors need to be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The AOP-Wiki XML contains 522 identifiers for the entity AOP\n",
      "\n",
      "The AOP-Wiki XML contains 1493 identifiers for the entity KE\n",
      "\n",
      "The AOP-Wiki XML contains 2125 identifiers for the entity KER\n",
      "\n",
      "The AOP-Wiki XML contains 721 identifiers for the entity Stressor\n"
     ]
    }
   ],
   "source": [
    "refs = {'AOP': {}, 'KE': {}, 'KER': {}, 'Stressor': {}}\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'aop-reference'):\n",
    "    refs['AOP'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'key-event-reference'):\n",
    "    refs['KE'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'key-event-relationship-reference'):\n",
    "    refs['KER'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'stressor-reference'):\n",
    "    refs['Stressor'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for item in refs:\n",
    "    print('\\nThe AOP-Wiki XML contains ' + str(len(refs[item])) + ' identifiers for the entity ' + item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adverse Outcome Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 522 Adverse Outcome Pathways have been parsed.\n"
     ]
    }
   ],
   "source": [
    "aopdict = {}\n",
    "kedict = {}\n",
    "for AOP in root.findall(aopxml + 'aop'):\n",
    "    aopdict[AOP.get('id')] = {}\n",
    "    aopdict[AOP.get('id')]['dc:identifier'] = 'aop:' + refs['AOP'][AOP.get('id')]\n",
    "    aopdict[AOP.get('id')]['rdfs:label'] = '\"AOP ' + refs['AOP'][AOP.get('id')] + '\"'\n",
    "    aopdict[AOP.get('id')]['foaf:page'] = '<https://identifiers.org/aop/' + refs['AOP'][AOP.get('id')] + '>'\n",
    "    aopdict[AOP.get('id')]['dc:title'] = '\"' + AOP.find(aopxml + 'title').text + '\"'\n",
    "    aopdict[AOP.get('id')]['dcterms:alternative'] = AOP.find(aopxml + 'short-name').text\n",
    "    aopdict[AOP.get('id')]['dc:description'] = []\n",
    "    if AOP.find(aopxml + 'background') is not None:\n",
    "        aopdict[AOP.get('id')]['dc:description'].append('\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'background').text) + '\"\"\"')\n",
    "    if AOP.find(aopxml + 'authors').text is not None:\n",
    "        aopdict[AOP.get('id')]['dc:creator'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'authors').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'abstract').text is not None:\n",
    "        aopdict[AOP.get('id')]['dcterms:abstract'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'abstract').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'status').find(aopxml + 'wiki-status') is not None:\n",
    "        aopdict[AOP.get('id')]['dcterms:accessRights'] = '\"' + AOP.find(aopxml + 'status').find(aopxml + 'wiki-status').text + '\"' \n",
    "    if AOP.find(aopxml + 'status').find(aopxml + 'oecd-status') is not None:\n",
    "        aopdict[AOP.get('id')]['oecd-status'] =  '\"' + AOP.find(aopxml + 'status').find(aopxml + 'oecd-status').text + '\"' \n",
    "    if AOP.find(aopxml + 'status').find(aopxml + 'saaop-status') is not None:\n",
    "        aopdict[AOP.get('id')]['saaop-status'] =  '\"' + AOP.find(aopxml + 'status').find(aopxml + 'saaop-status').text + '\"' \n",
    "    aopdict[AOP.get('id')]['oecd-project'] = AOP.find(aopxml + 'oecd-project').text\n",
    "    aopdict[AOP.get('id')]['dc:source'] = AOP.find(aopxml + 'source').text\n",
    "    aopdict[AOP.get('id')]['dcterms:created'] = AOP.find(aopxml + 'creation-timestamp').text\n",
    "    aopdict[AOP.get('id')]['dcterms:modified'] = AOP.find(aopxml + 'last-modification-timestamp').text\n",
    "    for appl in AOP.findall(aopxml + 'applicability'):\n",
    "        for sex in appl.findall(aopxml + 'sex'):\n",
    "            if 'pato:0000047' not in aopdict[AOP.get('id')]:\n",
    "                aopdict[AOP.get('id')]['pato:0000047'] = [[sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text]]\n",
    "            else:\n",
    "                aopdict[AOP.get('id')]['pato:0000047'].append([sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text])\n",
    "        for life in appl.findall(aopxml + 'life-stage'):\n",
    "            if 'aopo:LifeStageContext' not in aopdict[AOP.get('id')]:\n",
    "                aopdict[AOP.get('id')]['aopo:LifeStageContext'] = [[life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text]]\n",
    "            else:\n",
    "                aopdict[AOP.get('id')]['aopo:LifeStageContext'].append([life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text])\n",
    "    aopdict[AOP.get('id')]['aopo:has_key_event'] = {}\n",
    "    if AOP.find(aopxml + 'key-events') is not None:\n",
    "        for KE in AOP.find(aopxml + 'key-events').findall(aopxml + 'key-event'):\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event'][KE.get('key-event-id')] = {}\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event'][KE.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][KE.get('key-event-id')]\n",
    "    aopdict[AOP.get('id')]['aopo:has_key_event_relationship'] = {}\n",
    "    if AOP.find(aopxml + 'key-event-relationships') is not None:\n",
    "        for KER in AOP.find(aopxml + 'key-event-relationships').findall(aopxml + 'relationship'):\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')] = {}\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['dc:identifier'] = 'aop.relationships:' + refs['KER'][KER.get('id')]\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['adjacency'] = KER.find(aopxml + 'adjacency').text\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['quantitative-understanding-value'] = KER.find(aopxml + 'quantitative-understanding-value').text\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['aopo:has_evidence'] = KER.find(aopxml + 'evidence').text\n",
    "    aopdict[AOP.get('id')]['aopo:has_molecular_initiating_event'] = {}\n",
    "    for MIE in AOP.findall(aopxml + 'molecular-initiating-event'):\n",
    "        aopdict[AOP.get('id')]['aopo:has_molecular_initiating_event'][MIE.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_molecular_initiating_event'][MIE.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][MIE.get('key-event-id')]\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][MIE.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][MIE.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][MIE.get('key-event-id')]\n",
    "        if MIE.find(aopxml + 'evidence-supporting-chemical-initiation').text is not None:\n",
    "            kedict[MIE.get('key-event-id')] = {}\n",
    "            aopdict[AOP.get('id')]['dc:description'].append('\"\"\"' + TAG_RE.sub('', MIE.find(aopxml + 'evidence-supporting-chemical-initiation').text) + '\"\"\"')\n",
    "    aopdict[AOP.get('id')]['aopo:has_adverse_outcome'] = {}\n",
    "    for AO in AOP.findall(aopxml + 'adverse-outcome'):\n",
    "        aopdict[AOP.get('id')]['aopo:has_adverse_outcome'][AO.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_adverse_outcome'][AO.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][AO.get('key-event-id')]\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][AO.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][AO.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][AO.get('key-event-id')]\n",
    "        if AO.find(aopxml + 'examples').text is not None:\n",
    "            kedict[AO.get('key-event-id')] = {}\n",
    "            aopdict[AOP.get('id')]['dc:description'].append('\"\"\"' + TAG_RE.sub('', AO.find(aopxml + 'examples').text) + '\"\"\"')\n",
    "    aopdict[AOP.get('id')]['nci:C54571'] = {}\n",
    "    if AOP.find(aopxml + 'aop-stressors') is not None:\n",
    "        for stressor in AOP.find(aopxml + 'aop-stressors').findall(aopxml + 'aop-stressor'):\n",
    "            aopdict[AOP.get('id')]['nci:C54571'][stressor.get('stressor-id')] = {}\n",
    "            aopdict[AOP.get('id')]['nci:C54571'][stressor.get('stressor-id')]['dc:identifier'] = 'aop.stressor:' + refs['Stressor'][stressor.get('stressor-id')]\n",
    "            aopdict[AOP.get('id')]['nci:C54571'][stressor.get('stressor-id')]['aopo:has_evidence'] = stressor.find(aopxml + 'evidence').text\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'description').text is not None:\n",
    "        aopdict[AOP.get('id')]['nci:C25217'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'description').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'key-event-essentiality-summary').text is not None:\n",
    "        aopdict[AOP.get('id')]['nci:C48192'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'key-event-essentiality-summary').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'applicability').text is not None:\n",
    "        aopdict[AOP.get('id')]['aopo:AopContext'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'applicability').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'weight-of-evidence-summary').text is not None:\n",
    "        aopdict[AOP.get('id')]['aopo:has_evidence'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'weight-of-evidence-summary').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'quantitative-considerations').text is not None:\n",
    "        aopdict[AOP.get('id')]['edam:operation_3799'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'quantitative-considerations').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'potential-applications').text is not None:\n",
    "        aopdict[AOP.get('id')]['nci:C25725'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'potential-applications').text) + '\"\"\"'\n",
    "print('Done!\\n\\nA total of ' + str(len(aopdict)) + ' Adverse Outcome Pathways have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemicals\n",
    "For the chemicals in the AOP-Wiki, we added BridgeDb mappings for increased coverage of chemical databases for which we used the already present CAS identifers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 410 chemicals have been parsed.\n"
     ]
    }
   ],
   "source": [
    "chedict = {}\n",
    "listofchebi = []\n",
    "listofchemspider = []\n",
    "listofwikidata = []\n",
    "listofchembl = []\n",
    "listofdrugbank = []\n",
    "listofpubchem = []\n",
    "listoflipidmaps = []\n",
    "listofhmdb = []\n",
    "listofkegg = []\n",
    "listofcas = []\n",
    "listofinchikey = []\n",
    "listofcomptox = []\n",
    "\n",
    "for che in root.findall(aopxml + 'chemical'):\n",
    "    chedict[che.get('id')] = {}\n",
    "    if che.find(aopxml + 'casrn') is not None:\n",
    "        if 'NOCAS' not in che.find(aopxml + 'casrn').text:  # all NOCAS ids are taken out, so no issues as subjects\n",
    "            chedict[che.get('id')]['dc:identifier'] = 'cas:' + che.find(aopxml + 'casrn').text\n",
    "            listofcas.append('cas:' + che.find(aopxml + 'casrn').text)\n",
    "            chedict[che.get('id')]['cheminf:000446'] = '\"' + che.find(aopxml + 'casrn').text + '\"'\n",
    "            a = requests.get(bridgedb+'xrefs/Ca/'+che.find(aopxml + 'casrn').text).text.split('\\n')\n",
    "            dictionaryforchemical = {}\n",
    "            if 'html' not in a:\n",
    "                for item in a:\n",
    "                    b = item.split('\\t')\n",
    "                    if len(b) == 2:\n",
    "                        if b[1] not in dictionaryforchemical:\n",
    "                            dictionaryforchemical[b[1]] = []\n",
    "                            dictionaryforchemical[b[1]].append(b[0])\n",
    "                        else:\n",
    "                            dictionaryforchemical[b[1]].append(b[0])\n",
    "            if 'ChEBI' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000407'] = []\n",
    "                for chebi in dictionaryforchemical['ChEBI']:\n",
    "                    # Remove \"CHEBI:\" prefix if it exists\n",
    "                    formatted_chebi = \"chebi:\" + chebi.split(\"CHEBI:\")[-1]\n",
    "                    if formatted_chebi not in listofchebi:\n",
    "                        listofchebi.append(formatted_chebi)\n",
    "                    if formatted_chebi not in chedict[che.get('id')]['cheminf:000407']:\n",
    "                        chedict[che.get('id')]['cheminf:000407'].append(formatted_chebi)\n",
    "            if 'Chemspider' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000405'] = []\n",
    "                for chemspider in dictionaryforchemical['Chemspider']:\n",
    "                    if \"chemspider:\"+chemspider not in listofchemspider:\n",
    "                        listofchemspider.append(\"chemspider:\"+chemspider)\n",
    "                    chedict[che.get('id')]['cheminf:000405'].append(\"chemspider:\"+chemspider)\n",
    "            if 'Wikidata' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000567'] = []\n",
    "                for wd in dictionaryforchemical['Wikidata']:\n",
    "                    if \"wikidata:\"+wd not in listofwikidata:\n",
    "                        listofwikidata.append(\"wikidata:\"+wd)\n",
    "                    chedict[che.get('id')]['cheminf:000567'].append(\"wikidata:\"+wd)\n",
    "            if 'ChEMBL compound' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000412'] = []\n",
    "                for chembl in dictionaryforchemical['ChEMBL compound']:\n",
    "                    if \"chembl.compound:\"+chembl not in listofchembl:\n",
    "                        listofchembl.append(\"chembl.compound:\"+chembl)\n",
    "                    chedict[che.get('id')]['cheminf:000412'].append(\"chembl.compound:\"+chembl)\n",
    "            if 'PubChem-compound' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000140'] = []\n",
    "                for pub in dictionaryforchemical['PubChem-compound']:\n",
    "                    if \"pubchem.compound:\"+pub not in listofpubchem:\n",
    "                        listofpubchem.append(\"pubchem.compound:\"+pub)\n",
    "                    chedict[che.get('id')]['cheminf:000140'].append(\"pubchem.compound:\"+pub)\n",
    "            if 'DrugBank' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000406'] = []\n",
    "                for drugbank in dictionaryforchemical['DrugBank']:\n",
    "                    if \"drugbank:\"+drugbank not in listofdrugbank:\n",
    "                        listofdrugbank.append(\"drugbank:\"+drugbank)\n",
    "                    chedict[che.get('id')]['cheminf:000406'].append(\"drugbank:\"+drugbank)\n",
    "            if 'KEGG Compound' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000409'] = []\n",
    "                for kegg in dictionaryforchemical['KEGG Compound']:\n",
    "                    if \"kegg.compound:\"+kegg not in listofkegg:\n",
    "                        listofkegg.append(\"kegg.compound:\"+kegg)\n",
    "                    chedict[che.get('id')]['cheminf:000409'].append(\"kegg.compound:\"+kegg)\n",
    "            if 'LIPID MAPS' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000564'] = []\n",
    "                for lipidmaps in dictionaryforchemical['LIPID MAPS']:\n",
    "                    if \"lipidmaps:\"+lipidmaps not in listoflipidmaps:\n",
    "                        listoflipidmaps.append(\"lipidmaps:\"+lipidmaps)\n",
    "                    chedict[che.get('id')]['cheminf:000564'].append(\"lipidmaps:\"+lipidmaps)\n",
    "            if 'HMDB' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000408'] = []\n",
    "                for hmdb in dictionaryforchemical['HMDB']:\n",
    "                    if \"hmdb:\"+hmdb not in listofhmdb:\n",
    "                        listofhmdb.append(\"hmdb:\"+hmdb)\n",
    "                    chedict[che.get('id')]['cheminf:000408'].append(\"hmdb:\"+hmdb)\n",
    "        else:\n",
    "            chedict[che.get('id')]['dc:identifier'] = '\"' + che.find(aopxml + 'casrn').text + '\"'\n",
    "    if che.find(aopxml + 'jchem-inchi-key') is not None:\n",
    "        chedict[che.get('id')]['cheminf:000059'] = 'inchikey:' + str(che.find(aopxml + 'jchem-inchi-key').text)\n",
    "        listofinchikey.append('inchikey:' + str(che.find(aopxml + 'jchem-inchi-key').text))\n",
    "    if che.find(aopxml + 'preferred-name') is not None:\n",
    "        chedict[che.get('id')]['dc:title'] = '\"' + che.find(aopxml + 'preferred-name').text + '\"'\n",
    "    if che.find(aopxml + 'dsstox-id') is not None:\n",
    "        chedict[che.get('id')]['cheminf:000568'] = 'comptox:' + che.find(aopxml + 'dsstox-id').text\n",
    "        listofcomptox.append('comptox:' + che.find(aopxml + 'dsstox-id').text)\n",
    "    if che.find(aopxml + 'synonyms') is not None:\n",
    "        chedict[che.get('id')]['dcterms:alternative'] = []\n",
    "        for synonym in che.find(aopxml + 'synonyms').findall(aopxml + 'synonym'):\n",
    "            chedict[che.get('id')]['dcterms:alternative'].append(synonym.text[:-1])\n",
    "print('Done!\\n\\nA total of ' + str(len(chedict)) + ' chemicals have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 721 Stressors have been parsed.\n"
     ]
    }
   ],
   "source": [
    "strdict = {}\n",
    "for stressor in root.findall(aopxml + 'stressor'):\n",
    "    strdict[stressor.get('id')] = {}\n",
    "    strdict[stressor.get('id')]['dc:identifier'] = 'aop.stressor:' + refs['Stressor'][stressor.get('id')]\n",
    "    strdict[stressor.get('id')]['rdfs:label'] = '\"Stressor ' + refs['Stressor'][stressor.get('id')] + '\"'\n",
    "    strdict[stressor.get('id')]['foaf:page'] = '<https://identifiers.org/aop.stressor/' + refs['Stressor'][stressor.get('id')] + '>'\n",
    "    strdict[stressor.get('id')]['dc:title'] = '\"' + stressor.find(aopxml + 'name').text + '\"'\n",
    "    if stressor.find(aopxml + 'description').text is not None:\n",
    "        strdict[stressor.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', stressor.find(aopxml + 'description').text) + '\"\"\"'\n",
    "    strdict[stressor.get('id')]['dcterms:created'] = stressor.find(aopxml + 'creation-timestamp').text\n",
    "    strdict[stressor.get('id')]['dcterms:modified'] = stressor.find(aopxml + 'last-modification-timestamp').text\n",
    "    strdict[stressor.get('id')]['aopo:has_chemical_entity'] = []\n",
    "    strdict[stressor.get('id')]['linktochemical'] = []\n",
    "    if stressor.find(aopxml + 'chemicals') is not None:\n",
    "        for chemical in stressor.find(aopxml + 'chemicals').findall(aopxml + 'chemical-initiator'):\n",
    "            strdict[stressor.get('id')]['aopo:has_chemical_entity'].append('\"' + chemical.get('user-term') + '\"')\n",
    "            strdict[stressor.get('id')]['linktochemical'].append(chemical.get('chemical-id'))\n",
    "print('Done!\\n\\nA total of ' + str(len(strdict)) + ' Stressors have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 282 taxonomies have been parsed.\n"
     ]
    }
   ],
   "source": [
    "taxdict = {}\n",
    "for tax in root.findall(aopxml + 'taxonomy'):\n",
    "    taxdict[tax.get('id')] = {}\n",
    "    taxdict[tax.get('id')]['dc:source'] = tax.find(aopxml + 'source').text\n",
    "    taxdict[tax.get('id')]['dc:title'] = tax.find(aopxml + 'name').text\n",
    "    if taxdict[tax.get('id')]['dc:source'] == 'NCBI':\n",
    "        taxdict[tax.get('id')]['dc:identifier'] = 'ncbitaxon:' + tax.find(aopxml + 'source-id').text\n",
    "    elif taxdict[tax.get('id')]['dc:source'] is not None:\n",
    "        taxdict[tax.get('id')]['dc:identifier'] = '\"' + tax.find(aopxml + 'source-id').text + '\"'\n",
    "    else:\n",
    "        taxdict[tax.get('id')]['dc:identifier'] = '\"' + tax.find(aopxml + 'source-id').text + '\"'\n",
    "print('Done!\\n\\nA total of ' + str(len(taxdict)) + ' taxonomies have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Event Components\n",
    "Which comprise of the Biological Actions, Biological Processes, Biological Objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "A total of 12 Biological Activity annotations have been parsed.\n"
     ]
    }
   ],
   "source": [
    "bioactdict = {None: {}}\n",
    "bioactdict[None]['dc:identifier'] = None\n",
    "bioactdict[None]['dc:source'] = None\n",
    "bioactdict[None]['dc:title'] = None\n",
    "for bioact in root.findall(aopxml + 'biological-action'):\n",
    "    bioactdict[bioact.get('id')] = {}\n",
    "    bioactdict[bioact.get('id')]['dc:source'] = '\"' + bioact.find(aopxml + 'source').text + '\"'\n",
    "    bioactdict[bioact.get('id')]['dc:title'] = '\"' + bioact.find(aopxml + 'name').text + '\"'\n",
    "    bioactdict[bioact.get('id')]['dc:identifier'] = '\"WIKI:' + bioact.find(aopxml + 'source-id').text + '\"'\n",
    "print('Done!\\nA total of ' + str(len(bioactdict)) + ' Biological Activity annotations have been parsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 536 Biological Process annotations have been parsed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize bioprodict with default values\n",
    "bioprodict = {\n",
    "    None: {\n",
    "        'dc:identifier': None,\n",
    "        'dc:source': None,\n",
    "        'dc:title': None\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mapping of source prefixes to their respective formats\n",
    "source_prefix_map = {\n",
    "    '\"GO\"': ('go:', 3),\n",
    "    '\"MI\"': ('mi:', 0),\n",
    "    '\"MP\"': ('mp:', 3),\n",
    "    '\"MESH\"': ('mesh:', 0),\n",
    "    '\"HP\"': ('hp:', 3),\n",
    "    '\"PCO\"': ('pco:', 4),\n",
    "    '\"NBO\"': ('nbo:', 4),\n",
    "    '\"VT\"': ('vt:', 3),\n",
    "    '\"RBO\"': ('rbo:', 4),\n",
    "    '\"NCI\"': ('nci:', 4),\n",
    "    '\"IDO\"': ('ido:', 4),\n",
    "}\n",
    "\n",
    "# Loop through biological processes and populate bioprodict\n",
    "for biopro in root.findall(aopxml + 'biological-process'):\n",
    "    biopro_id = biopro.get('id')\n",
    "    bioprodict[biopro_id] = {}\n",
    "\n",
    "    # Extract values\n",
    "    source = f'\"{biopro.find(aopxml + \"source\").text}\"'\n",
    "    name = f'\"{biopro.find(aopxml + \"name\").text}\"'\n",
    "    source_id = biopro.find(aopxml + 'source-id').text\n",
    "\n",
    "    # Populate source and title\n",
    "    bioprodict[biopro_id]['dc:source'] = source\n",
    "    bioprodict[biopro_id]['dc:title'] = name\n",
    "\n",
    "    # Handle identifier based on source prefix\n",
    "    if source in source_prefix_map:\n",
    "        prefix, offset = source_prefix_map[source]\n",
    "        identifier = prefix + source_id[offset:]\n",
    "        bioprodict[biopro_id]['dc:identifier'] = identifier\n",
    "    else:\n",
    "        # Default case for unhandled sources\n",
    "        bioprodict[biopro_id]['dc:identifier'] = source_id\n",
    "\n",
    "print(f\"Done!\\n\\nA total of {len(bioprodict)} Biological Process annotations have been parsed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 481 Biological Object annotations have been parsed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize bioobjdict with default values\n",
    "bioobjdict = {\n",
    "    None: {\n",
    "        'dc:identifier': None,\n",
    "        'dc:source': None,\n",
    "        'dc:title': None\n",
    "    }\n",
    "}\n",
    "objectstoskip = []\n",
    "prolist = []\n",
    "\n",
    "# Mapping of source prefixes to their respective formats\n",
    "source_prefix_map = {\n",
    "    '\"PR\"': ('pr:', 3),\n",
    "    '\"CL\"': ('cl:', 3),\n",
    "    '\"MESH\"': ('mesh:', 0),\n",
    "    '\"GO\"': ('go:', 3),\n",
    "    '\"UBERON\"': ('uberon:', 7),\n",
    "    '\"CHEBI\"': ('chebio:', 6),\n",
    "    '\"MP\"': ('mp:', 3),\n",
    "    '\"FMA\"': ('fma:', 4),\n",
    "    '\"PCO\"': ('pco:', 4),\n",
    "}\n",
    "\n",
    "# Loop through biological objects and populate bioobjdict\n",
    "for bioobj in root.findall(aopxml + 'biological-object'):\n",
    "    bioobj_id = bioobj.get('id')\n",
    "    bioobjdict[bioobj_id] = {}\n",
    "\n",
    "    # Extract values\n",
    "    source = f'\"{bioobj.find(aopxml + \"source\").text}\"'\n",
    "    name = f'\"{bioobj.find(aopxml + \"name\").text}\"'\n",
    "    source_id = bioobj.find(aopxml + 'source-id').text\n",
    "\n",
    "    # Populate source and title\n",
    "    bioobjdict[bioobj_id]['dc:source'] = source\n",
    "    bioobjdict[bioobj_id]['dc:title'] = name\n",
    "\n",
    "    # Handle identifier based on source prefix\n",
    "    if source in source_prefix_map:\n",
    "        prefix, offset = source_prefix_map[source]\n",
    "        identifier = prefix + source_id[offset:]\n",
    "        bioobjdict[bioobj_id]['dc:identifier'] = identifier\n",
    "\n",
    "        # Add to prolist if PR\n",
    "        if source == '\"PR\"':\n",
    "            prolist.append(identifier)\n",
    "    else:\n",
    "        # Default case for unhandled sources\n",
    "        bioobjdict[bioobj_id]['dc:identifier'] = f'\"{source_id}\"'\n",
    "\n",
    "print(f\"Done!\\n\\nA total of {len(bioobjdict)} Biological Object annotations have been parsed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Biological Objects containing terms from the Protein Ontology are mapped to protein identifiers with the PR mapping file `promapping.txt`, which was downloaded from the [Protein Consortium website](https://proconsortium.org/download/current/), which provides matching identifiers from Entrez Gene, HGNC and UniProt. The file location should be the `filepath` variable defined in Step #2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/promapping.txt', <http.client.HTTPMessage at 0x7f10e2433530>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro = \"promapping.txt\"\n",
    "urllib.request.urlretrieve('https://proconsortium.org/download/current/promapping.txt', 'data/promapping.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Modified Time :  Mon May  5 22:47:33 2025\n"
     ]
    }
   ],
   "source": [
    "fileStatsObj = os.stat (filepath + pro)\n",
    "PromodificationTime = time.ctime ( fileStatsObj [ stat.ST_MTIME ] )\n",
    "print(\"Last Modified Time : \", PromodificationTime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This step added 718 identifiers for 151 Protein Ontology terms\n"
     ]
    }
   ],
   "source": [
    "f = open(filepath+pro, \"r\")\n",
    "prodict = {}\n",
    "hgnclist = []\n",
    "uniprotlist = []\n",
    "ncbigenelist = []\n",
    "for line in f:\n",
    "    a = line.split('\\t')\n",
    "    key = 'pr:'+a[0][3:]\n",
    "    if key in prolist:\n",
    "        if not key in prodict:\n",
    "            prodict[key] = []\n",
    "        if 'HGNC:' in a[1]:\n",
    "            prodict[key].append('hgnc:'+a[1][5:])\n",
    "            hgnclist.append('hgnc:'+a[1][5:])\n",
    "        if 'NCBIGene:' in a[1]:\n",
    "            prodict[key].append('ncbigene:'+a[1][9:])\n",
    "            ncbigenelist.append('ncbigene:'+a[1][9:])\n",
    "        if 'UniProtKB:' in a[1]:\n",
    "            prodict[key].append('uniprot:'+a[1].split(',')[0][10:])\n",
    "            uniprotlist.append('uniprot:'+a[1].split(',')[0][10:])\n",
    "        if prodict[key]==[]:\n",
    "            del prodict[key]\n",
    "f.close()\n",
    "print('This step added ' + str(len(hgnclist)+len(ncbigenelist)+len(uniprotlist)) + ' identifiers for ' + str(len(prodict)) + ' Protein Ontology terms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Events\n",
    "The KEs also include the entities for cell-terms and organ-terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 1493 Key Events have been parsed.\n"
     ]
    }
   ],
   "source": [
    "listofkedescriptions = []\n",
    "for ke in root.findall(aopxml + 'key-event'):\n",
    "    if not ke.get('id') in kedict:\n",
    "        kedict[ke.get('id')] = {}\n",
    "    kedict[ke.get('id')]['dc:identifier'] = 'aop.events:' + refs['KE'][ke.get('id')]\n",
    "    kedict[ke.get('id')]['rdfs:label'] = '\"KE ' + refs['KE'][ke.get('id')] + '\"'\n",
    "    kedict[ke.get('id')]['foaf:page'] = '<https://identifiers.org/aop.events/' + refs['KE'][ke.get('id')] + '>'\n",
    "    kedict[ke.get('id')]['dc:title'] = '\"' + ke.find(aopxml + 'title').text + '\"'\n",
    "    kedict[ke.get('id')]['dcterms:alternative'] = ke.find(aopxml + 'short-name').text\n",
    "    kedict[ke.get('id')]['nci:C25664'] = '\"\"\"' + ke.find(aopxml + 'biological-organization-level').text + '\"\"\"'\n",
    "    if ke.find(aopxml + 'description').text is not None:\n",
    "        kedict[ke.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', ke.find(aopxml + 'description').text) + '\"\"\"'\n",
    "#    if ke.find(aopxml + 'evidence-supporting-taxonomic-applicability').text is not None:\n",
    "#        kedict[ke.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', ke.find(aopxml + 'evidence-supporting-taxonomic-applicability').text) + '\"\"\"'\n",
    "    if ke.find(aopxml + 'measurement-methodology').text is not None:\n",
    "        kedict[ke.get('id')]['mmo:0000000'] = '\"\"\"' + TAG_RE.sub('', ke.find(aopxml + 'measurement-methodology').text) + '\"\"\"'\n",
    "    kedict[ke.get('id')]['biological-organization-level'] = ke.find(aopxml + 'biological-organization-level').text\n",
    "    kedict[ke.get('id')]['dc:source'] = ke.find(aopxml + 'source').text\n",
    "    for appl in ke.findall(aopxml + 'applicability'):\n",
    "        for sex in appl.findall(aopxml + 'sex'):\n",
    "            if 'pato:0000047' not in kedict[ke.get('id')]:\n",
    "                kedict[ke.get('id')]['pato:0000047'] = [[sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text]]\n",
    "            else:\n",
    "                kedict[ke.get('id')]['pato:0000047'].append([sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text])\n",
    "        for life in appl.findall(aopxml + 'life-stage'):\n",
    "            if 'aopo:LifeStageContext' not in kedict[ke.get('id')]:\n",
    "                kedict[ke.get('id')]['aopo:LifeStageContext'] = [[life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text]]\n",
    "            else:\n",
    "                kedict[ke.get('id')]['aopo:LifeStageContext'].append([life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text])\n",
    "        for tax in appl.findall(aopxml + 'taxonomy'):\n",
    "            if 'ncbitaxon:131567' not in kedict[ke.get('id')]:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kedict[ke.get('id')]['ncbitaxon:131567'] = [[tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']]]\n",
    "            else:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kedict[ke.get('id')]['ncbitaxon:131567'].append([tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']])\n",
    "    kedict[ke.get('id')]['biological-events'] = []\n",
    "    kedict[ke.get('id')]['biological-event'] = {}\n",
    "    kedict[ke.get('id')]['biological-event']['go:0008150'] = []\n",
    "    kedict[ke.get('id')]['biological-event']['pato:0001241'] = []\n",
    "    kedict[ke.get('id')]['biological-event']['pato:0000001'] = []\n",
    "    bioevents = ke.find(aopxml + 'biological-events')\n",
    "    if bioevents is not None:\n",
    "        for event in bioevents.findall(aopxml + 'biological-event'):\n",
    "            event_entry = {}\n",
    "            if event.get('process-id') is not None:\n",
    "                event_entry['process'] = bioprodict[event.get('process-id')]['dc:identifier']\n",
    "                kedict[ke.get('id')]['biological-event']['go:0008150'].append(bioprodict[event.get('process-id')]['dc:identifier'])\n",
    "            if event.get('object-id') is not None:\n",
    "                event_entry['object'] = bioobjdict[event.get('object-id')]['dc:identifier']\n",
    "                kedict[ke.get('id')]['biological-event']['pato:0001241'].append(bioobjdict[event.get('object-id')]['dc:identifier'])\n",
    "            if event.get('action-id') is not None:\n",
    "                event_entry['action'] = bioactdict[event.get('action-id')]['dc:identifier']\n",
    "                kedict[ke.get('id')]['biological-event']['pato:0000001'].append(bioactdict[event.get('action-id')]['dc:identifier'])\n",
    "            kedict[ke.get('id')]['biological-events'].append(event_entry)\n",
    "    if ke.find(aopxml + 'cell-term') is not None:\n",
    "        kedict[ke.get('id')]['aopo:CellTypeContext'] = {}\n",
    "        kedict[ke.get('id')]['aopo:CellTypeContext']['dc:source'] = '\"' + ke.find(aopxml + 'cell-term').find(aopxml + 'source').text + '\"'\n",
    "        kedict[ke.get('id')]['aopo:CellTypeContext']['dc:title'] = '\"' + ke.find(aopxml + 'cell-term').find(aopxml + 'name').text + '\"'\n",
    "        if kedict[ke.get('id')]['aopo:CellTypeContext']['dc:source'] == '\"CL\"':\n",
    "            kedict[ke.get('id')]['aopo:CellTypeContext']['dc:identifier'] = ['cl:' + ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text[3:], ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text]\n",
    "        elif kedict[ke.get('id')]['aopo:CellTypeContext']['dc:source'] == '\"UBERON\"':\n",
    "            kedict[ke.get('id')]['aopo:CellTypeContext']['dc:identifier'] = ['uberon:' + ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text[7:], ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text]\n",
    "        else:\n",
    "            kedict[ke.get('id')]['aopo:CellTypeContext']['dc:identifier'] = ['\"' + ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text + '\"', 'placeholder']\n",
    "    if ke.find(aopxml + 'organ-term') is not None:\n",
    "        kedict[ke.get('id')]['aopo:OrganContext'] = {}\n",
    "        kedict[ke.get('id')]['aopo:OrganContext']['dc:source'] = '\"' + ke.find(aopxml + 'organ-term').find(aopxml + 'source').text + '\"'\n",
    "        kedict[ke.get('id')]['aopo:OrganContext']['dc:title'] = '\"' + ke.find(aopxml + 'organ-term').find(aopxml + 'name').text + '\"'\n",
    "        if kedict[ke.get('id')]['aopo:OrganContext']['dc:source'] == '\"UBERON\"':\n",
    "            kedict[ke.get('id')]['aopo:OrganContext']['dc:identifier'] = ['uberon:' + ke.find(aopxml + 'organ-term').find(aopxml + 'source-id').text[7:], ke.find(aopxml + 'organ-term').find(aopxml + 'source-id').text]\n",
    "        else:\n",
    "            kedict[ke.get('id')]['aopo:OrganContext']['dc:identifier'] = [\n",
    "                '\"' + ke.find(aopxml + 'organ-term').find(aopxml + 'source-id').text + '\"', 'placeholder']\n",
    "    if ke.find(aopxml + 'key-event-stressors') is not None:\n",
    "        kedict[ke.get('id')]['nci:C54571'] = {}\n",
    "        for stressor in ke.find(aopxml + 'key-event-stressors').findall(aopxml + 'key-event-stressor'):\n",
    "            kedict[ke.get('id')]['nci:C54571'][stressor.get('stressor-id')] = {}\n",
    "            kedict[ke.get('id')]['nci:C54571'][stressor.get('stressor-id')]['dc:identifier'] = strdict[stressor.get('stressor-id')]['dc:identifier']\n",
    "            kedict[ke.get('id')]['nci:C54571'][stressor.get('stressor-id')]['aopo:has_evidence'] = stressor.find(aopxml + 'evidence').text\n",
    "print('Done!\\n\\nA total of ' + str(len(kedict)) + ' Key Events have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Event Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 2125 Key Event Relationships have been parsed.\n"
     ]
    }
   ],
   "source": [
    "kerdict = {}\n",
    "for ker in root.findall(aopxml + 'key-event-relationship'):\n",
    "    kerdict[ker.get('id')] = {}\n",
    "    kerdict[ker.get('id')]['dc:identifier'] = 'aop.relationships:' + refs['KER'][ker.get('id')]\n",
    "    kerdict[ker.get('id')]['rdfs:label'] = '\"KER ' + refs['KER'][ker.get('id')] + '\"'\n",
    "    kerdict[ker.get('id')]['foaf:page'] = '<https://identifiers.org/aop.relationships/' + refs['KER'][ker.get('id')] + '>'\n",
    "    kerdict[ker.get('id')]['dc:source'] = ker.find(aopxml + 'source').text\n",
    "    kerdict[ker.get('id')]['dcterms:created'] = ker.find(aopxml + 'creation-timestamp').text\n",
    "    kerdict[ker.get('id')]['dcterms:modified'] = ker.find(aopxml + 'last-modification-timestamp').text\n",
    "    if ker.find(aopxml + 'description').text is not None:\n",
    "        kerdict[ker.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', ker.find(aopxml + 'description').text) + '\"\"\"'\n",
    "    for weight in ker.findall(aopxml + 'weight-of-evidence'):\n",
    "        if weight.find(aopxml + 'biological-plausibility').text is not None:\n",
    "            kerdict[ker.get('id')]['nci:C80263'] = '\"\"\"' + TAG_RE.sub('', weight.find(aopxml + 'biological-plausibility').text) + '\"\"\"'\n",
    "        if weight.find(aopxml + 'emperical-support-linkage').text is not None:\n",
    "            kerdict[ker.get('id')]['edam:data_2042'] = '\"\"\"' + TAG_RE.sub('', weight.find(aopxml + 'emperical-support-linkage').text) + '\"\"\"'\n",
    "        if weight.find(aopxml + 'uncertainties-or-inconsistencies').text is not None:\n",
    "            kerdict[ker.get('id')]['nci:C71478'] = '\"\"\"' + TAG_RE.sub('', weight.find(aopxml + 'uncertainties-or-inconsistencies').text) + '\"\"\"'\n",
    "    kerdict[ker.get('id')]['aopo:has_upstream_key_event'] = {}\n",
    "    kerdict[ker.get('id')]['aopo:has_upstream_key_event']['id'] = ker.find(aopxml + 'title').find(aopxml + 'upstream-id').text\n",
    "    kerdict[ker.get('id')]['aopo:has_upstream_key_event']['dc:identifier'] = 'aop.events:' + refs['KE'][ker.find(aopxml + 'title').find(aopxml + 'upstream-id').text]\n",
    "    kerdict[ker.get('id')]['aopo:has_downstream_key_event'] = {}\n",
    "    kerdict[ker.get('id')]['aopo:has_downstream_key_event']['id'] = ker.find(aopxml + 'title').find(aopxml + 'downstream-id').text\n",
    "    kerdict[ker.get('id')]['aopo:has_downstream_key_event']['dc:identifier'] = 'aop.events:' + refs['KE'][ker.find(aopxml + 'title').find(aopxml + 'downstream-id').text]\n",
    "    for appl in ker.findall(aopxml + 'taxonomic-applicability'):\n",
    "        for sex in appl.findall(aopxml + 'sex'):\n",
    "            if 'pato:0000047' not in kerdict[ker.get('id')]:\n",
    "                kerdict[ker.get('id')]['pato:0000047'] = [[sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text]]\n",
    "            else:\n",
    "                kerdict[ker.get('id')]['pato:0000047'].append([sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text])\n",
    "        for life in appl.findall(aopxml + 'life-stage'):\n",
    "            if 'aopo:LifeStageContext' not in kerdict[ker.get('id')]:\n",
    "                kerdict[ker.get('id')]['aopo:LifeStageContext'] = [[life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text]]\n",
    "            else:\n",
    "                kerdict[ker.get('id')]['aopo:LifeStageContext'].append([life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text])\n",
    "        for tax in appl.findall(aopxml + 'taxonomy'):\n",
    "            if 'ncbitaxon:131567' not in kerdict[ker.get('id')]:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kerdict[ker.get('id')]['ncbitaxon:131567'] = [[tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']]]\n",
    "            else:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kerdict[ker.get('id')]['ncbitaxon:131567'].append([tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']])\n",
    "print('Done!\\n\\nA total of ' + str(len(kerdict)) + ' Key Event Relationships have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #4: Writing the AOP-Wiki RDF</b>\n",
    "This step involves the writing of the central RDF file, containing all information from the AOP-Wiki XML, written in Turtle (ttl) syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open(filepath + 'AOPWikiRDF.ttl', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_multivalue_triple(file_handle, predicate, values, quote=False):\n",
    "    if not values:\n",
    "        return\n",
    "    formatted = [f'\"{v}\"' if quote else v for v in values]\n",
    "    file_handle.write(f' ;\\n\\t{predicate}\\t' + ', '.join(formatted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing prefixes\n",
    "The first thing is writing the Prefixes of all ontologies and database identifiers, which go in the top of the document. That is followed by the writing of all entities of the AOP-Wiki described in Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n",
      "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix aop: <https://identifiers.org/aop/> .\n",
      "@prefix aop.events: <https://identifiers.org/aop.events/> .\n",
      "@prefix aop.relationships: <https://identifiers.org/aop.relationships/> .\n",
      "@prefix aop.stressor: <https://identifiers.org/aop.stressor/> .\n",
      "@prefix aopo: <http://aopkb.org/aop_ontology#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix cas: <https://identifiers.org/cas/> .\n",
      "@prefix inchikey: <https://identifiers.org/inchikey/> .\n",
      "@prefix pato: <http://purl.obolibrary.org/obo/PATO_> .\n",
      "@prefix ncbitaxon: <http://purl.bioontology.org/ontology/NCBITAXON/> .\n",
      "@prefix cl: <http://purl.obolibrary.org/obo/CL_> .\n",
      "@prefix uberon: <http://purl.obolibrary.org/obo/UBERON_> .\n",
      "@prefix go: <http://purl.org/obo/owl/GO#> .\n",
      "@prefix mi: <http://purl.obolibrary.org/obo/MI_> .\n",
      "@prefix mp: <http://purl.obolibrary.org/obo/MP_> .\n",
      "@prefix mesh: <http://purl.org/commons/record/mesh/> .\n",
      "@prefix hp: <http://purl.obolibrary.org/obo/HP_> .\n",
      "@prefix pco: <http://purl.obolibrary.org/obo/PCO_> .\n",
      "@prefix nbo: <http://purl.obolibrary.org/obo/NBO_> .\n",
      "@prefix vt: <http://purl.obolibrary.org/obo/VT_> .\n",
      "@prefix pr: <http://purl.obolibrary.org/obo/PR_> .\n",
      "@prefix chebio: <http://purl.obolibrary.org/obo/CHEBI_> .\n",
      "@prefix fma: <http://purl.obolibrary.org/obo/FMA_> .\n",
      "@prefix cheminf: <http://semanticscience.org/resource/CHEMINF_> .\n",
      "@prefix nci: <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#> .\n",
      "@prefix comptox: <https://identifiers.org/comptox/> .\n",
      "@prefix mmo: <http://purl.obolibrary.org/obo/MMO_> .\n",
      "@prefix chebi: <https://identifiers.org/chebi/> .\n",
      "@prefix chemspider: <https://identifiers.org/chemspider/> .\n",
      "@prefix wikidata: <https://identifiers.org/wikidata/> .\n",
      "@prefix chembl.compound: <https://identifiers.org/chembl.compound/> .\n",
      "@prefix pubchem.compound: <https://identifiers.org/pubchem.compound/> .\n",
      "@prefix drugbank: <https://identifiers.org/drugbank/> .\n",
      "@prefix kegg.compound: <https://identifiers.org/kegg.compound/> .\n",
      "@prefix lipidmaps: <https://identifiers.org/lipidmaps/> .\n",
      "@prefix hmdb: <https://identifiers.org/hmdb/> .\n",
      "@prefix ensembl: <https://identifiers.org/ensembl/> .\n",
      "@prefix edam: <http://edamontology.org/> .\n",
      "@prefix hgnc: <https://identifiers.org/hgnc/> .\n",
      "@prefix ncbigene: <https://identifiers.org/ncbigene/> .\n",
      "@prefix uniprot: <https://identifiers.org/uniprot/> .\n",
      "@prefix rbo: <http://purl.obolibrary.org/obo/RBO_> .\n",
      "@prefix ido: <http://purl.obolibrary.org/obo/IDO_> .\n"
     ]
    }
   ],
   "source": [
    "# Load the prefixes from a CSV file\n",
    "prefixes = pd.read_csv(\"prefixes.csv\")\n",
    "\n",
    "# Format the prefixes as RDF-compatible strings\n",
    "prefix_strings = prefixes.apply(lambda row: f\"@prefix {row['prefix']}: <{row['uri']}> .\", axis=1)\n",
    "\n",
    "# Join the strings with newlines\n",
    "rdf_prefixes = \"\\n\".join(prefix_strings)\n",
    "print(rdf_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2641"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.write(rdf_prefixes + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SHACL declarations (assumes `g` is your open file object)\n",
    "g.write('\\n')  # newline after @prefixes\n",
    "for _, row in prefixes.iterrows():\n",
    "    prefix = row['prefix']\n",
    "    uri = row['uri']\n",
    "    g.write(f'[] sh:declare [ sh:prefix \"{prefix}\" ; sh:namespace \"{uri}\"^^xsd:anyURI ] .\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Adverse Outcome Pathway triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for aop in aopdict:\n",
    "    g.write(\n",
    "        aopdict[aop]['dc:identifier'] +\n",
    "        '\\n\\ta\\taopo:AdverseOutcomePathway ;' +\n",
    "        '\\n\\tdc:identifier\\t' + aopdict[aop]['dc:identifier'] +\n",
    "        ' ;\\n\\trdfs:label\\t' + aopdict[aop]['rdfs:label'] +\n",
    "        ' ;\\n\\trdfs:seeAlso\\t' + aopdict[aop]['foaf:page'] +\n",
    "        ' ;\\n\\tfoaf:page\\t' + aopdict[aop]['foaf:page'] +\n",
    "        ' ;\\n\\tdc:title\\t' + aopdict[aop]['dc:title'] +\n",
    "        ' ;\\n\\tdcterms:alternative\\t\"' + aopdict[aop]['dcterms:alternative'] + '\"' +\n",
    "        ' ;\\n\\tdc:source\\t\"' + aopdict[aop]['dc:source'] + '\"' +\n",
    "        ' ;\\n\\tdcterms:created\\t\"' + aopdict[aop]['dcterms:created'] + '\"' +\n",
    "        ' ;\\n\\tdcterms:modified\\t\"' + aopdict[aop]['dcterms:modified'] + '\"'\n",
    "    )\n",
    "\n",
    "    if 'dc:description' in aopdict[aop] and aopdict[aop]['dc:description']:\n",
    "        write_multivalue_triple(g, 'dc:description', aopdict[aop]['dc:description'], quote=False)\n",
    "\n",
    "    for predicate in [\n",
    "            'nci:C25217', 'nci:C48192', 'aopo:AopContext', 'aopo:has_evidence',\n",
    "            'edam:operation_3799', 'nci:C25725', 'dc:creator',\n",
    "            'dcterms:accessRights', 'dcterms:abstract'\n",
    "        ]:\n",
    "            if predicate in aopdict[aop]:\n",
    "                g.write(f' ;\\n\\t{predicate}\\t' + aopdict[aop][predicate])\n",
    "                \n",
    "    # OECD and SAAOP status are written as nci:C25688\n",
    "    if 'oecd-status' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tnci:C25688\\t' + aopdict[aop]['oecd-status'])\n",
    "    if 'saaop-status' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tnci:C25688\\t' + aopdict[aop]['saaop-status'])\n",
    "\n",
    "    # has_key_event\n",
    "    write_multivalue_triple(g,'aopo:has_key_event',[aopdict[aop]['aopo:has_key_event'][ke]['dc:identifier'] for ke in aopdict[aop].get('aopo:has_key_event', {})])\n",
    "\n",
    "    # has_key_event_relationship\n",
    "    write_multivalue_triple(g,'aopo:has_key_event_relationship',[aopdict[aop]['aopo:has_key_event_relationship'][ker]['dc:identifier'] for ker in aopdict[aop].get('aopo:has_key_event_relationship', {})])\n",
    "\n",
    "    # has_molecular_initiating_event\n",
    "    write_multivalue_triple(g,'aopo:has_molecular_initiating_event',[aopdict[aop]['aopo:has_molecular_initiating_event'][mie]['dc:identifier'] for mie in aopdict[aop].get('aopo:has_molecular_initiating_event', {})])\n",
    "\n",
    "    # has_adverse_outcome\n",
    "    write_multivalue_triple(g,'aopo:has_adverse_outcome',[aopdict[aop]['aopo:has_adverse_outcome'][ao]['dc:identifier'] for ao in aopdict[aop].get('aopo:has_adverse_outcome', {})])\n",
    "\n",
    "    # stressors\n",
    "    write_multivalue_triple(g,'nci:C54571',[aopdict[aop]['nci:C54571'][s]['dc:identifier'] for s in aopdict[aop].get('nci:C54571', {})])\n",
    "\n",
    "    # sex\n",
    "    if 'pato:0000047' in aopdict[aop]:\n",
    "        write_multivalue_triple(g,'pato:0000047',[sex[1] for sex in aopdict[aop]['pato:0000047']],quote=True)\n",
    "\n",
    "    # life stage\n",
    "    if 'aopo:LifeStageContext' in aopdict[aop]:\n",
    "        write_multivalue_triple(g,'aopo:LifeStageContext',[stage[1] for stage in aopdict[aop]['aopo:LifeStageContext']],quote=True)\n",
    "\n",
    "    g.write(' .\\n\\n')\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event triples\n",
    "This step also includes the extraction of the cell-terms and organ-terms, which are written to the file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cterm = {}\n",
    "oterm = {}\n",
    "bioevent_triples = []\n",
    "\n",
    "for ke in kedict:\n",
    "    g.write(\n",
    "        kedict[ke]['dc:identifier'] +\n",
    "        '\\n\\ta\\taopo:KeyEvent ;' +\n",
    "        '\\n\\tdc:identifier\\t' + kedict[ke]['dc:identifier'] +\n",
    "        ' ;\\n\\trdfs:label\\t' + kedict[ke]['rdfs:label'] +\n",
    "        ' ;\\n\\tfoaf:page\\t' + kedict[ke]['foaf:page'] +\n",
    "        ' ;\\n\\trdfs:seeAlso\\t' + kedict[ke]['foaf:page'] +\n",
    "        ' ;\\n\\tdc:title\\t' + kedict[ke]['dc:title'] +\n",
    "        ' ;\\n\\tdcterms:alternative\\t\"' + kedict[ke]['dcterms:alternative'] + '\"' +\n",
    "        ' ;\\n\\tdc:source\\t\"' + kedict[ke]['dc:source'] + '\"'\n",
    "    )\n",
    "\n",
    "    if 'dc:description' in kedict[ke]:\n",
    "        g.write(' ;\\n\\tdc:description\\t' + kedict[ke]['dc:description'])\n",
    "\n",
    "    for predicate in ['mmo:0000000', 'nci:C25664']:\n",
    "        if predicate in kedict[ke]:\n",
    "            g.write(f' ;\\n\\t{predicate}\\t' + kedict[ke][predicate])\n",
    "\n",
    "    if 'pato:0000047' in kedict[ke]:\n",
    "        write_multivalue_triple(g,'pato:0000047',[sex[1] for sex in kedict[ke]['pato:0000047']],quote=True)\n",
    "\n",
    "    if 'aopo:LifeStageContext' in kedict[ke]:\n",
    "        write_multivalue_triple(g,'aopo:LifeStageContext',[stage[1] for stage in kedict[ke]['aopo:LifeStageContext']],quote=True)\n",
    "\n",
    "    if 'ncbitaxon:131567' in kedict[ke]:\n",
    "        write_multivalue_triple(g,'ncbitaxon:131567',[tax[2] for tax in kedict[ke]['ncbitaxon:131567']])\n",
    "\n",
    "    if 'nci:C54571' in kedict[ke]:\n",
    "        write_multivalue_triple(g,'nci:C54571',[kedict[ke]['nci:C54571'][s]['dc:identifier'] for s in kedict[ke]['nci:C54571']])\n",
    "\n",
    "    if 'aopo:CellTypeContext' in kedict[ke]:\n",
    "        cell_id = kedict[ke]['aopo:CellTypeContext']['dc:identifier'][0]\n",
    "        g.write(' ;\\n\\taopo:CellTypeContext\\t' + cell_id)\n",
    "        if cell_id not in cterm:\n",
    "            cterm[cell_id] = {\n",
    "                'dc:source': kedict[ke]['aopo:CellTypeContext']['dc:source'],\n",
    "                'dc:title': kedict[ke]['aopo:CellTypeContext']['dc:title']\n",
    "            }\n",
    "\n",
    "    if 'aopo:OrganContext' in kedict[ke]:\n",
    "        organ_id = kedict[ke]['aopo:OrganContext']['dc:identifier'][0]\n",
    "        g.write(' ;\\n\\taopo:OrganContext\\t' + organ_id)\n",
    "        if organ_id not in oterm:\n",
    "            oterm[organ_id] = {\n",
    "                'dc:source': kedict[ke]['aopo:OrganContext']['dc:source'],\n",
    "                'dc:title': kedict[ke]['aopo:OrganContext']['dc:title']\n",
    "            }\n",
    "\n",
    "    if 'biological-events' in kedict[ke]:\n",
    "        bioevent_uris = []\n",
    "        for idx, be in enumerate(kedict[ke]['biological-events']):\n",
    "            be_uri = f'<{kedict[ke][\"dc:identifier\"].split(\":\")[1]}_bioevent_{idx}>'\n",
    "            bioevent_uris.append(be_uri)\n",
    "\n",
    "            triples = [f'{be_uri} a aopo:BiologicalEvent']\n",
    "            if 'process' in be:\n",
    "                triples.append(f'\\taopo:hasProcess\\t{be[\"process\"]}')\n",
    "            if 'object' in be:\n",
    "                triples.append(f'\\taopo:hasObject\\t{be[\"object\"]}')\n",
    "            if 'action' in be:\n",
    "                triples.append(f'\\taopo:hasAction\\t{be[\"action\"]}')\n",
    "            bioevent_triples.append(' ;\\n'.join(triples) + ' .\\n\\n')\n",
    "\n",
    "        write_multivalue_triple(g, 'aopo:hasBiologicalEvent', bioevent_uris)\n",
    "\n",
    "    if 'biological-event' in kedict[ke]:\n",
    "        for p in ['go:0008150', 'pato:0000001', 'pato:0001241']:\n",
    "            values = sorted(set(kedict[ke]['biological-event'].get(p, [])))\n",
    "            write_multivalue_triple(g, p, values)\n",
    "\n",
    "    # Link KE to AOP(s)\n",
    "    aop_links = [\n",
    "        aopdict[aop]['dc:identifier']\n",
    "        for aop in aopdict\n",
    "        if ke in aopdict[aop]['aopo:has_key_event']\n",
    "    ]\n",
    "    write_multivalue_triple(g, 'dcterms:isPartOf', aop_links)\n",
    "\n",
    "    g.write(' .\\n\\n')\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all biological events as separate RDF blocks\n",
    "for triple_block in bioevent_triples:\n",
    "    g.write(triple_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event Relationship triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for ker in kerdict:\n",
    "    g.write(\n",
    "        kerdict[ker]['dc:identifier'] +\n",
    "        '\\n\\ta\\taopo:KeyEventRelationship ;' +\n",
    "        '\\n\\tdc:identifier\\t' + kerdict[ker]['dc:identifier'] +\n",
    "        ' ;\\n\\trdfs:label\\t' + kerdict[ker]['rdfs:label'] +\n",
    "        ' ;\\n\\tfoaf:page\\t' + kerdict[ker]['foaf:page'] +\n",
    "        ' ;\\n\\trdfs:seeAlso\\t' + kerdict[ker]['foaf:page'] +\n",
    "        ' ;\\n\\tdcterms:created\\t\"' + kerdict[ker]['dcterms:created'] + '\"' +\n",
    "        ' ;\\n\\tdcterms:modified\\t\"' + kerdict[ker]['dcterms:modified'] + '\"' +\n",
    "        ' ;\\n\\taopo:has_upstream_key_event\\t' + kerdict[ker]['aopo:has_upstream_key_event']['dc:identifier'] +\n",
    "        ' ;\\n\\taopo:has_downstream_key_event\\t' + kerdict[ker]['aopo:has_downstream_key_event']['dc:identifier']\n",
    "    )\n",
    "\n",
    "    if 'dc:description' in kerdict[ker]:\n",
    "        g.write(' ;\\n\\tdc:description\\t' + kerdict[ker]['dc:description'])\n",
    "\n",
    "    for predicate in ['nci:C80263', 'edam:data_2042', 'nci:C71478']:\n",
    "        if predicate in kerdict[ker]:\n",
    "            value = kerdict[ker][predicate].replace(\"\\\\\", \"\")\n",
    "            g.write(f' ;\\n\\t{predicate}\\t{value}')\n",
    "\n",
    "    if 'pato:0000047' in kerdict[ker]:\n",
    "        write_multivalue_triple(g,'pato:0000047',[sex[1] for sex in kerdict[ker]['pato:0000047']],quote=True)\n",
    "\n",
    "    if 'aopo:LifeStageContext' in kerdict[ker]:\n",
    "        write_multivalue_triple(g,'aopo:LifeStageContext', [stage[1] for stage in kerdict[ker]['aopo:LifeStageContext']],quote=True)\n",
    "\n",
    "    if 'ncbitaxon:131567' in kerdict[ker]:\n",
    "        write_multivalue_triple(g,'ncbitaxon:131567',[tax[2] for tax in kerdict[ker]['ncbitaxon:131567']] )\n",
    "\n",
    "    # Link KER to AOP(s)\n",
    "    aop_links = [\n",
    "        aopdict[aop]['dc:identifier']\n",
    "        for aop in aopdict\n",
    "        if ker in aopdict[aop]['aopo:has_key_event_relationship']\n",
    "    ]\n",
    "    write_multivalue_triple(g, 'dcterms:isPartOf', aop_links)\n",
    "\n",
    "    g.write(' .\\n\\n')\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Taxonomy triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for tax in taxdict:\n",
    "    if 'dc:identifier' in taxdict[tax]:\n",
    "        if '\"' not in taxdict[tax]['dc:identifier']:\n",
    "            g.write(taxdict[tax]['dc:identifier'] + '\\n\\ta\\tncbitaxon:131567 ;\\n\\tdc:identifier\\t' + taxdict[tax]['dc:identifier'] + ' ;\\n\\tdc:title\\t\"' + taxdict[tax]['dc:title'])\n",
    "            if taxdict[tax]['dc:source'] is not None:\n",
    "                g.write('\" ;\\n\\tdc:source\\t\"' + taxdict[tax]['dc:source'])\n",
    "            g.write('\" .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Stressor triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for stressor in strdict:\n",
    "    g.write(\n",
    "        strdict[stressor]['dc:identifier'] +\n",
    "        '\\n\\ta\\tnci:C54571 ;' +\n",
    "        '\\n\\tdc:identifier\\t' + strdict[stressor]['dc:identifier'] +\n",
    "        ' ;\\n\\trdfs:label\\t' + strdict[stressor]['rdfs:label'] +\n",
    "        ' ;\\n\\tfoaf:page\\t' + strdict[stressor]['foaf:page'] +\n",
    "        ' ;\\n\\tdc:title\\t' + strdict[stressor]['dc:title'] +\n",
    "        ' ;\\n\\tdcterms:created\\t\"' + strdict[stressor]['dcterms:created'] + '\"' +\n",
    "        ' ;\\n\\tdcterms:modified\\t\"' + strdict[stressor]['dcterms:modified'] + '\"'\n",
    "    )\n",
    "\n",
    "    if 'dc:description' in strdict[stressor]:\n",
    "        g.write(' ;\\n\\tdc:description\\t' + strdict[stressor]['dc:description'])\n",
    "\n",
    "    # Link to chemicals\n",
    "    write_multivalue_triple(g,'aopo:has_chemical_entity',[chedict[chem]['dc:identifier'] for chem in strdict[stressor].get('linktochemical', [])])\n",
    "\n",
    "    # Link to KEs\n",
    "    ke_ids = [\n",
    "        kedict[ke]['dc:identifier']\n",
    "        for ke in kedict\n",
    "        if 'nci:C54571' in kedict[ke] and stressor in kedict[ke]['nci:C54571']\n",
    "    ]\n",
    "\n",
    "    # Extend to AOPs via linked KEs\n",
    "    aop_ids = set()\n",
    "    for ke_id in ke_ids:\n",
    "        for ke in kedict:\n",
    "            if kedict[ke]['dc:identifier'] == ke_id:\n",
    "                for aop in aopdict:\n",
    "                    if ke in aopdict[aop]['aopo:has_key_event']:\n",
    "                        aop_ids.add(aopdict[aop]['dc:identifier'])\n",
    "\n",
    "    # Direct links from AOPs\n",
    "    for aop in aopdict:\n",
    "        if stressor in aopdict[aop].get('nci:C54571', {}):\n",
    "            aop_ids.add(aopdict[aop]['dc:identifier'])\n",
    "\n",
    "    # Combine KE and AOP dcterms:isPartOf links\n",
    "    write_multivalue_triple(g, 'dcterms:isPartOf', list(set(ke_ids + list(aop_ids))))\n",
    "\n",
    "    g.write(' .\\n\\n')\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Biological Process triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for pro in bioprodict:\n",
    "    if pro is not None:\n",
    "        g.write(bioprodict[pro]['dc:identifier'] + '\\ta\\tgo:0008150 ;\\n\\tdc:identifier\\t' + bioprodict[pro]['dc:identifier'] + ' ;\\n\\tdc:title\\t' + bioprodict[pro]['dc:title'] + ' ;\\n\\tdc:source\\t' + bioprodict[pro]['dc:source'] + ' . \\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Biological Object triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for obj in bioobjdict:\n",
    "    if obj is not None and \"N/A\" not in bioobjdict[obj]['dc:identifier'] and 'TAIR' not in bioobjdict[obj]['dc:identifier']:\n",
    "        g.write(bioobjdict[obj]['dc:identifier'] + '\\ta\\tpato:0001241 ;\\n\\tdc:identifier\\t' + bioobjdict[obj]['dc:identifier'] + ' ;\\n\\tdc:title\\t' + bioobjdict[obj]['dc:title'] + ' ;\\n\\tdc:source\\t' + bioobjdict[obj]['dc:source'])\n",
    "        if bioobjdict[obj]['dc:identifier'] in prodict:\n",
    "            g.write(' ;\\n\\tskos:exactMatch\\t'+','.join(prodict[bioobjdict[obj]['dc:identifier']]))\n",
    "        g.write('. \\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Biological Action triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for act in bioactdict:\n",
    "    if act is not None:\n",
    "        if '\"' not in bioactdict[act]['dc:identifier']:\n",
    "            g.write(bioactdict[act]['dc:identifier'] + '\\ta\\tpato:0000001 ;\\n\\tdc:identifier\\t' + bioactdict[act]['dc:identifier'] + ' ;\\n\\tdc:title\\t' + bioactdict[act]['dc:title'] + ' ;\\n\\tdc:source\\t' + bioactdict[act]['dc:source'] + ' . \\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Cell term triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for item in cterm:\n",
    "    if '\"' not in item:\n",
    "        g.write(item + '\\ta\\taopo:CellTypeContext ;\\n\\tdc:identifier\\t' + item + ' ;\\n\\tdc:title\\t' + cterm[item]['dc:title'] + ' ;\\n\\tdc:source\\t' + cterm[item]['dc:source'] + ' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Organ term triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for item in oterm:\n",
    "    if '\"' not in item:\n",
    "        g.write(item + '\\ta\\taopo:OrganContext ;\\n\\tdc:identifier\\t' + item + ' ;\\n\\tdc:title\\t' + oterm[item]['dc:title'] + ' ;\\n\\tdc:source\\t' + oterm[item]['dc:source'] + ' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Chemical triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for che in chedict:\n",
    "    che_data = chedict[che]\n",
    "    if 'dc:identifier' not in che_data or '\"' in che_data['dc:identifier']:\n",
    "        continue\n",
    "\n",
    "    g.write(f\"{che_data['dc:identifier']}\\n\\tdc:identifier\\t{che_data['dc:identifier']}\")\n",
    "\n",
    "    if 'cheminf:000446' in che_data:\n",
    "        g.write(' ;\\n\\ta\\tcheminf:000000, cheminf:000446')\n",
    "        g.write(f' ;\\n\\tcheminf:000446\\t{che_data[\"cheminf:000446\"]}')\n",
    "\n",
    "    if che_data.get('cheminf:000059') != 'inchikey:None':\n",
    "        g.write(f' ;\\n\\tcheminf:000059\\t{che_data[\"cheminf:000059\"]}')\n",
    "\n",
    "    if 'dc:title' in che_data:\n",
    "        g.write(f' ;\\n\\tdc:title\\t{che_data[\"dc:title\"]}')\n",
    "\n",
    "    if 'cheminf:000568' in che_data:\n",
    "        g.write(f' ;\\n\\tcheminf:000568\\t{che_data[\"cheminf:000568\"]}')\n",
    "\n",
    "    # Collect all cheminf properties for skos:exactMatch\n",
    "    cheminf_keys = [\n",
    "        'cheminf:000407', 'cheminf:000405', 'cheminf:000567', 'cheminf:000412',\n",
    "        'cheminf:000140', 'cheminf:000406', 'cheminf:000408', 'cheminf:000409', 'cheminf:000564'\n",
    "    ]\n",
    "    exact_matches = []\n",
    "    for key in cheminf_keys:\n",
    "        exact_matches.extend(che_data.get(key, []))\n",
    "\n",
    "    write_multivalue_triple(g, 'skos:exactMatch', exact_matches)\n",
    "\n",
    "    if 'dcterms:alternative' in che_data:\n",
    "        write_multivalue_triple(g, 'dcterms:alternative', che_data['dcterms:alternative'], quote=True)\n",
    "\n",
    "    # Link chemical to stressors\n",
    "    part_of_stressors = [\n",
    "        strdict[stressor]['dc:identifier']\n",
    "        for stressor in strdict\n",
    "        if 'aopo:has_chemical_entity' in strdict[stressor]\n",
    "        and che in strdict[stressor]['linktochemical']\n",
    "    ]\n",
    "    write_multivalue_triple(g, 'dcterms:isPartOf', part_of_stressors)\n",
    "\n",
    "    g.write(' .\\n\\n')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing mapped Chemical identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "813\n",
      "1223\n",
      "1662\n",
      "2078\n",
      "2493\n",
      "2836\n",
      "3294\n",
      "3508\n",
      "3818\n",
      "3853\n",
      "4373\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for cas in listofcas:\n",
    "    g.write(cas + '\\tdc:source\\t\"CAS\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for inchikey in listofinchikey:\n",
    "    g.write(inchikey + '\\tdc:source\\t\"InChIKey\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "    \n",
    "for comptox in listofcomptox:\n",
    "    g.write(comptox + '\\tdc:source\\t\"CompTox\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "\n",
    "for chebi in listofchebi:\n",
    "    g.write(chebi + '\\ta\\tcheminf:000407 ;\\n\\tcheminf:000407\\t\"'+chebi[6:]+'\";\\n\\tdc:identifier\\t\"'+chebi+'\";\\n\\tdc:source\\t\"ChEBI\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for chemspider in listofchemspider:\n",
    "    g.write(chemspider + '\\ta\\tcheminf:000405 ;\\n\\tcheminf:000405\\t\"'+chemspider[11:]+'\";\\n\\tdc:identifier\\t\"'+chemspider+'\";\\n\\tdc:source\\t\"ChemSpider\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for wd in listofwikidata:\n",
    "    g.write(wd + '\\ta\\tcheminf:000567 ;\\n\\tcheminf:000567\\t\"'+wd[9:]+'\";\\n\\tdc:identifier\\t\"'+wd+'\";\\n\\tdc:source\\t\"Wikidata\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for chembl in listofchembl:\n",
    "    g.write(chembl + '\\ta\\tcheminf:000412 ;\\n\\tcheminf:000412\\t\"'+chembl[16:]+'\";\\n\\tdc:identifier\\t\"'+chembl+'\";\\n\\tdc:source\\t\"ChEMBL\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for pubchem in listofpubchem:\n",
    "    g.write(pubchem + '\\ta\\tcheminf:000140 ;\\n\\tcheminf:000140\\t\"'+pubchem[17:]+'\";\\n\\tdc:identifier\\t\"'+pubchem+'\";\\n\\tdc:source\\t\"PubChem\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for drugbank in listofdrugbank:\n",
    "    g.write(drugbank + '\\ta\\tcheminf:000406 ;\\n\\tcheminf:000406\\t\"'+drugbank[9:]+'\";\\n\\tdc:identifier\\t\"'+drugbank+'\";\\n\\tdc:source\\t\"DrugBank\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for kegg in listofkegg:\n",
    "    g.write(kegg + '\\ta\\tcheminf:000409 ;\\n\\tcheminf:000409\\t\"'+kegg[14:]+'\";\\n\\tdc:identifier\\t\"'+kegg+'\";\\n\\tdc:source\\t\"KEGG\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for lipidmaps in listoflipidmaps:\n",
    "    g.write(lipidmaps + '\\ta\\tcheminf:000564 ;\\n\\tcheminf:000564\\t\"'+lipidmaps[10:]+'\";\\n\\tdc:identifier\\t\"'+lipidmaps+'\";\\n\\tdc:source\\t\"LIPID MAPS\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for hmdb in listofhmdb:\n",
    "    g.write(hmdb + '\\ta\\tcheminf:000408 ;\\n\\tcheminf:000408\\t\"'+hmdb[5:]+'\";\\n\\tdc:identifier\\t\"'+hmdb+'\";\\n\\tdc:source\\t\"HMDB\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing mapped Gene identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for hgnc in hgnclist:\n",
    "    g.write(hgnc + '\\ta\\tedam:data_2298, edam:data_1025 ;\\n\\tedam:data_2298\\t\"'+hgnc[5:]+'\";\\n\\tdc:identifier\\t\"'+hgnc+'\";\\n\\tdc:source\\t\"HGNC\".\\n\\n')\n",
    "\n",
    "for entrez in ncbigenelist:\n",
    "    g.write(entrez + '\\ta\\tedam:data_1027, edam:data_1025 ;\\n\\tedam:data_1027\\t\"'+entrez[9:]+'\";\\n\\tdc:identifier\\t\"'+entrez+'\";\\n\\tdc:source\\t\"Entrez Gene\".\\n\\n')\n",
    "\n",
    "for uniprot in uniprotlist:\n",
    "    g.write(uniprot + '\\ta\\tedam:data_2291, edam:data_1025 ;\\n\\trdfs:seeAlso <http://purl.uniprot.org/uniprot/' + uniprot[8:] + '>;\\n\\towl:sameAs <http://purl.uniprot.org/uniprot/' + uniprot[8:] + '>;\\n\\tedam:data_2291\\t\"'+uniprot[8:]+'\";\\n\\tdc:identifier\\t\"'+uniprot+'\";\\n\\tdc:source\\t\"UniProt\".\\n\\n')\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://rdfs.org/ns/void#Dataset&gt;</td>\n",
       "      <td>Dataset</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://edamontology.org/data_1027&gt;</td>\n",
       "      <td>Gene ID (NCBI)</td>\n",
       "      <td>An NCBI unique identifier of a gene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://edamontology.org/data_1025&gt;</td>\n",
       "      <td>Gene identifier</td>\n",
       "      <td>An identifier of a gene, such as a name/symbol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://edamontology.org/data_2298&gt;</td>\n",
       "      <td>Gene ID (HGNC)</td>\n",
       "      <td>Identifier for a gene approved by the HUGO Gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://purl.org/obo/owl/GO#0008150&gt;</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>A biological process represents a specific obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#CellTypeContext&gt;</td>\n",
       "      <td>Cell-term</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#OrganContext&gt;</td>\n",
       "      <td>Organ-term</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>ChEBI identifier</td>\n",
       "      <td>Database identifier used by ChEBI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>ChEMBL identifier</td>\n",
       "      <td>Identifier used by the ChEMBL database for com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>ChemSpider identifier</td>\n",
       "      <td>Database identifier used by ChemSpider.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>DrugBank identifier</td>\n",
       "      <td>Database identifier used by DrugBank.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>HMDB identifier</td>\n",
       "      <td>Database identifier used by Human Metabolome D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>KEGG identifier</td>\n",
       "      <td>Database identifier used by KEGG.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>LipidMaps identifier</td>\n",
       "      <td>Identifier used by the LipidMaps database, htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>PubChem compound identifier (CID)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>Wikidata identifier</td>\n",
       "      <td>Database identifier used by Wikidata.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;http://rdfs.org/ns/void#Linkset&gt;</td>\n",
       "      <td>Linkset</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#KeyEvent&gt;</td>\n",
       "      <td>Key Event</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#KeyEventRelatio...</td>\n",
       "      <td>Key Event Relationship</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;http://edamontology.org/data_1033&gt;</td>\n",
       "      <td>Ensembl gene ID</td>\n",
       "      <td>Unique identifier for a gene (or other feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>Stressor</td>\n",
       "      <td>An agent, stimulus, activity, or event that ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#AdverseOutcomeP...</td>\n",
       "      <td>Adverse Outcome Pathway</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>chemical entity</td>\n",
       "      <td>A chemical entity is any molecular entity or c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>CAS registry number</td>\n",
       "      <td>Identifier used by the Chemical Abstracts Serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;http://edamontology.org/data_2291&gt;</td>\n",
       "      <td>UniProt ID</td>\n",
       "      <td>An identifier of a polypeptide in the UniProt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;http://purl.bioontology.org/ontology/NCBITAXO...</td>\n",
       "      <td>cellular organisms</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/PATO_0001241&gt;</td>\n",
       "      <td>physical object quality</td>\n",
       "      <td>A quality which inheres in a continuant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URI  \\\n",
       "0                   <http://rdfs.org/ns/void#Dataset>   \n",
       "1                 <http://edamontology.org/data_1027>   \n",
       "2                 <http://edamontology.org/data_1025>   \n",
       "3                 <http://edamontology.org/data_2298>   \n",
       "4                <http://purl.org/obo/owl/GO#0008150>   \n",
       "5     <http://aopkb.org/aop_ontology#CellTypeContext>   \n",
       "6        <http://aopkb.org/aop_ontology#OrganContext>   \n",
       "7   <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "8   <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "9   <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "10  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "11  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "12  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "13  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "14  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "15  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "16                  <http://rdfs.org/ns/void#Linkset>   \n",
       "17           <http://aopkb.org/aop_ontology#KeyEvent>   \n",
       "18  <http://aopkb.org/aop_ontology#KeyEventRelatio...   \n",
       "19                <http://edamontology.org/data_1033>   \n",
       "20  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...   \n",
       "21  <http://aopkb.org/aop_ontology#AdverseOutcomeP...   \n",
       "22  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "23  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "24                <http://edamontology.org/data_2291>   \n",
       "25  <http://purl.bioontology.org/ontology/NCBITAXO...   \n",
       "26      <http://purl.obolibrary.org/obo/PATO_0001241>   \n",
       "\n",
       "                                label  \\\n",
       "0                             Dataset   \n",
       "1                      Gene ID (NCBI)   \n",
       "2                     Gene identifier   \n",
       "3                      Gene ID (HGNC)   \n",
       "4                  biological_process   \n",
       "5                           Cell-term   \n",
       "6                          Organ-term   \n",
       "7                    ChEBI identifier   \n",
       "8                   ChEMBL identifier   \n",
       "9               ChemSpider identifier   \n",
       "10                DrugBank identifier   \n",
       "11                    HMDB identifier   \n",
       "12                    KEGG identifier   \n",
       "13               LipidMaps identifier   \n",
       "14  PubChem compound identifier (CID)   \n",
       "15                Wikidata identifier   \n",
       "16                            Linkset   \n",
       "17                          Key Event   \n",
       "18             Key Event Relationship   \n",
       "19                    Ensembl gene ID   \n",
       "20                           Stressor   \n",
       "21            Adverse Outcome Pathway   \n",
       "22                    chemical entity   \n",
       "23                CAS registry number   \n",
       "24                         UniProt ID   \n",
       "25                 cellular organisms   \n",
       "26            physical object quality   \n",
       "\n",
       "                                          description  \n",
       "0                                                   -  \n",
       "1                An NCBI unique identifier of a gene.  \n",
       "2   An identifier of a gene, such as a name/symbol...  \n",
       "3   Identifier for a gene approved by the HUGO Gen...  \n",
       "4   A biological process represents a specific obj...  \n",
       "5                                                   -  \n",
       "6                                                   -  \n",
       "7                  Database identifier used by ChEBI.  \n",
       "8   Identifier used by the ChEMBL database for com...  \n",
       "9             Database identifier used by ChemSpider.  \n",
       "10              Database identifier used by DrugBank.  \n",
       "11  Database identifier used by Human Metabolome D...  \n",
       "12                  Database identifier used by KEGG.  \n",
       "13  Identifier used by the LipidMaps database, htt...  \n",
       "14                                                  -  \n",
       "15              Database identifier used by Wikidata.  \n",
       "16                                                  -  \n",
       "17                                                  -  \n",
       "18                                                  -  \n",
       "19  Unique identifier for a gene (or other feature...  \n",
       "20  An agent, stimulus, activity, or event that ca...  \n",
       "21                                                  -  \n",
       "22  A chemical entity is any molecular entity or c...  \n",
       "23  Identifier used by the Chemical Abstracts Serv...  \n",
       "24  An identifier of a polypeptide in the UniProt ...  \n",
       "25                                                  -  \n",
       "26            A quality which inheres in a continuant  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath + 'typelabels.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row,index in df.iterrows():\n",
    "    g.write('\\n\\n'+index['URI']+'\\trdfs:label\\t\"'+index['label'])\n",
    "    if index['description'] != '-':\n",
    "        g.write('\";\\n\\tdc:description\\t\"\"\"'+index['description']+'\"\"\".')\n",
    "    else:\n",
    "        g.write('\".')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AOP-Wiki RDF file is created!\n"
     ]
    }
   ],
   "source": [
    "g.close()\n",
    "print(\"The AOP-Wiki RDF file is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #5: Gene ID text-mapping (HGNC)</b>\n",
    "In order to identify genes present in the textual descriptions of Key Events (KEs) and Key Event Relationships (KERs), HGNC identifier mapping was performed. [Genenames.org](https://www.genenames.org/) is the curated online repository for HGNC nomenclature, and it allows custom downloads for all HGNC entries, including approved symbols and names, previous symbols and synonyms. \n",
    "\n",
    "## Step #5A - Parsing the custom HGNC file\n",
    "This starts with loading the custom download file, which was named `HGNCgenes.txt` and stored in the path defined in Step #2. Next, its contents are extracted and stored in a dictionary called `genedict1`, while variants are created for every gene name and gene symbol for more effective mapping of genes. These variants are stored in `genedict2`, which is used for more effective mapping of genes in Step #5B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNCfilename = 'HGNCgenes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Modified Time :  Tue Aug 20 08:51:09 2024\n"
     ]
    }
   ],
   "source": [
    "fileStatsObj = os.stat (filepath + HGNCfilename)\n",
    "HGNCmodificationTime = time.ctime ( fileStatsObj [ stat.ST_MTIME ] )\n",
    "print(\"Last Modified Time : \", HGNCmodificationTime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 41893 genes are included for mappings\n"
     ]
    }
   ],
   "source": [
    "HGNCgenes = open(filepath + HGNCfilename, 'r')\n",
    "symbols = [' ','(',')','[',']',',','.']\n",
    "genedict1 = {}\n",
    "genedict2 = {}\n",
    "b = 0\n",
    "for line in HGNCgenes:\n",
    "    if not 'HGNC ID\tApproved symbol\tApproved name\tPrevious symbols\tSynonyms\tAccession numbers\tEnsembl ID(supplied by Ensembl)'in line:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if not '@' in a[1]: #gene clusters contain a '@' in their symbol, which are filtered out\n",
    "            genedict1[a[1]] = []\n",
    "            genedict2[a[1]] = []\n",
    "            genedict1[a[1]].append(a[1])\n",
    "            if not a[2] == '':\n",
    "                genedict1[a[1]].append(a[2])\n",
    "            for item in a[3:]:\n",
    "                if not item == '':\n",
    "                    for name in item.split(', '):\n",
    "                        genedict1[a[1]].append(name)\n",
    "            for item in genedict1[a[1]]:\n",
    "                for s1 in symbols:\n",
    "                    for s2 in symbols:\n",
    "                        genedict2[a[1]].append((s1+item+s2))\n",
    "HGNCgenes.close()\n",
    "print(\"A total of \" + str(len(genedict2)) + \" genes are included for mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5B - HGNC identifier mapping\n",
    "Genes are mapped for descriptions of KEs and KERs, and for the biological plausibility and emperical support sections of KERs. First, these are screened for any overlap with all possible gene symbols and names captured in genedict1. Then, all positive matches are checked by mapping with all variants of those genes, ensuring the correct mapping. All matches are stored in the kedict and kerdict dictionaries. Also, all mapped genes are stored in a list called hgnclist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene mapping on Key Events is can take a minute...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m genedict1[key]:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m kedict[ke\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdc:description\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     12\u001b[0m         a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hgnclist = []\n",
    "keyhitcount = {}\n",
    "print(\"Gene mapping on Key Events is can take a minute...\")\n",
    "for ke in root.findall(aopxml + 'key-event'):\n",
    "    geneoverlapdict = {}\n",
    "    if ke.find(aopxml + 'description').text is not None:\n",
    "        geneoverlapdict[ke.get('id')] = []\n",
    "        for key in genedict2:\n",
    "            a = 0\n",
    "            for item in genedict1[key]:\n",
    "                if item in kedict[ke.get('id')]['dc:description']:\n",
    "                    a = 1\n",
    "            if a == 1:\n",
    "                for item in genedict2[key]:\n",
    "                    if item in kedict[ke.get('id')]['dc:description'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ke.get('id')]:\n",
    "                        geneoverlapdict[ke.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                        if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                            hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                        if item in keyhitcount:\n",
    "                            keyhitcount[item] += 1\n",
    "                        else:\n",
    "                            keyhitcount[item] = 1\n",
    "                            \n",
    "        if not geneoverlapdict[ke.get('id')]:\n",
    "            del geneoverlapdict[ke.get('id')]\n",
    "    if ke.get('id') in geneoverlapdict:\n",
    "        kedict[ke.get('id')]['edam:data_1025'] = geneoverlapdict[ke.get('id')]\n",
    "print(\"Done!\\nIn total, \" + str(len(hgnclist))+ \" genes were mapped to descriptions of Key Events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROS : 12 hits\n",
      " II : 41 hits\n",
      " B : 37 hits\n",
      "(ALP): 24 hits\n",
      "(ROS): 13 hits\n",
      " T3 : 11 hits\n",
      " TH : 18 hits\n",
      " G2 : 15 hits\n",
      " T : 35 hits\n",
      " AR : 12 hits\n",
      " E2 : 30 hits\n"
     ]
    }
   ],
   "source": [
    "for gene, count in keyhitcount.items():\n",
    "    if count > 10:\n",
    "        print(f\"{gene}: {count} hits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Event Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene mapping on Key Events is can take a couple of minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m genedict1[key]:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m kerdict[ker\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnci:C80263\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     23\u001b[0m         a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Gene mapping on Key Events is can take a couple of minutes...\")\n",
    "for ker in root.findall(aopxml + 'key-event-relationship'):\n",
    "    geneoverlapdict = {}\n",
    "    geneoverlapdict[ker.get('id')] = []\n",
    "    if ker.find(aopxml + 'description').text is not None:\n",
    "        for key in genedict2:\n",
    "            a = 0\n",
    "            for item in genedict1[key]:\n",
    "                if item in kerdict[ker.get('id')]['dc:description']:\n",
    "                    a = 1\n",
    "            if a == 1:\n",
    "                for item in genedict2[key]:\n",
    "                    if item in kerdict[ker.get('id')]['dc:description'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ker.get('id')]:\n",
    "                        geneoverlapdict[ker.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                        if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                            hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "    for weight in ker.findall(aopxml + 'weight-of-evidence'):\n",
    "        if weight.find(aopxml + 'biological-plausibility').text is not None:\n",
    "            for key in genedict2:\n",
    "                a = 0\n",
    "                for item in genedict1[key]:\n",
    "                    if item in kerdict[ker.get('id')]['nci:C80263']:\n",
    "                        a = 1\n",
    "                if a== 1:\n",
    "                    for item in genedict2[key]:\n",
    "                        if item in kerdict[ker.get('id')]['nci:C80263'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ker.get('id')]:\n",
    "                            geneoverlapdict[ker.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                            if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                                hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "        if weight.find(aopxml + 'emperical-support-linkage').text is not None:\n",
    "            for key in genedict2:\n",
    "                a = 0\n",
    "                for item in genedict1[key]:\n",
    "                    if item in kerdict[ker.get('id')]['edam:data_2042']:\n",
    "                        a = 1\n",
    "                if a== 1:\n",
    "                    for item in genedict2[key]:\n",
    "                        if item in kerdict[ker.get('id')]['edam:data_2042'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ker.get('id')]:\n",
    "                            geneoverlapdict[ker.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                            if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                                hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "    if not geneoverlapdict[ker.get('id')]:\n",
    "        del geneoverlapdict[ker.get('id')]\n",
    "    if ker.get('id') in geneoverlapdict:\n",
    "        kerdict[ker.get('id')]['edam:data_1025'] = geneoverlapdict[ker.get('id')]\n",
    "print(\"Done!\\nIn total, \" + str(len(hgnclist))+ \" genes were mapped to descriptions of Key Events and Key Event Relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5C - Identifier mapping for other databases\n",
    "BridgeDb was used to additional identifiers from other databases, including Entrez gene, Ensembl, and UniProt IDs. By a request call, identifiers are returned, which are stored in the dictionary called `geneiddict`. The BridgeDb service URL has already been defined in Step #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene identifiers mapped:\n",
      "1534 Entrez gene IDs\n",
      "8252 Uniprot IDs\n",
      "1539 Ensembl IDs\n"
     ]
    }
   ],
   "source": [
    "geneiddict = {}\n",
    "listofentrez = []\n",
    "listofensembl = []\n",
    "listofuniprot = []\n",
    "\n",
    "for gene in hgnclist:\n",
    "    a = requests.get(bridgedb + 'xrefs/H/' + gene[5:]).text.split('\\n')\n",
    "    dictionaryforgene = {}\n",
    "    if 'html' not in a:\n",
    "        for item in a:\n",
    "            b = item.split('\\t')\n",
    "            if len(b) == 2:\n",
    "                if b[1] not in dictionaryforgene:\n",
    "                    dictionaryforgene[b[1]] = []\n",
    "                    dictionaryforgene[b[1]].append(b[0])\n",
    "                else:\n",
    "                    dictionaryforgene[b[1]].append(b[0])\n",
    "    geneiddict[gene] = []\n",
    "    if 'Entrez Gene' in dictionaryforgene:\n",
    "        for entrez in dictionaryforgene['Entrez Gene']:\n",
    "            if 'ncbigene:'+entrez not in listofentrez:\n",
    "                listofentrez.append(\"ncbigene:\"+entrez)\n",
    "            geneiddict[gene].append(\"ncbigene:\"+entrez)\n",
    "    if 'Ensembl' in dictionaryforgene:\n",
    "        for ensembl in dictionaryforgene['Ensembl']:\n",
    "            if 'ensembl:' + ensembl not in listofensembl:\n",
    "                listofensembl.append(\"ensembl:\"+ensembl)\n",
    "            geneiddict[gene].append(\"ensembl:\"+ensembl)\n",
    "    if 'Uniprot-TrEMBL' in dictionaryforgene:\n",
    "        for uniprot in dictionaryforgene['Uniprot-TrEMBL']:\n",
    "            if 'uniprot:'+uniprot not in listofuniprot:\n",
    "                listofuniprot.append(\"uniprot:\"+uniprot)\n",
    "            geneiddict[gene].append(\"uniprot:\"+uniprot)\n",
    "print(\"Gene identifiers mapped:\\n\" + str(len(listofentrez)) + \" Entrez gene IDs\\n\" + str(len(listofuniprot)) + \" Uniprot IDs\\n\" + str(len(listofensembl)) + \" Ensembl IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5D - Writing output file\n",
    "The final step involves the writing of the RDF file in Turtle syntax. After writing the prefixes used for predicates and identifier types, all gene mapping links stored in the kedict and kerdict are written, followed by the HGNC IDs and matched IDs for other databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open(filepath + 'AOPWikiRDF-Genes.ttl', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.write('@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix aop.events: <https://identifiers.org/aop.events/> .\\n@prefix aop.relationships: <https://identifiers.org/aop.relationships/> .\\n@prefix skos: <http://www.w3.org/2004/02/skos/core#> . \\n@prefix ensembl: <https://identifiers.org/ensembl/> .\\n@prefix edam: <http://edamontology.org/> .\\n@prefix hgnc: <https://identifiers.org/hgnc/>.\\n@prefix ncbigene: <https://identifiers.org/ncbigene/>.\\n@prefix uniprot: <https://identifiers.org/uniprot/>.\\n@prefix owl: <http://www.w3.org/2002/07/owl#>.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event triples\n",
    "These triples only contain the mappings with genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Number of Key Events with genes mapped to their descriptions: 383\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for ke in kedict:\n",
    "    if 'edam:data_1025' in kedict[ke]:\n",
    "        n += 1\n",
    "        g.write(kedict[ke]['dc:identifier']+'\\tedam:data_1025\\t' + ','.join(kedict[ke]['edam:data_1025'])+' .\\n\\n')\n",
    "print(\"Done!\\n\\nNumber of Key Events with genes mapped to their descriptions: \" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event Relationship triples\n",
    "These triples only contain the mappings with genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Number of Key Event Relationships with genes mapped to their descriptions: 596\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for ker in kerdict:\n",
    "    if 'edam:data_1025' in kerdict[ker]:\n",
    "        n += 1\n",
    "        g.write(kerdict[ker]['dc:identifier']+'\\tedam:data_1025\\t' + ','.join(kerdict[ker]['edam:data_1025'])+' .\\n\\n')\n",
    "print(\"Done!\\n\\nNumber of Key Event Relationships with genes mapped to their descriptions: \" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Gene identifier triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1571 HGNC triples written.\n",
      "1534 Entrez gene triples written.\n",
      "1539 Ensembl triples written.\n",
      "8252 UniProt triples written.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for hgnc in hgnclist:\n",
    "    g.write(hgnc + '\\ta\\tedam:data_2298, edam:data_1025 ;\\n\\tedam:data_2298\\t\"'+hgnc[5:]+'\";\\n\\tdc:identifier\\t\"'+hgnc+'\";\\n\\tdc:source\\t\"HGNC\"')\n",
    "    if not geneiddict[hgnc] == []:\n",
    "        g.write(' ;\\n\\tskos:exactMatch\\t'+','.join(geneiddict[hgnc]))\n",
    "    g.write('.\\n\\n')\n",
    "print(str(len(hgnclist))+\" HGNC triples written.\")\n",
    "for entrez in listofentrez:\n",
    "    g.write(entrez + '\\ta\\tedam:data_1027, edam:data_1025 ;\\n\\tedam:data_1027\\t\"'+entrez[9:]+'\";\\n\\tdc:identifier\\t\"'+entrez+'\";\\n\\tdc:source\\t\"Entrez Gene\".\\n\\n')\n",
    "print(str(len(listofentrez))+\" Entrez gene triples written.\")\n",
    "for ensembl in listofensembl:\n",
    "    g.write(ensembl + '\\ta\\tedam:data_1033, edam:data_1025 ;\\n\\tedam:data_1033\\t\"'+ensembl[8:]+'\";\\n\\tdc:identifier\\t\"'+ensembl+'\";\\n\\tdc:source\\t\"Ensembl\".\\n\\n')\n",
    "print(str(len(listofensembl))+ \" Ensembl triples written.\")\n",
    "for uniprot in listofuniprot:\n",
    "    g.write(uniprot + '\\ta\\tedam:data_2291, edam:data_1025 ;\\n\\tedam:data_2291\\t\"'+uniprot[8:]+'\";\\n\\tdc:identifier\\t\"'+uniprot+'\";\\n\\tdc:source\\t\"UniProt\".\\n\\n')\n",
    "print(str(len(listofuniprot))+ \" UniProt triples written.\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AOP-Wiki RDF Genes file is created!\n"
     ]
    }
   ],
   "source": [
    "g.close()\n",
    "print(\"The AOP-Wiki RDF Genes file is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #6: Creating the VoID file</b>\n",
    "The last file contains the metadata of the original data, script, and tools used for the creation of the AOP-Wiki RDF files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of the BridgeDb mapping files: \n",
      " Gene/Proteins: Ensembl:111\n",
      " Chemicals: HMDB-CHEBI-WIKIDATA:HMDB5.0.20240416-CHEBI236-WIKIDATA20241215\n"
     ]
    }
   ],
   "source": [
    "a = requests.get(bridgedb + 'properties').text.split('\\n')\n",
    "info = {}\n",
    "for item in a:\n",
    "    if not item.split('\\t')[0] in info:\n",
    "        info[item.split('\\t')[0]] = []\n",
    "    if len(item.split('\\t')) == 2:\n",
    "        info[item.split('\\t')[0]].append(item.split('\\t')[1])\n",
    "print('The version of the BridgeDb mapping files: \\n Gene/Proteins: '\n",
    "      + str(info['DATASOURCENAME'][0]) + ':' + str(info['DATASOURCEVERSION'][0]) + '\\n Chemicals: '\n",
    "      + str(info['DATASOURCENAME'][5]) + ':' + str(info['DATASOURCEVERSION'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date: 2025-05-05 21:42:50.112099\n"
     ]
    }
   ],
   "source": [
    "x = datetime.datetime.now()\n",
    "print('The date: ' + str(x))\n",
    "y = str(x)\n",
    "y = y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VoID file is created!\n"
     ]
    }
   ],
   "source": [
    "g = open(filepath + 'AOPWikiRDF-Void.ttl', 'w', encoding='utf-8')\n",
    "g.write('@prefix : <https://aopwiki.rdf.bigcat-bioinformatics.org/> .\\n@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix dcterms: <http://purl.org/dc/terms/> .\\n@prefix void:  <http://rdfs.org/ns/void#> .\\n@prefix pav:   <http://purl.org/pav/> .\\n@prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix dcat:  <http://www.w3.org/ns/dcat#> .\\n@prefix foaf:  <http://xmlns.com/foaf/0.1/> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n@prefix freq:  <http://purl.org/cld/freq/> .')\n",
    "g.write('\\n:AOPWikiRDF.ttl\\ta\\tvoid:Dataset ;\\n\\tdc:description\\t\"AOP-Wiki RDF data from the AOP-Wiki database\" ;\\n\\tpav:createdOn\\t\"' + y + '\"^^xsd:date;\\n\\tdcterms:modified\\t\"' + y +'\"^^xsd:date ;\\n\\tpav:createdWith\\t\"' + str(aopwikixmlfilename) + '\", :Promapping ;\\n\\tpav:createdBy\\t<https://zenodo.org/badge/latestdoi/146466058> ;\\n\\tfoaf:homepage\\t<https://aopwiki.org> ;\\n\\tdcterms:accuralPeriodicity  freq:quarterly ;\\n\\tdcat:downloadURL\\t<https://aopwiki.org/downloads/' + str(aopwikixmlfilename) + '> .\\n\\n:AOPWikiRDF-Genes.ttl\\ta\\tvoid:Dataset ;\\n\\tdc:description\\t\"AOP-Wiki RDF extension with gene mappings based on approved names and symbols\" ;\\n\\tpav:createdOn\\t\"' + str(x) + '\" ;\\n\\tpav:createdWith\\t\"' + str(aopwikixmlfilename) + '\", :HGNCgenes ;\\n\\tpav:createdBy\\t<https://zenodo.org/badge/latestdoi/146466058> ;\\n\\tdcterms:accuralPeriodicity  freq:quarterly ;\\n\\tfoaf:homepage\\t<https://aopwiki.org> ;\\n\\tdcat:downloadURL\\t<https://aopwiki.org/downloads/' + str(aopwikixmlfilename) + '>, <https://www.genenames.org/download/custom/> . \\n\\n:HGNCgenes.txt\\ta\\tvoid:Dataset, void:Linkset ;\\n\\tdc:description\\t\"HGNC approved symbols and names for genes\" ;\\n\\tdcat:downloadURL\\t<https://www.genenames.org/download/custom/> ;\\n\\tpav:importedOn\\t\"'+HGNCmodificationTime+'\" .\\n\\n<https://proconsortium.org/download/current/promapping.txt>\\ta\\tvoid:Dataset, void:Linkset;\\n\\tdc:description\\t\"PRotein ontology mappings to protein database identifiers\";\\n\\tdcat:downloadURL\\t<https://proconsortium.org/download/current/promapping.txt>;\\n\\tpav:importedOn\\t\"'+PromodificationTime+'\".')\n",
    "g.close()\n",
    "print(\"The VoID file is created!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
