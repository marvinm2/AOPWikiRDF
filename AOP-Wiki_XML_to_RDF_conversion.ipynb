{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>AOP-Wiki XML conversion to RDF</b>\n",
    "Author: Marvin Martens\n",
    "\n",
    "The [AOP-Wiki](https://aopwiki.org/) is the central repository for qualitative descriptions of AOPs, and releases its database every three months in XML format. This Jupyter notebook makes the conversion of the AOP-Wiki XML into RDF with Turtle (ttl) syntax. \n",
    "\n",
    "It downloads and parses the AOP-Wiki XML file with the ElementTree XML API Python library, and stores all its components in nested dictionaries for the all subjects which form the basis of the existing AOP-Wiki, being the AOPs, KEs,  KERs,  stressors,  chemicals,  taxonomy,  cell-terms,  organ-terms,  and  the  KE  components, which comprise of Biological Processes (BPs),  Biological Objects (BOs) and Biological Actions (BAs).  During the filling of those dictionaries, semantic annotations are being added for  the  subjects,  the  relationship  (predicate)  to  their  property  (object),  and  for  the  properties themselves when meant to represent an identifier or ontology term.\n",
    "\n",
    "<img src=\"Overview AOP-Wiki RDF.svg\" style=\"width: 650px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #1: imports</b>\n",
    "First, all required Python libraries are imported. It will `pip install` libraries if the imports are not found on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/marvin/anaconda3/lib/python3.12/site-packages (25.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip \n",
    "from xml.etree.ElementTree import parse\n",
    "import re\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "import requests\n",
    "import datetime\n",
    "import urllib\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import stat\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pipreqsnb: command not found\n"
     ]
    }
   ],
   "source": [
    "!pipreqsnb . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the mapping of identifiers for chemicals and genes. To make this possible, the URL to the BridgeDb service should be defined in the `bridgedb` variable, and include the `/Human/`. The quickest way to execute the code is by using a local BridgeDb service launched with the BridgeDb Docker image using the [instructions](https://github.com/bridgedb/docker). Alternatively, the live web version can be used by defining the `bridgedb` variable as 'https://webservice.bridgedb.org/Human/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridgedb = 'https://webservice.bridgedb.org/Human/'#'http://localhost:8180/Human/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #2: Getting the AOP-Wiki XML</b>\n",
    "Next, the last version of the AOP-Wiki XML is defined in the `aopwikixmlfilename` variable, which can be found in the [download page of the AOP-Wiki](https://aopwiki.org/downloads/). This file is downloaded, unzipped, and opened, after which the ElementTree XML API parses it, making it ready for extracting its contents from the `root`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-02-12\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aopwiki.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "aopwikixmlfilename = 'aop-wiki-xml-'+str(today)\n",
    "response = requests.get('https://aopwiki.org/downloads/aop-wiki-xml.gz', verify=False)\n",
    "with open(aopwikixmlfilename, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XML will be extracted to the folder defined within the variable `filepath` in the next block of code, which is by defailt `/data` relative to the location of the Jupyter notebook. All datafiles used and produced with this notebook will be placed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/aop-wiki-xml-2025-02-12 opened\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with gzip.open(aopwikixmlfilename, 'rb') as f_in:\n",
    "        with open(filepath+aopwikixmlfilename, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            print('File ' + filepath+aopwikixmlfilename + ' opened')\n",
    "except:\n",
    "    print('Check if the filepath is correct:\\n' + filepath+aopwikixmlfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AOP-Wiki XML is parsed correctly, and contains 6559 entities\n"
     ]
    }
   ],
   "source": [
    "tree = parse(filepath + aopwikixmlfilename)\n",
    "root = tree.getroot()\n",
    "print('The AOP-Wiki XML is parsed correctly, and contains ' + str(len(root)) + ' entities')\n",
    "\n",
    "aopxml = '{http://www.aopkb.org/aop-xml}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #3: extracting information from the XML</b>\n",
    "The next section extracts all information from the main 11 AOP-Wiki entities shown in Figure 1. These are stored in nested dictionaries, while using ontological annotations as keys for semantic mapping of the information. Note that the cell-terms and organ-terms are included in the KE block of code.\n",
    "\n",
    "First, all reference identifiers for AOPs, KEs, KERs and stressors need to be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The AOP-Wiki XML contains 514 identifiers for the entity AOP\n",
      "\n",
      "The AOP-Wiki XML contains 1497 identifiers for the entity KE\n",
      "\n",
      "The AOP-Wiki XML contains 2123 identifiers for the entity KER\n",
      "\n",
      "The AOP-Wiki XML contains 719 identifiers for the entity Stressor\n"
     ]
    }
   ],
   "source": [
    "refs = {'AOP': {}, 'KE': {}, 'KER': {}, 'Stressor': {}}\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'aop-reference'):\n",
    "    refs['AOP'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'key-event-reference'):\n",
    "    refs['KE'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'key-event-relationship-reference'):\n",
    "    refs['KER'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for ref in root.find(aopxml + 'vendor-specific').findall(aopxml + 'stressor-reference'):\n",
    "    refs['Stressor'][ref.get('id')] = ref.get('aop-wiki-id')\n",
    "for item in refs:\n",
    "    print('\\nThe AOP-Wiki XML contains ' + str(len(refs[item])) + ' identifiers for the entity ' + item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adverse Outcome Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 514 Adverse Outcome Pathways have been parsed.\n"
     ]
    }
   ],
   "source": [
    "aopdict = {}\n",
    "kedict = {}\n",
    "for AOP in root.findall(aopxml + 'aop'):\n",
    "    aopdict[AOP.get('id')] = {}\n",
    "    aopdict[AOP.get('id')]['dc:identifier'] = 'aop:' + refs['AOP'][AOP.get('id')]\n",
    "    aopdict[AOP.get('id')]['rdfs:label'] = '\"AOP ' + refs['AOP'][AOP.get('id')] + '\"'\n",
    "    aopdict[AOP.get('id')]['foaf:page'] = '<https://identifiers.org/aop/' + refs['AOP'][AOP.get('id')] + '>'\n",
    "    aopdict[AOP.get('id')]['dc:title'] = '\"' + AOP.find(aopxml + 'title').text + '\"'\n",
    "    aopdict[AOP.get('id')]['dcterms:alternative'] = AOP.find(aopxml + 'short-name').text\n",
    "    aopdict[AOP.get('id')]['dc:description'] = []\n",
    "    if AOP.find(aopxml + 'background') is not None:\n",
    "        aopdict[AOP.get('id')]['dc:description'].append('\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'background').text) + '\"\"\"')\n",
    "    if AOP.find(aopxml + 'authors').text is not None:\n",
    "        aopdict[AOP.get('id')]['dc:creator'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'authors').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'abstract').text is not None:\n",
    "        aopdict[AOP.get('id')]['dcterms:abstract'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'abstract').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'status').find(aopxml + 'wiki-status') is not None:\n",
    "        aopdict[AOP.get('id')]['dcterms:accessRights'] = '\"' + AOP.find(aopxml + 'status').find(aopxml + 'wiki-status').text + '\"' \n",
    "    if AOP.find(aopxml + 'status').find(aopxml + 'oecd-status') is not None:\n",
    "        aopdict[AOP.get('id')]['oecd-status'] =  '\"' + AOP.find(aopxml + 'status').find(aopxml + 'oecd-status').text + '\"' \n",
    "    if AOP.find(aopxml + 'status').find(aopxml + 'saaop-status') is not None:\n",
    "        aopdict[AOP.get('id')]['saaop-status'] =  '\"' + AOP.find(aopxml + 'status').find(aopxml + 'saaop-status').text + '\"' \n",
    "    aopdict[AOP.get('id')]['oecd-project'] = AOP.find(aopxml + 'oecd-project').text\n",
    "    aopdict[AOP.get('id')]['dc:source'] = AOP.find(aopxml + 'source').text\n",
    "    aopdict[AOP.get('id')]['dcterms:created'] = AOP.find(aopxml + 'creation-timestamp').text\n",
    "    aopdict[AOP.get('id')]['dcterms:modified'] = AOP.find(aopxml + 'last-modification-timestamp').text\n",
    "    for appl in AOP.findall(aopxml + 'applicability'):\n",
    "        for sex in appl.findall(aopxml + 'sex'):\n",
    "            if 'pato:0000047' not in aopdict[AOP.get('id')]:\n",
    "                aopdict[AOP.get('id')]['pato:0000047'] = [[sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text]]\n",
    "            else:\n",
    "                aopdict[AOP.get('id')]['pato:0000047'].append([sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text])\n",
    "        for life in appl.findall(aopxml + 'life-stage'):\n",
    "            if 'aopo:LifeStageContext' not in aopdict[AOP.get('id')]:\n",
    "                aopdict[AOP.get('id')]['aopo:LifeStageContext'] = [[life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text]]\n",
    "            else:\n",
    "                aopdict[AOP.get('id')]['aopo:LifeStageContext'].append([life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text])\n",
    "    aopdict[AOP.get('id')]['aopo:has_key_event'] = {}\n",
    "    if AOP.find(aopxml + 'key-events') is not None:\n",
    "        for KE in AOP.find(aopxml + 'key-events').findall(aopxml + 'key-event'):\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event'][KE.get('key-event-id')] = {}\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event'][KE.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][KE.get('key-event-id')]\n",
    "    aopdict[AOP.get('id')]['aopo:has_key_event_relationship'] = {}\n",
    "    if AOP.find(aopxml + 'key-event-relationships') is not None:\n",
    "        for KER in AOP.find(aopxml + 'key-event-relationships').findall(aopxml + 'relationship'):\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')] = {}\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['dc:identifier'] = 'aop.relationships:' + refs['KER'][KER.get('id')]\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['adjacency'] = KER.find(aopxml + 'adjacency').text\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['quantitative-understanding-value'] = KER.find(aopxml + 'quantitative-understanding-value').text\n",
    "            aopdict[AOP.get('id')]['aopo:has_key_event_relationship'][KER.get('id')]['aopo:has_evidence'] = KER.find(aopxml + 'evidence').text\n",
    "    aopdict[AOP.get('id')]['aopo:has_molecular_initiating_event'] = {}\n",
    "    for MIE in AOP.findall(aopxml + 'molecular-initiating-event'):\n",
    "        aopdict[AOP.get('id')]['aopo:has_molecular_initiating_event'][MIE.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_molecular_initiating_event'][MIE.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][MIE.get('key-event-id')]\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][MIE.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][MIE.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][MIE.get('key-event-id')]\n",
    "        if MIE.find(aopxml + 'evidence-supporting-chemical-initiation').text is not None:\n",
    "            kedict[MIE.get('key-event-id')] = {}\n",
    "            aopdict[AOP.get('id')]['dc:description'].append('\"\"\"' + TAG_RE.sub('', MIE.find(aopxml + 'evidence-supporting-chemical-initiation').text) + '\"\"\"')\n",
    "    aopdict[AOP.get('id')]['aopo:has_adverse_outcome'] = {}\n",
    "    for AO in AOP.findall(aopxml + 'adverse-outcome'):\n",
    "        aopdict[AOP.get('id')]['aopo:has_adverse_outcome'][AO.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_adverse_outcome'][AO.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][AO.get('key-event-id')]\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][AO.get('key-event-id')] = {}\n",
    "        aopdict[AOP.get('id')]['aopo:has_key_event'][AO.get('key-event-id')]['dc:identifier'] = 'aop.events:' + refs['KE'][AO.get('key-event-id')]\n",
    "        if AO.find(aopxml + 'examples').text is not None:\n",
    "            kedict[AO.get('key-event-id')] = {}\n",
    "            aopdict[AOP.get('id')]['dc:description'].append('\"\"\"' + TAG_RE.sub('', AO.find(aopxml + 'examples').text) + '\"\"\"')\n",
    "    aopdict[AOP.get('id')]['nci:C54571'] = {}\n",
    "    if AOP.find(aopxml + 'aop-stressors') is not None:\n",
    "        for stressor in AOP.find(aopxml + 'aop-stressors').findall(aopxml + 'aop-stressor'):\n",
    "            aopdict[AOP.get('id')]['nci:C54571'][stressor.get('stressor-id')] = {}\n",
    "            aopdict[AOP.get('id')]['nci:C54571'][stressor.get('stressor-id')]['dc:identifier'] = 'aop.stressor:' + refs['Stressor'][stressor.get('stressor-id')]\n",
    "            aopdict[AOP.get('id')]['nci:C54571'][stressor.get('stressor-id')]['aopo:has_evidence'] = stressor.find(aopxml + 'evidence').text\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'description').text is not None:\n",
    "        aopdict[AOP.get('id')]['nci:C25217'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'description').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'key-event-essentiality-summary').text is not None:\n",
    "        aopdict[AOP.get('id')]['nci:C48192'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'key-event-essentiality-summary').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'applicability').text is not None:\n",
    "        aopdict[AOP.get('id')]['aopo:AopContext'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'applicability').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'weight-of-evidence-summary').text is not None:\n",
    "        aopdict[AOP.get('id')]['aopo:has_evidence'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'weight-of-evidence-summary').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'overall-assessment').find(aopxml + 'quantitative-considerations').text is not None:\n",
    "        aopdict[AOP.get('id')]['edam:operation_3799'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'overall-assessment').find(aopxml + 'quantitative-considerations').text) + '\"\"\"'\n",
    "    if AOP.find(aopxml + 'potential-applications').text is not None:\n",
    "        aopdict[AOP.get('id')]['nci:C25725'] = '\"\"\"' + TAG_RE.sub('', AOP.find(aopxml + 'potential-applications').text) + '\"\"\"'\n",
    "print('Done!\\n\\nA total of ' + str(len(aopdict)) + ' Adverse Outcome Pathways have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemicals\n",
    "For the chemicals in the AOP-Wiki, we added BridgeDb mappings for increased coverage of chemical databases for which we used the already present CAS identifers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 412 chemicals have been parsed.\n"
     ]
    }
   ],
   "source": [
    "chedict = {}\n",
    "listofchebi = []\n",
    "listofchemspider = []\n",
    "listofwikidata = []\n",
    "listofchembl = []\n",
    "listofdrugbank = []\n",
    "listofpubchem = []\n",
    "listoflipidmaps = []\n",
    "listofhmdb = []\n",
    "listofkegg = []\n",
    "listofcas = []\n",
    "listofinchikey = []\n",
    "listofcomptox = []\n",
    "\n",
    "for che in root.findall(aopxml + 'chemical'):\n",
    "    chedict[che.get('id')] = {}\n",
    "    if che.find(aopxml + 'casrn') is not None:\n",
    "        if 'NOCAS' not in che.find(aopxml + 'casrn').text:  # all NOCAS ids are taken out, so no issues as subjects\n",
    "            chedict[che.get('id')]['dc:identifier'] = 'cas:' + che.find(aopxml + 'casrn').text\n",
    "            listofcas.append('cas:' + che.find(aopxml + 'casrn').text)\n",
    "            chedict[che.get('id')]['cheminf:000446'] = '\"' + che.find(aopxml + 'casrn').text + '\"'\n",
    "            a = requests.get(bridgedb+'xrefs/Ca/'+che.find(aopxml + 'casrn').text).text.split('\\n')\n",
    "            dictionaryforchemical = {}\n",
    "            if 'html' not in a:\n",
    "                for item in a:\n",
    "                    b = item.split('\\t')\n",
    "                    if len(b) == 2:\n",
    "                        if b[1] not in dictionaryforchemical:\n",
    "                            dictionaryforchemical[b[1]] = []\n",
    "                            dictionaryforchemical[b[1]].append(b[0])\n",
    "                        else:\n",
    "                            dictionaryforchemical[b[1]].append(b[0])\n",
    "            if 'ChEBI' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000407'] = []\n",
    "                for chebi in dictionaryforchemical['ChEBI']:\n",
    "                    # Remove \"CHEBI:\" prefix if it exists\n",
    "                    formatted_chebi = \"chebi:\" + chebi.split(\"CHEBI:\")[-1]\n",
    "                    if formatted_chebi not in listofchebi:\n",
    "                        listofchebi.append(formatted_chebi)\n",
    "                    chedict[che.get('id')]['cheminf:000407'].append(formatted_chebi)\n",
    "            if 'Chemspider' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000405'] = []\n",
    "                for chemspider in dictionaryforchemical['Chemspider']:\n",
    "                    if \"chemspider:\"+chemspider not in listofchemspider:\n",
    "                        listofchemspider.append(\"chemspider:\"+chemspider)\n",
    "                    chedict[che.get('id')]['cheminf:000405'].append(\"chemspider:\"+chemspider)\n",
    "            if 'Wikidata' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000567'] = []\n",
    "                for wd in dictionaryforchemical['Wikidata']:\n",
    "                    if \"wikidata:\"+wd not in listofwikidata:\n",
    "                        listofwikidata.append(\"wikidata:\"+wd)\n",
    "                    chedict[che.get('id')]['cheminf:000567'].append(\"wikidata:\"+wd)\n",
    "            if 'ChEMBL compound' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000412'] = []\n",
    "                for chembl in dictionaryforchemical['ChEMBL compound']:\n",
    "                    if \"chembl.compound:\"+chembl not in listofchembl:\n",
    "                        listofchembl.append(\"chembl.compound:\"+chembl)\n",
    "                    chedict[che.get('id')]['cheminf:000412'].append(\"chembl.compound:\"+chembl)\n",
    "            if 'PubChem-compound' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000140'] = []\n",
    "                for pub in dictionaryforchemical['PubChem-compound']:\n",
    "                    if \"pubchem.compound:\"+pub not in listofpubchem:\n",
    "                        listofpubchem.append(\"pubchem.compound:\"+pub)\n",
    "                    chedict[che.get('id')]['cheminf:000140'].append(\"pubchem.compound:\"+pub)\n",
    "            if 'DrugBank' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000406'] = []\n",
    "                for drugbank in dictionaryforchemical['DrugBank']:\n",
    "                    if \"drugbank:\"+drugbank not in listofdrugbank:\n",
    "                        listofdrugbank.append(\"drugbank:\"+drugbank)\n",
    "                    chedict[che.get('id')]['cheminf:000406'].append(\"drugbank:\"+drugbank)\n",
    "            if 'KEGG Compound' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000409'] = []\n",
    "                for kegg in dictionaryforchemical['KEGG Compound']:\n",
    "                    if \"kegg.compound:\"+kegg not in listofkegg:\n",
    "                        listofkegg.append(\"kegg.compound:\"+kegg)\n",
    "                    chedict[che.get('id')]['cheminf:000409'].append(\"kegg.compound:\"+kegg)\n",
    "            if 'LIPID MAPS' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000564'] = []\n",
    "                for lipidmaps in dictionaryforchemical['LIPID MAPS']:\n",
    "                    if \"lipidmaps:\"+lipidmaps not in listoflipidmaps:\n",
    "                        listoflipidmaps.append(\"lipidmaps:\"+lipidmaps)\n",
    "                    chedict[che.get('id')]['cheminf:000564'].append(\"lipidmaps:\"+lipidmaps)\n",
    "            if 'HMDB' in dictionaryforchemical:\n",
    "                chedict[che.get('id')]['cheminf:000408'] = []\n",
    "                for hmdb in dictionaryforchemical['HMDB']:\n",
    "                    if \"hmdb:\"+hmdb not in listofhmdb:\n",
    "                        listofhmdb.append(\"hmdb:\"+hmdb)\n",
    "                    chedict[che.get('id')]['cheminf:000408'].append(\"hmdb:\"+hmdb)\n",
    "        else:\n",
    "            chedict[che.get('id')]['dc:identifier'] = '\"' + che.find(aopxml + 'casrn').text + '\"'\n",
    "    if che.find(aopxml + 'jchem-inchi-key') is not None:\n",
    "        chedict[che.get('id')]['cheminf:000059'] = 'inchikey:' + str(che.find(aopxml + 'jchem-inchi-key').text)\n",
    "        listofinchikey.append('inchikey:' + str(che.find(aopxml + 'jchem-inchi-key').text))\n",
    "    if che.find(aopxml + 'preferred-name') is not None:\n",
    "        chedict[che.get('id')]['dc:title'] = '\"' + che.find(aopxml + 'preferred-name').text + '\"'\n",
    "    if che.find(aopxml + 'dsstox-id') is not None:\n",
    "        chedict[che.get('id')]['cheminf:000568'] = 'comptox:' + che.find(aopxml + 'dsstox-id').text\n",
    "        listofcomptox.append('comptox:' + che.find(aopxml + 'dsstox-id').text)\n",
    "    if che.find(aopxml + 'synonyms') is not None:\n",
    "        chedict[che.get('id')]['dcterms:alternative'] = []\n",
    "        for synonym in che.find(aopxml + 'synonyms').findall(aopxml + 'synonym'):\n",
    "            chedict[che.get('id')]['dcterms:alternative'].append(synonym.text[:-1])\n",
    "print('Done!\\n\\nA total of ' + str(len(chedict)) + ' chemicals have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 719 Stressors have been parsed.\n"
     ]
    }
   ],
   "source": [
    "strdict = {}\n",
    "for stressor in root.findall(aopxml + 'stressor'):\n",
    "    strdict[stressor.get('id')] = {}\n",
    "    strdict[stressor.get('id')]['dc:identifier'] = 'aop.stressor:' + refs['Stressor'][stressor.get('id')]\n",
    "    strdict[stressor.get('id')]['rdfs:label'] = '\"Stressor ' + refs['Stressor'][stressor.get('id')] + '\"'\n",
    "    strdict[stressor.get('id')]['foaf:page'] = '<https://identifiers.org/aop.stressor/' + refs['Stressor'][stressor.get('id')] + '>'\n",
    "    strdict[stressor.get('id')]['dc:title'] = '\"' + stressor.find(aopxml + 'name').text + '\"'\n",
    "    if stressor.find(aopxml + 'description').text is not None:\n",
    "        strdict[stressor.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', stressor.find(aopxml + 'description').text) + '\"\"\"'\n",
    "    strdict[stressor.get('id')]['dcterms:created'] = stressor.find(aopxml + 'creation-timestamp').text\n",
    "    strdict[stressor.get('id')]['dcterms:modified'] = stressor.find(aopxml + 'last-modification-timestamp').text\n",
    "    strdict[stressor.get('id')]['aopo:has_chemical_entity'] = []\n",
    "    strdict[stressor.get('id')]['linktochemical'] = []\n",
    "    if stressor.find(aopxml + 'chemicals') is not None:\n",
    "        for chemical in stressor.find(aopxml + 'chemicals').findall(aopxml + 'chemical-initiator'):\n",
    "            strdict[stressor.get('id')]['aopo:has_chemical_entity'].append('\"' + chemical.get('user-term') + '\"')\n",
    "            strdict[stressor.get('id')]['linktochemical'].append(chemical.get('chemical-id'))\n",
    "print('Done!\\n\\nA total of ' + str(len(strdict)) + ' Stressors have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 282 taxonomies have been parsed.\n"
     ]
    }
   ],
   "source": [
    "taxdict = {}\n",
    "for tax in root.findall(aopxml + 'taxonomy'):\n",
    "    taxdict[tax.get('id')] = {}\n",
    "    taxdict[tax.get('id')]['dc:source'] = tax.find(aopxml + 'source').text\n",
    "    taxdict[tax.get('id')]['dc:title'] = tax.find(aopxml + 'name').text\n",
    "    if taxdict[tax.get('id')]['dc:source'] == 'NCBI':\n",
    "        taxdict[tax.get('id')]['dc:identifier'] = 'ncbitaxon:' + tax.find(aopxml + 'source-id').text\n",
    "    elif taxdict[tax.get('id')]['dc:source'] is not None:\n",
    "        taxdict[tax.get('id')]['dc:identifier'] = '\"' + tax.find(aopxml + 'source-id').text + '\"'\n",
    "    else:\n",
    "        taxdict[tax.get('id')]['dc:identifier'] = '\"' + tax.find(aopxml + 'source-id').text + '\"'\n",
    "print('Done!\\n\\nA total of ' + str(len(taxdict)) + ' taxonomies have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Event Components\n",
    "Which comprise of the Biological Actions, Biological Processes, Biological Objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "A total of 12 Biological Activity annotations have been parsed.\n"
     ]
    }
   ],
   "source": [
    "bioactdict = {None: {}}\n",
    "bioactdict[None]['dc:identifier'] = None\n",
    "bioactdict[None]['dc:source'] = None\n",
    "bioactdict[None]['dc:title'] = None\n",
    "for bioact in root.findall(aopxml + 'biological-action'):\n",
    "    bioactdict[bioact.get('id')] = {}\n",
    "    bioactdict[bioact.get('id')]['dc:source'] = '\"' + bioact.find(aopxml + 'source').text + '\"'\n",
    "    bioactdict[bioact.get('id')]['dc:title'] = '\"' + bioact.find(aopxml + 'name').text + '\"'\n",
    "    bioactdict[bioact.get('id')]['dc:identifier'] = '\"WIKI:' + bioact.find(aopxml + 'source-id').text + '\"'\n",
    "print('Done!\\nA total of ' + str(len(bioactdict)) + ' Biological Activity annotations have been parsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 526 Biological Process annotations have been parsed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize bioprodict with default values\n",
    "bioprodict = {\n",
    "    None: {\n",
    "        'dc:identifier': None,\n",
    "        'dc:source': None,\n",
    "        'dc:title': None\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mapping of source prefixes to their respective formats\n",
    "source_prefix_map = {\n",
    "    '\"GO\"': ('go:', 3),\n",
    "    '\"MI\"': ('mi:', 0),\n",
    "    '\"MP\"': ('mp:', 3),\n",
    "    '\"MESH\"': ('mesh:', 0),\n",
    "    '\"HP\"': ('hp:', 3),\n",
    "    '\"PCO\"': ('pco:', 4),\n",
    "    '\"NBO\"': ('nbo:', 4),\n",
    "    '\"VT\"': ('vt:', 3),\n",
    "    '\"RBO\"': ('rbo:', 4),\n",
    "    '\"NCI\"': ('nci:', 4),\n",
    "    '\"IDO\"': ('ido:', 4),\n",
    "}\n",
    "\n",
    "# Loop through biological processes and populate bioprodict\n",
    "for biopro in root.findall(aopxml + 'biological-process'):\n",
    "    biopro_id = biopro.get('id')\n",
    "    bioprodict[biopro_id] = {}\n",
    "\n",
    "    # Extract values\n",
    "    source = f'\"{biopro.find(aopxml + \"source\").text}\"'\n",
    "    name = f'\"{biopro.find(aopxml + \"name\").text}\"'\n",
    "    source_id = biopro.find(aopxml + 'source-id').text\n",
    "\n",
    "    # Populate source and title\n",
    "    bioprodict[biopro_id]['dc:source'] = source\n",
    "    bioprodict[biopro_id]['dc:title'] = name\n",
    "\n",
    "    # Handle identifier based on source prefix\n",
    "    if source in source_prefix_map:\n",
    "        prefix, offset = source_prefix_map[source]\n",
    "        identifier = prefix + source_id[offset:]\n",
    "        bioprodict[biopro_id]['dc:identifier'] = identifier\n",
    "    else:\n",
    "        # Default case for unhandled sources\n",
    "        bioprodict[biopro_id]['dc:identifier'] = source_id\n",
    "\n",
    "print(f\"Done!\\n\\nA total of {len(bioprodict)} Biological Process annotations have been parsed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 476 Biological Object annotations have been parsed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize bioobjdict with default values\n",
    "bioobjdict = {\n",
    "    None: {\n",
    "        'dc:identifier': None,\n",
    "        'dc:source': None,\n",
    "        'dc:title': None\n",
    "    }\n",
    "}\n",
    "objectstoskip = []\n",
    "prolist = []\n",
    "\n",
    "# Mapping of source prefixes to their respective formats\n",
    "source_prefix_map = {\n",
    "    '\"PR\"': ('pr:', 3),\n",
    "    '\"CL\"': ('cl:', 3),\n",
    "    '\"MESH\"': ('mesh:', 0),\n",
    "    '\"GO\"': ('go:', 3),\n",
    "    '\"UBERON\"': ('uberon:', 7),\n",
    "    '\"CHEBI\"': ('chebio:', 6),\n",
    "    '\"MP\"': ('mp:', 3),\n",
    "    '\"FMA\"': ('fma:', 4),\n",
    "    '\"PCO\"': ('pco:', 4),\n",
    "}\n",
    "\n",
    "# Loop through biological objects and populate bioobjdict\n",
    "for bioobj in root.findall(aopxml + 'biological-object'):\n",
    "    bioobj_id = bioobj.get('id')\n",
    "    bioobjdict[bioobj_id] = {}\n",
    "\n",
    "    # Extract values\n",
    "    source = f'\"{bioobj.find(aopxml + \"source\").text}\"'\n",
    "    name = f'\"{bioobj.find(aopxml + \"name\").text}\"'\n",
    "    source_id = bioobj.find(aopxml + 'source-id').text\n",
    "\n",
    "    # Populate source and title\n",
    "    bioobjdict[bioobj_id]['dc:source'] = source\n",
    "    bioobjdict[bioobj_id]['dc:title'] = name\n",
    "\n",
    "    # Handle identifier based on source prefix\n",
    "    if source in source_prefix_map:\n",
    "        prefix, offset = source_prefix_map[source]\n",
    "        identifier = prefix + source_id[offset:]\n",
    "        bioobjdict[bioobj_id]['dc:identifier'] = identifier\n",
    "\n",
    "        # Add to prolist if PR\n",
    "        if source == '\"PR\"':\n",
    "            prolist.append(identifier)\n",
    "    else:\n",
    "        # Default case for unhandled sources\n",
    "        bioobjdict[bioobj_id]['dc:identifier'] = f'\"{source_id}\"'\n",
    "\n",
    "print(f\"Done!\\n\\nA total of {len(bioobjdict)} Biological Object annotations have been parsed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Biological Objects containing terms from the Protein Ontology are mapped to protein identifiers with the PR mapping file `promapping.txt`, which was downloaded from the [Protein Consortium website](https://proconsortium.org/download/current/), which provides matching identifiers from Entrez Gene, HGNC and UniProt. The file location should be the `filepath` variable defined in Step #2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/promapping.txt', <http.client.HTTPMessage at 0x797aca17d580>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro = \"promapping.txt\"\n",
    "urllib.request.urlretrieve('https://proconsortium.org/download/current/promapping.txt', 'data/promapping.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Modified Time :  Wed Feb 12 14:30:01 2025\n"
     ]
    }
   ],
   "source": [
    "fileStatsObj = os.stat (filepath + pro)\n",
    "PromodificationTime = time.ctime ( fileStatsObj [ stat.ST_MTIME ] )\n",
    "print(\"Last Modified Time : \", PromodificationTime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This step added 709 identifiers for 150 Protein Ontology terms\n"
     ]
    }
   ],
   "source": [
    "f = open(filepath+pro, \"r\")\n",
    "prodict = {}\n",
    "hgnclist = []\n",
    "uniprotlist = []\n",
    "ncbigenelist = []\n",
    "for line in f:\n",
    "    a = line.split('\\t')\n",
    "    key = 'pr:'+a[0][3:]\n",
    "    if key in prolist:\n",
    "        if not key in prodict:\n",
    "            prodict[key] = []\n",
    "        if 'HGNC:' in a[1]:\n",
    "            prodict[key].append('hgnc:'+a[1][5:])\n",
    "            hgnclist.append('hgnc:'+a[1][5:])\n",
    "        if 'NCBIGene:' in a[1]:\n",
    "            prodict[key].append('ncbigene:'+a[1][9:])\n",
    "            ncbigenelist.append('ncbigene:'+a[1][9:])\n",
    "        if 'UniProtKB:' in a[1]:\n",
    "            prodict[key].append('uniprot:'+a[1].split(',')[0][10:])\n",
    "            uniprotlist.append('uniprot:'+a[1].split(',')[0][10:])\n",
    "        if prodict[key]==[]:\n",
    "            del prodict[key]\n",
    "f.close()\n",
    "print('This step added ' + str(len(hgnclist)+len(ncbigenelist)+len(uniprotlist)) + ' identifiers for ' + str(len(prodict)) + ' Protein Ontology terms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Events\n",
    "The KEs also include the entities for cell-terms and organ-terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 1497 Key Events have been parsed.\n"
     ]
    }
   ],
   "source": [
    "listofkedescriptions = []\n",
    "for ke in root.findall(aopxml + 'key-event'):\n",
    "    if not ke.get('id') in kedict:\n",
    "        kedict[ke.get('id')] = {}\n",
    "    kedict[ke.get('id')]['dc:identifier'] = 'aop.events:' + refs['KE'][ke.get('id')]\n",
    "    kedict[ke.get('id')]['rdfs:label'] = '\"KE ' + refs['KE'][ke.get('id')] + '\"'\n",
    "    kedict[ke.get('id')]['foaf:page'] = '<https://identifiers.org/aop.events/' + refs['KE'][ke.get('id')] + '>'\n",
    "    kedict[ke.get('id')]['dc:title'] = '\"' + ke.find(aopxml + 'title').text + '\"'\n",
    "    kedict[ke.get('id')]['dcterms:alternative'] = ke.find(aopxml + 'short-name').text\n",
    "    kedict[ke.get('id')]['nci:C25664'] = '\"\"\"' + ke.find(aopxml + 'biological-organization-level').text + '\"\"\"'\n",
    "    if ke.find(aopxml + 'description').text is not None:\n",
    "        kedict[ke.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', ke.find(aopxml + 'description').text) + '\"\"\"'\n",
    "#    if ke.find(aopxml + 'evidence-supporting-taxonomic-applicability').text is not None:\n",
    "#        kedict[ke.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', ke.find(aopxml + 'evidence-supporting-taxonomic-applicability').text) + '\"\"\"'\n",
    "    if ke.find(aopxml + 'measurement-methodology').text is not None:\n",
    "        kedict[ke.get('id')]['mmo:0000000'] = '\"\"\"' + TAG_RE.sub('', ke.find(aopxml + 'measurement-methodology').text) + '\"\"\"'\n",
    "    kedict[ke.get('id')]['biological-organization-level'] = ke.find(aopxml + 'biological-organization-level').text\n",
    "    kedict[ke.get('id')]['dc:source'] = ke.find(aopxml + 'source').text\n",
    "    for appl in ke.findall(aopxml + 'applicability'):\n",
    "        for sex in appl.findall(aopxml + 'sex'):\n",
    "            if 'pato:0000047' not in kedict[ke.get('id')]:\n",
    "                kedict[ke.get('id')]['pato:0000047'] = [[sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text]]\n",
    "            else:\n",
    "                kedict[ke.get('id')]['pato:0000047'].append([sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text])\n",
    "        for life in appl.findall(aopxml + 'life-stage'):\n",
    "            if 'aopo:LifeStageContext' not in kedict[ke.get('id')]:\n",
    "                kedict[ke.get('id')]['aopo:LifeStageContext'] = [[life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text]]\n",
    "            else:\n",
    "                kedict[ke.get('id')]['aopo:LifeStageContext'].append([life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text])\n",
    "        for tax in appl.findall(aopxml + 'taxonomy'):\n",
    "            if 'ncbitaxon:131567' not in kedict[ke.get('id')]:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kedict[ke.get('id')]['ncbitaxon:131567'] = [[tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']]]\n",
    "            else:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kedict[ke.get('id')]['ncbitaxon:131567'].append([tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']])\n",
    "    if ke.find(aopxml + 'biological-events') is not None:\n",
    "        kedict[ke.get('id')]['biological-event'] = {}\n",
    "        kedict[ke.get('id')]['biological-event']['go:0008150'] = []\n",
    "        kedict[ke.get('id')]['biological-event']['pato:0001241'] = []\n",
    "        kedict[ke.get('id')]['biological-event']['pato:0000001'] = []\n",
    "        for event in ke.find(aopxml + 'biological-events').findall(aopxml + 'biological-event'):\n",
    "            if event.get('process-id') is not None:\n",
    "                kedict[ke.get('id')]['biological-event']['go:0008150'].append(bioprodict[event.get('process-id')]['dc:identifier'])\n",
    "            if event.get('object-id') is not None:\n",
    "                kedict[ke.get('id')]['biological-event']['pato:0001241'].append(bioobjdict[event.get('object-id')]['dc:identifier'])\n",
    "            if event.get('action-id') is not None:\n",
    "                kedict[ke.get('id')]['biological-event']['pato:0000001'].append(bioactdict[event.get('action-id')]['dc:identifier'])\n",
    "    if ke.find(aopxml + 'cell-term') is not None:\n",
    "        kedict[ke.get('id')]['aopo:CellTypeContext'] = {}\n",
    "        kedict[ke.get('id')]['aopo:CellTypeContext']['dc:source'] = '\"' + ke.find(aopxml + 'cell-term').find(aopxml + 'source').text + '\"'\n",
    "        kedict[ke.get('id')]['aopo:CellTypeContext']['dc:title'] = '\"' + ke.find(aopxml + 'cell-term').find(aopxml + 'name').text + '\"'\n",
    "        if kedict[ke.get('id')]['aopo:CellTypeContext']['dc:source'] == '\"CL\"':\n",
    "            kedict[ke.get('id')]['aopo:CellTypeContext']['dc:identifier'] = ['cl:' + ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text[3:], ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text]\n",
    "        elif kedict[ke.get('id')]['aopo:CellTypeContext']['dc:source'] == '\"UBERON\"':\n",
    "            kedict[ke.get('id')]['aopo:CellTypeContext']['dc:identifier'] = ['uberon:' + ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text[7:], ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text]\n",
    "        else:\n",
    "            kedict[ke.get('id')]['aopo:CellTypeContext']['dc:identifier'] = ['\"' + ke.find(aopxml + 'cell-term').find(aopxml + 'source-id').text + '\"', 'placeholder']\n",
    "    if ke.find(aopxml + 'organ-term') is not None:\n",
    "        kedict[ke.get('id')]['aopo:OrganContext'] = {}\n",
    "        kedict[ke.get('id')]['aopo:OrganContext']['dc:source'] = '\"' + ke.find(aopxml + 'organ-term').find(aopxml + 'source').text + '\"'\n",
    "        kedict[ke.get('id')]['aopo:OrganContext']['dc:title'] = '\"' + ke.find(aopxml + 'organ-term').find(aopxml + 'name').text + '\"'\n",
    "        if kedict[ke.get('id')]['aopo:OrganContext']['dc:source'] == '\"UBERON\"':\n",
    "            kedict[ke.get('id')]['aopo:OrganContext']['dc:identifier'] = ['uberon:' + ke.find(aopxml + 'organ-term').find(aopxml + 'source-id').text[7:], ke.find(aopxml + 'organ-term').find(aopxml + 'source-id').text]\n",
    "        else:\n",
    "            kedict[ke.get('id')]['aopo:OrganContext']['dc:identifier'] = [\n",
    "                '\"' + ke.find(aopxml + 'organ-term').find(aopxml + 'source-id').text + '\"', 'placeholder']\n",
    "    if ke.find(aopxml + 'key-event-stressors') is not None:\n",
    "        kedict[ke.get('id')]['nci:C54571'] = {}\n",
    "        for stressor in ke.find(aopxml + 'key-event-stressors').findall(aopxml + 'key-event-stressor'):\n",
    "            kedict[ke.get('id')]['nci:C54571'][stressor.get('stressor-id')] = {}\n",
    "            kedict[ke.get('id')]['nci:C54571'][stressor.get('stressor-id')]['dc:identifier'] = strdict[stressor.get('stressor-id')]['dc:identifier']\n",
    "            kedict[ke.get('id')]['nci:C54571'][stressor.get('stressor-id')]['aopo:has_evidence'] = stressor.find(aopxml + 'evidence').text\n",
    "print('Done!\\n\\nA total of ' + str(len(kedict)) + ' Key Events have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Event Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "A total of 2123 Key Event Relationships have been parsed.\n"
     ]
    }
   ],
   "source": [
    "kerdict = {}\n",
    "for ker in root.findall(aopxml + 'key-event-relationship'):\n",
    "    kerdict[ker.get('id')] = {}\n",
    "    kerdict[ker.get('id')]['dc:identifier'] = 'aop.relationships:' + refs['KER'][ker.get('id')]\n",
    "    kerdict[ker.get('id')]['rdfs:label'] = '\"KER ' + refs['KER'][ker.get('id')] + '\"'\n",
    "    kerdict[ker.get('id')]['foaf:page'] = '<https://identifiers.org/aop.relationships/' + refs['KER'][ker.get('id')] + '>'\n",
    "    kerdict[ker.get('id')]['dc:source'] = ker.find(aopxml + 'source').text\n",
    "    kerdict[ker.get('id')]['dcterms:created'] = ker.find(aopxml + 'creation-timestamp').text\n",
    "    kerdict[ker.get('id')]['dcterms:modified'] = ker.find(aopxml + 'last-modification-timestamp').text\n",
    "    if ker.find(aopxml + 'description').text is not None:\n",
    "        kerdict[ker.get('id')]['dc:description'] = '\"\"\"' + TAG_RE.sub('', ker.find(aopxml + 'description').text) + '\"\"\"'\n",
    "    for weight in ker.findall(aopxml + 'weight-of-evidence'):\n",
    "        if weight.find(aopxml + 'biological-plausibility').text is not None:\n",
    "            kerdict[ker.get('id')]['nci:C80263'] = '\"\"\"' + TAG_RE.sub('', weight.find(aopxml + 'biological-plausibility').text) + '\"\"\"'\n",
    "        if weight.find(aopxml + 'emperical-support-linkage').text is not None:\n",
    "            kerdict[ker.get('id')]['edam:data_2042'] = '\"\"\"' + TAG_RE.sub('', weight.find(aopxml + 'emperical-support-linkage').text) + '\"\"\"'\n",
    "        if weight.find(aopxml + 'uncertainties-or-inconsistencies').text is not None:\n",
    "            kerdict[ker.get('id')]['nci:C71478'] = '\"\"\"' + TAG_RE.sub('', weight.find(aopxml + 'uncertainties-or-inconsistencies').text) + '\"\"\"'\n",
    "    kerdict[ker.get('id')]['aopo:has_upstream_key_event'] = {}\n",
    "    kerdict[ker.get('id')]['aopo:has_upstream_key_event']['id'] = ker.find(aopxml + 'title').find(aopxml + 'upstream-id').text\n",
    "    kerdict[ker.get('id')]['aopo:has_upstream_key_event']['dc:identifier'] = 'aop.events:' + refs['KE'][ker.find(aopxml + 'title').find(aopxml + 'upstream-id').text]\n",
    "    kerdict[ker.get('id')]['aopo:has_downstream_key_event'] = {}\n",
    "    kerdict[ker.get('id')]['aopo:has_downstream_key_event']['id'] = ker.find(aopxml + 'title').find(aopxml + 'downstream-id').text\n",
    "    kerdict[ker.get('id')]['aopo:has_downstream_key_event']['dc:identifier'] = 'aop.events:' + refs['KE'][ker.find(aopxml + 'title').find(aopxml + 'downstream-id').text]\n",
    "    for appl in ker.findall(aopxml + 'taxonomic-applicability'):\n",
    "        for sex in appl.findall(aopxml + 'sex'):\n",
    "            if 'pato:0000047' not in kerdict[ker.get('id')]:\n",
    "                kerdict[ker.get('id')]['pato:0000047'] = [[sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text]]\n",
    "            else:\n",
    "                kerdict[ker.get('id')]['pato:0000047'].append([sex.find(aopxml + 'evidence').text, sex.find(aopxml + 'sex').text])\n",
    "        for life in appl.findall(aopxml + 'life-stage'):\n",
    "            if 'aopo:LifeStageContext' not in kerdict[ker.get('id')]:\n",
    "                kerdict[ker.get('id')]['aopo:LifeStageContext'] = [[life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text]]\n",
    "            else:\n",
    "                kerdict[ker.get('id')]['aopo:LifeStageContext'].append([life.find(aopxml + 'evidence').text, life.find(aopxml + 'life-stage').text])\n",
    "        for tax in appl.findall(aopxml + 'taxonomy'):\n",
    "            if 'ncbitaxon:131567' not in kerdict[ker.get('id')]:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kerdict[ker.get('id')]['ncbitaxon:131567'] = [[tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']]]\n",
    "            else:\n",
    "                if 'dc:identifier' in taxdict[tax.get('taxonomy-id')]:\n",
    "                    kerdict[ker.get('id')]['ncbitaxon:131567'].append([tax.get('taxonomy-id'), tax.find(aopxml + 'evidence').text, taxdict[tax.get('taxonomy-id')]['dc:identifier'], taxdict[tax.get('taxonomy-id')]['dc:source'], taxdict[tax.get('taxonomy-id')]['dc:title']])\n",
    "print('Done!\\n\\nA total of ' + str(len(kerdict)) + ' Key Event Relationships have been parsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #4: Writing the AOP-Wiki RDF</b>\n",
    "This step involves the writing of the central RDF file, containing all information from the AOP-Wiki XML, written in Turtle (ttl) syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open(filepath + 'AOPWikiRDF.ttl', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing prefixes\n",
    "The first thing is writing the Prefixes of all ontologies and database identifiers, which go in the top of the document. That is followed by the writing of all entities of the AOP-Wiki described in Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n",
      "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix aop: <https://identifiers.org/aop/> .\n",
      "@prefix aop.events: <https://identifiers.org/aop.events/> .\n",
      "@prefix aop.relationships: <https://identifiers.org/aop.relationships/> .\n",
      "@prefix aop.stressor: <https://identifiers.org/aop.stressor/> .\n",
      "@prefix aopo: <http://aopkb.org/aop_ontology#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix cas: <https://identifiers.org/cas/> .\n",
      "@prefix inchikey: <https://identifiers.org/inchikey/> .\n",
      "@prefix pato: <http://purl.obolibrary.org/obo/PATO_> .\n",
      "@prefix ncbitaxon: <http://purl.bioontology.org/ontology/NCBITAXON/> .\n",
      "@prefix cl: <http://purl.obolibrary.org/obo/CL_> .\n",
      "@prefix uberon: <http://purl.obolibrary.org/obo/UBERON_> .\n",
      "@prefix go: <http://purl.obolibrary.org/obo/GO_> .\n",
      "@prefix mi: <http://purl.obolibrary.org/obo/MI_> .\n",
      "@prefix mp: <http://purl.obolibrary.org/obo/MP_> .\n",
      "@prefix mesh: <http://purl.org/commons/record/mesh/> .\n",
      "@prefix hp: <http://purl.obolibrary.org/obo/HP_> .\n",
      "@prefix pco: <http://purl.obolibrary.org/obo/PCO_> .\n",
      "@prefix nbo: <http://purl.obolibrary.org/obo/NBO_> .\n",
      "@prefix vt: <http://purl.obolibrary.org/obo/VT_> .\n",
      "@prefix pr: <http://purl.obolibrary.org/obo/PR_> .\n",
      "@prefix chebio: <http://purl.obolibrary.org/obo/CHEBI_> .\n",
      "@prefix fma: <http://purl.org/sig/ont/fma/fma> .\n",
      "@prefix cheminf: <http://semanticscience.org/resource/CHEMINF_> .\n",
      "@prefix nci: <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#> .\n",
      "@prefix comptox: <https://identifiers.org/comptox/> .\n",
      "@prefix mmo: <http://purl.obolibrary.org/obo/MMO_> .\n",
      "@prefix chebi: <https://identifiers.org/chebi/> .\n",
      "@prefix chemspider: <https://identifiers.org/chemspider/> .\n",
      "@prefix wikidata: <https://identifiers.org/wikidata/> .\n",
      "@prefix chembl.compound: <https://identifiers.org/chembl.compound/> .\n",
      "@prefix pubchem.compound: <https://identifiers.org/pubchem.compound/> .\n",
      "@prefix drugbank: <https://identifiers.org/drugbank/> .\n",
      "@prefix kegg.compound: <https://identifiers.org/kegg.compound/> .\n",
      "@prefix lipidmaps: <https://identifiers.org/lipidmaps/> .\n",
      "@prefix hmdb: <https://identifiers.org/hmdb/> .\n",
      "@prefix ensembl: <https://identifiers.org/ensembl/> .\n",
      "@prefix edam: <http://edamontology.org/> .\n",
      "@prefix hgnc: <https://identifiers.org/hgnc/> .\n",
      "@prefix ncbigene: <https://identifiers.org/ncbigene/> .\n",
      "@prefix uniprot: <https://identifiers.org/uniprot/> .\n",
      "@prefix rbo: <http://purl.obolibrary.org/obo/RBO_> .\n",
      "@prefix ido: <http://purl.obolibrary.org/obo/IDO_> .\n"
     ]
    }
   ],
   "source": [
    "# Load the prefixes from a CSV file\n",
    "prefixes = pd.read_csv(\"prefixes.csv\")\n",
    "\n",
    "# Format the prefixes as RDF-compatible strings\n",
    "prefix_strings = prefixes.apply(lambda row: f\"@prefix {row['prefix']}: <{row['uri']}> .\", axis=1)\n",
    "\n",
    "# Join the strings with newlines\n",
    "rdf_prefixes = \"\\n\".join(prefix_strings)\n",
    "print(rdf_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.write(rdf_prefixes + \"\\n\")\n",
    "#g.write('@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix dcterms: <http://purl.org/dc/terms/> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix owl: <http://www.w3.org/2002/07/owl#> .\\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\\n@prefix aop: <https://identifiers.org/aop/> .\\n@prefix aop.events: <https://identifiers.org/aop.events/> .\\n@prefix aop.relationships: <https://identifiers.org/aop.relationships/> .\\n@prefix aop.stressor: <https://identifiers.org/aop.stressor/> .\\n@prefix aopo: <http://aopkb.org/aop_ontology#> .\\n@prefix skos: <http://www.w3.org/2004/02/skos/core#> . \\n@prefix cas: <https://identifiers.org/cas/> .\\n@prefix inchikey: <https://identifiers.org/inchikey/> .\\n@prefix pato: <http://purl.obolibrary.org/obo/PATO_> .\\n@prefix ncbitaxon: <http://purl.bioontology.org/ontology/NCBITAXON/> .\\n@prefix cl: <http://purl.obolibrary.org/obo/CL_> .\\n@prefix uberon: <http://purl.obolibrary.org/obo/UBERON_> .\\n@prefix go: <http://purl.obolibrary.org/obo/GO_> .\\n@prefix mi: <http://purl.obolibrary.org/obo/MI_> .\\n@prefix mp: <http://purl.obolibrary.org/obo/MP_> .\\n@prefix mesh: <http://purl.org/commons/record/mesh/> .\\n@prefix hp: <http://purl.obolibrary.org/obo/HP_> .\\n@prefix pco: <http://purl.obolibrary.org/obo/PCO_> .\\n@prefix nbo: <http://purl.obolibrary.org/obo/NBO_> .\\n@prefix vt: <http://purl.obolibrary.org/obo/VT_> .\\n@prefix pr: <http://purl.obolibrary.org/obo/PR_> .\\n@prefix chebio: <http://purl.obolibrary.org/obo/CHEBI_> .\\n@prefix fma: <http://purl.org/sig/ont/fma/fma> .\\n@prefix cheminf: <http://semanticscience.org/resource/CHEMINF_> .\\n@prefix nci: <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#> .\\n@prefix comptox: <https://identifiers.org/comptox/> .\\n@prefix mmo: <http://purl.obolibrary.org/obo/MMO_> .\\n@prefix chebi: <https://identifiers.org/chebi/> .\\n@prefix chemspider: <https://identifiers.org/chemspider/> .\\n@prefix wikidata: <https://identifiers.org/wikidata/> .\\n@prefix chembl.compound: <https://identifiers.org/chembl.compound/> .\\n@prefix pubchem.compound: <https://identifiers.org/pubchem.compound/> .\\n@prefix drugbank: <https://identifiers.org/drugbank/> .\\n@prefix kegg.compound: <https://identifiers.org/kegg.compound/> .\\n@prefix lipidmaps: <https://identifiers.org/lipidmaps/> .\\n@prefix hmdb: <https://identifiers.org/hmdb/> .\\n@prefix ensembl: <https://identifiers.org/ensembl/> .\\n@prefix edam: <http://edamontology.org/> .\\n@prefix hgnc: <https://identifiers.org/hgnc/>.\\n@prefix ncbigene: <https://identifiers.org/ncbigene/>.\\n@prefix uniprot: <https://identifiers.org/uniprot/>.\\n@prefix rbo: <http://purl.obolibrary.org/obo/RBO_>.\\n@prefix ido: <http://purl.obolibrary.org/obo/IDO_>.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Adverse Outcome Pathway triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for aop in aopdict:\n",
    "    g.write(aopdict[aop]['dc:identifier'] + '\\n\\ta\\taopo:AdverseOutcomePathway ;\\n\\tdc:identifier\\t' + aopdict[aop]['dc:identifier'] + ' ;\\n\\trdfs:label\\t' + aopdict[aop]['rdfs:label'] + ' ;\\n\\trdfs:seeAlso\\t' + aopdict[aop]['foaf:page'] + ' ;\\n\\tfoaf:page\\t' + aopdict[aop]['foaf:page'] + ' ;\\n\\tdc:title\\t' + aopdict[aop]['dc:title'] + ' ;\\n\\tdcterms:alternative\\t\"' + aopdict[aop]['dcterms:alternative'] + '\" ;\\n\\tdc:source\\t\"' + aopdict[aop]['dc:source'] + '\" ;\\n\\tdcterms:created\\t\"' + aopdict[aop]['dcterms:created'] + '\" ;\\n\\tdcterms:modified\\t\"' + aopdict[aop]['dcterms:modified'] + '\"')\n",
    "    if 'dc:description' in aopdict[aop]:\n",
    "        if not aopdict[aop]['dc:description'] == []:\n",
    "            g.write(' ;\\n\\tdc:description\\t' + ','.join(aopdict[aop]['dc:description']))\n",
    "    if 'nci:C25217' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tnci:C25217\\t' + aopdict[aop]['nci:C25217'])\n",
    "    if 'nci:C48192' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tnci:C48192\\t' + aopdict[aop]['nci:C48192'])\n",
    "    if 'aopo:AopContext' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\taopo:AopContext\\t' + aopdict[aop]['aopo:AopContext'])\n",
    "    if 'aopo:has_evidence' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\taopo:has_evidence\\t' + aopdict[aop]['aopo:has_evidence'])\n",
    "    if 'edam:operation_3799' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tedam:operation_3799\\t' + aopdict[aop]['edam:operation_3799'])\n",
    "    if 'nci:C25725' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tnci:C25725\\t' + aopdict[aop]['nci:C25725'])\n",
    "    if 'dc:creator' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tdc:creator\\t' + aopdict[aop]['dc:creator'])\n",
    "    if 'dcterms:accessRights' in aopdict[aop]:\n",
    "         g.write(' ;\\n\\tdcterms:accessRights\\t' + aopdict[aop]['dcterms:accessRights'])\n",
    "    if 'oecd-status' in aopdict[aop]:\n",
    "         g.write(' ;\\n\\tnci:C25688\\t' + aopdict[aop]['oecd-status'])\n",
    "    if 'saaop-status' in aopdict[aop]:\n",
    "         g.write(' ;\\n\\tnci:C25688\\t' + aopdict[aop]['saaop-status'])\n",
    "    if 'dcterms:abstract' in aopdict[aop]:\n",
    "        g.write(' ;\\n\\tdcterms:abstract\\t' + aopdict[aop]['dcterms:abstract'])\n",
    "    listofthings = []\n",
    "    for KE in aopdict[aop]['aopo:has_key_event']:\n",
    "        listofthings.append(aopdict[aop]['aopo:has_key_event'][KE]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\taopo:has_key_event\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    for KER in aopdict[aop]['aopo:has_key_event_relationship']:\n",
    "        listofthings.append(aopdict[aop]['aopo:has_key_event_relationship'][KER]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\taopo:has_key_event_relationship\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    for mie in aopdict[aop]['aopo:has_molecular_initiating_event']:\n",
    "        listofthings.append(aopdict[aop]['aopo:has_molecular_initiating_event'][mie]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\taopo:has_molecular_initiating_event\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    for ao in aopdict[aop]['aopo:has_adverse_outcome']:\n",
    "        listofthings.append(aopdict[aop]['aopo:has_adverse_outcome'][ao]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\taopo:has_adverse_outcome\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    for stressor in aopdict[aop]['nci:C54571']:\n",
    "        listofthings.append(aopdict[aop]['nci:C54571'][stressor]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\tnci:C54571\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'pato:0000047' in aopdict[aop]:\n",
    "        for sex in aopdict[aop]['pato:0000047']:\n",
    "            listofthings.append('\"' + sex[1] + '\"')\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tpato:0000047\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'aopo:LifeStageContext' in aopdict[aop]:\n",
    "        for lifestage in aopdict[aop]['aopo:LifeStageContext']:\n",
    "            listofthings.append('\"' + lifestage[1] + '\"')\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\taopo:LifeStageContext\\t' + (','.join(listofthings)))\n",
    "    g.write(' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event triples\n",
    "This step also includes the extraction of the cell-terms and organ-terms, which are written to the file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cterm = {}\n",
    "oterm = {}\n",
    "for ke in kedict:\n",
    "    g.write(kedict[ke]['dc:identifier'] + '\\n\\ta\\taopo:KeyEvent ;\\n\\tdc:identifier\\t' + kedict[ke]['dc:identifier'] + ' ;\\n\\trdfs:label\\t' + kedict[ke]['rdfs:label'] + ' ;\\n\\tfoaf:page\\t' + kedict[ke]['foaf:page'] + ' ;\\n\\trdfs:seeAlso\\t' + kedict[ke]['foaf:page'] + ' ;\\n\\tdc:title\\t' + kedict[ke]['dc:title'] + ' ;\\n\\tdcterms:alternative\\t\"' + kedict[ke]['dcterms:alternative'] + '\" ;\\n\\tdc:source\\t\"' + kedict[ke]['dc:source'] + '\"')\n",
    "    if 'dc:description' in kedict[ke]:\n",
    "        g.write(' ;\\n\\tdc:description\\t' + kedict[ke]['dc:description'])\n",
    "    if 'mmo:0000000' in kedict[ke]:\n",
    "        g.write(' ;\\n\\tmmo:0000000\\t' + kedict[ke]['mmo:0000000'])\n",
    "    if 'nci:C25664' in kedict[ke]:\n",
    "        g.write(' ;\\n\\tnci:C25664\\t' + kedict[ke]['nci:C25664'])\n",
    "    listofthings = []\n",
    "    if 'pato:0000047' in kedict[ke]:\n",
    "        for sex in kedict[ke]['pato:0000047']:\n",
    "            listofthings.append('\"' + sex[1] + '\"')\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tpato:0000047\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'aopo:LifeStageContext' in kedict[ke]:\n",
    "        for lifestage in kedict[ke]['aopo:LifeStageContext']:\n",
    "            listofthings.append('\"' + lifestage[1] + '\"')\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\taopo:LifeStageContext\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'ncbitaxon:131567' in kedict[ke]:\n",
    "        for taxonomy in kedict[ke]['ncbitaxon:131567']:\n",
    "            listofthings.append(taxonomy[2])\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tncbitaxon:131567\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'nci:C54571' in kedict[ke]:\n",
    "        for stressor in kedict[ke]['nci:C54571']:\n",
    "            listofthings.append(kedict[ke]['nci:C54571'][stressor]['dc:identifier'])\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tnci:C54571\\t' + (','.join(listofthings)))\n",
    "    if 'aopo:CellTypeContext' in kedict[ke]:\n",
    "        g.write(' ;\\n\\taopo:CellTypeContext\\t' + kedict[ke]['aopo:CellTypeContext']['dc:identifier'][0])\n",
    "        if not kedict[ke]['aopo:CellTypeContext']['dc:identifier'][0] in cterm:\n",
    "            cterm[kedict[ke]['aopo:CellTypeContext']['dc:identifier'][0]] = {}\n",
    "            cterm[kedict[ke]['aopo:CellTypeContext']['dc:identifier'][0]]['dc:source'] = kedict[ke]['aopo:CellTypeContext']['dc:source']\n",
    "            cterm[kedict[ke]['aopo:CellTypeContext']['dc:identifier'][0]]['dc:title'] = kedict[ke]['aopo:CellTypeContext']['dc:title']\n",
    "    if 'aopo:OrganContext' in kedict[ke]:\n",
    "        g.write(' ;\\n\\taopo:OrganContext\\t' + kedict[ke]['aopo:OrganContext']['dc:identifier'][0])\n",
    "        if not kedict[ke]['aopo:OrganContext']['dc:identifier'][0] in oterm:\n",
    "            oterm[kedict[ke]['aopo:OrganContext']['dc:identifier'][0]] = {}\n",
    "            oterm[kedict[ke]['aopo:OrganContext']['dc:identifier'][0]]['dc:source'] = kedict[ke]['aopo:OrganContext']['dc:source']\n",
    "            oterm[kedict[ke]['aopo:OrganContext']['dc:identifier'][0]]['dc:title'] = kedict[ke]['aopo:OrganContext']['dc:title']\n",
    "    if 'biological-event' in kedict[ke]:\n",
    "        if len(kedict[ke]['biological-event']['go:0008150']) > 0:\n",
    "            g.write(' ;\\n\\tgo:0008150\\t' + (','.join(kedict[ke]['biological-event']['go:0008150'])))\n",
    "        if len(kedict[ke]['biological-event']['pato:0000001']) > 0:\n",
    "            g.write(' ;\\n\\tpato:0000001\\t' + (','.join(kedict[ke]['biological-event']['pato:0000001'])))\n",
    "        if len(kedict[ke]['biological-event']['pato:0001241']) > 0:\n",
    "            g.write(' ;\\n\\tpato:0001241\\t' + (','.join(kedict[ke]['biological-event']['pato:0001241'])))\n",
    "    listofthings = []\n",
    "    for aop in aopdict:\n",
    "        if ke in aopdict[aop]['aopo:has_key_event']:\n",
    "            listofthings.append(aopdict[aop]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\tdcterms:isPartOf\\t' + (','.join(listofthings)))\n",
    "    g.write(' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event Relationship triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for ker in kerdict:\n",
    "    g.write(kerdict[ker]['dc:identifier'] + '\\n\\ta\\taopo:KeyEventRelationship ;\\n\\tdc:identifier\\t' + kerdict[ker]['dc:identifier'] + ' ;\\n\\trdfs:label\\t' + kerdict[ker]['rdfs:label'] + ' ;\\n\\tfoaf:page\\t' + kerdict[ker]['foaf:page'] + ' ;\\n\\trdfs:seeAlso\\t' + kerdict[ker]['foaf:page'] + ' ;\\n\\tdcterms:created\\t\"' + kerdict[ker]['dcterms:created'] + '\" ;\\n\\tdcterms:modified\\t\"' + kerdict[ker]['dcterms:modified'] + '\" ;\\n\\taopo:has_upstream_key_event\\t' + kerdict[ker]['aopo:has_upstream_key_event']['dc:identifier'] + ' ;\\n\\taopo:has_downstream_key_event\\t' + kerdict[ker]['aopo:has_downstream_key_event']['dc:identifier'])\n",
    "    if 'dc:description' in kerdict[ker]:\n",
    "        g.write(' ;\\n\\tdc:description\\t' + kerdict[ker]['dc:description'])\n",
    "    if 'nci:C80263' in kerdict[ker]:\n",
    "        g.write(' ;\\n\\tnci:C80263\\t' + kerdict[ker]['nci:C80263'])\n",
    "    if 'edam:data_2042' in kerdict[ker]:\n",
    "        g.write(' ;\\n\\tedam:data_2042\\t' + kerdict[ker]['edam:data_2042'].replace(\"\\\\\", \"\"))\n",
    "    if 'nci:C71478' in kerdict[ker]:\n",
    "        g.write(' ;\\n\\tnci:C71478\\t' + kerdict[ker]['nci:C71478'].replace(\"\\\\\", \"\"))\n",
    "    listofthings = []\n",
    "    if 'pato:0000047' in kerdict[ker]:\n",
    "        for sex in kerdict[ker]['pato:0000047']:\n",
    "            listofthings.append('\"' + sex[1] + '\"')\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tpato:0000047\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'aopo:LifeStageContext' in kerdict[ker]:\n",
    "        for lifestage in kerdict[ker]['aopo:LifeStageContext']:\n",
    "            listofthings.append('\"' + lifestage[1] + '\"')\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\taopo:LifeStageContext\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    if 'ncbitaxon:131567' in kerdict[ker]:\n",
    "        for taxonomy in kerdict[ker]['ncbitaxon:131567']:\n",
    "            listofthings.append(taxonomy[2])\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tncbitaxon:131567\\t' + (','.join(listofthings)))\n",
    "    listofthings = []\n",
    "    for aop in aopdict:\n",
    "        if ker in aopdict[aop]['aopo:has_key_event_relationship']:\n",
    "            listofthings.append(aopdict[aop]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\tdcterms:isPartOf\\t' + (','.join(listofthings)))\n",
    "    g.write(' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Taxonomy triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for tax in taxdict:\n",
    "    if 'dc:identifier' in taxdict[tax]:\n",
    "        if '\"' not in taxdict[tax]['dc:identifier']:\n",
    "            g.write(taxdict[tax]['dc:identifier'] + '\\n\\ta\\tncbitaxon:131567 ;\\n\\tdc:identifier\\t' + taxdict[tax]['dc:identifier'] + ' ;\\n\\tdc:title\\t\"' + taxdict[tax]['dc:title'])\n",
    "            if taxdict[tax]['dc:source'] is not None:\n",
    "                g.write('\" ;\\n\\tdc:source\\t\"' + taxdict[tax]['dc:source'])\n",
    "            g.write('\" .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Stressor triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for stressor in strdict:\n",
    "    g.write(strdict[stressor]['dc:identifier'] + '\\n\\ta\\tnci:C54571 ;\\n\\tdc:identifier\\t' + strdict[stressor]['dc:identifier'] + ' ;\\n\\trdfs:label\\t' + strdict[stressor]['rdfs:label'] + ' ;\\n\\tfoaf:page\\t' + strdict[stressor]['foaf:page'] + ' ;\\n\\tdc:title\\t' + strdict[stressor]['dc:title'] + ' ;\\n\\tdcterms:created\\t\"' + strdict[stressor]['dcterms:created'] + '\" ;\\n\\tdcterms:modified\\t\"' + strdict[stressor]['dcterms:modified'] + '\"')\n",
    "    if 'dc:description' in strdict[stressor]:\n",
    "        g.write(' ;\\n\\tdc:description\\t' + strdict[stressor]['dc:description'])\n",
    "    listofthings = []\n",
    "    for chem in strdict[stressor]['linktochemical']:\n",
    "        listofthings.append(chedict[chem]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\taopo:has_chemical_entity\\t' + ','.join(listofthings))\n",
    "    listofthings = []\n",
    "    for ke in kedict:\n",
    "        if 'nci:C54571' in kedict[ke]:\n",
    "            if stressor in kedict[ke]['nci:C54571']:\n",
    "                listofthings.append(kedict[ke]['dc:identifier'])\n",
    "    for item in listofthings:\n",
    "        for ke in kedict:\n",
    "            if kedict[ke]['dc:identifier'] == item:\n",
    "                for aop in aopdict:\n",
    "                    if ke in aopdict[aop]['aopo:has_key_event'] and aopdict[aop]['dc:identifier'] not in listofthings:\n",
    "                        listofthings.append(aopdict[aop]['dc:identifier'])\n",
    "    for aop in aopdict:\n",
    "        if stressor in aopdict[aop]['nci:C54571']:\n",
    "                if not aopdict[aop]['dc:identifier'] in listofthings:\n",
    "                    listofthings.append(aopdict[aop]['dc:identifier'])\n",
    "    if not listofthings == []:\n",
    "        g.write(' ;\\n\\tdcterms:isPartOf\\t' + (','.join(listofthings)))\n",
    "    g.write(' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Biological Process triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "d17c4950-392e-4875-a248-7c85156b8ebf\n",
      "ce62db30-f5be-4d01-b806-4fde0381c112\n",
      "a30e743c-8c27-450b-a458-687c34ef1715\n",
      "2969f6a8-9abc-4a80-b11f-c9dabf6d5c61\n",
      "8f31a562-0bd9-4df2-890a-7c9576d51942\n",
      "4dc420ed-5fbf-4506-97b9-9e767bad4bed\n",
      "c2b9857b-9bf8-42fb-a12c-573accdee6a8\n",
      "26814182-9ccd-4a08-89fd-e863eac6c39e\n",
      "466fa198-8344-4549-872b-22c77077942e\n",
      "c9ae32ef-b253-44c7-9b1c-d64afffc1d8c\n",
      "10ceedb5-ce26-4491-8087-e3e880ded023\n",
      "9cc71da6-bcc2-4537-ab07-212c0187491e\n",
      "79125d96-9675-465e-9763-250b1ba2c29e\n",
      "f13cba50-e587-466d-adda-8ac969b28e31\n",
      "19f0ff7e-0eee-4f9f-9167-5eb92f997cc9\n",
      "c82651df-f31a-4b50-bbc1-28ee663d146f\n",
      "cd5e1d29-dcd9-4904-9264-b27c5276035a\n",
      "f1202337-0391-4a72-8653-9c1e81f4a51d\n",
      "2d6cad53-e7d9-4721-9a62-b28924c9de53\n",
      "bd2cd354-24d7-427a-8888-3d34e5e4ee84\n",
      "bc580a8c-7a27-4966-946d-f66fdc6b563d\n",
      "f56cb10c-12bb-43a0-8a5a-5923e25dbda0\n",
      "e7aaf327-0107-46b3-805e-2e7c49087937\n",
      "04f25e36-43c2-430e-8a9d-89b9b4b71182\n",
      "6e2dd908-cdea-4c5b-88c5-d409b60c62da\n",
      "3a38a325-5144-483b-8b22-a682171ebfc9\n",
      "4a6f8df6-dc04-444a-9e27-de324cf66416\n",
      "324dcfc6-ec97-4a48-838d-f4832fd5f5a6\n",
      "a6deee9f-af84-4d1e-8f9c-2a2a0f308718\n",
      "fae81d95-2897-4979-bc96-2872110b8969\n",
      "49e1f964-2c6d-4519-a556-3e4f8b745685\n",
      "037566d5-1a1a-46fd-86dc-3de0359c0eef\n",
      "9dd7e17d-bd3e-4268-993e-bb7101a8d5f1\n",
      "6b5e3917-b694-4484-a8f1-76019c7ddc54\n",
      "436a5c79-9d65-44e6-91f6-7238ae162bc4\n",
      "6943cfe1-3480-41f6-b850-c8cfe739a11d\n",
      "89348b11-eeb1-4f50-badb-99aeb08fdef7\n",
      "d20d9131-6eb7-46b0-83da-905be3067661\n",
      "2619d007-480a-4efc-aa1f-835ab03cd6fa\n",
      "e4e96c06-a99f-415b-8889-c25c6a33e2f9\n",
      "bd238234-9cc2-43b4-8807-002aedf42153\n",
      "301f9913-7cd8-4569-baac-8bf29f71a8bf\n",
      "87168514-9fd8-4935-a7dc-d8c68bb57962\n",
      "22b1eda6-402c-47e9-81d9-4949fbb5fe35\n",
      "1c70748f-64cd-45c7-aef7-712f75fe2511\n",
      "7a999a85-8a4a-48de-bb50-96f3f9a1ba00\n",
      "8fcf555e-5900-4f9a-b539-1023dd1b9cf0\n",
      "dac6bf7d-9114-40fa-8237-6ad86c74b453\n",
      "e0e7b2bf-af83-4b7e-8960-c5381341e47d\n",
      "33687ef8-d003-40b1-82a9-2db16602a2f5\n",
      "ba417177-d796-4dc3-86a2-03cda8c426b9\n",
      "b1e1ff69-c2ae-4fde-8105-aef698afaba7\n",
      "1d80b2cf-e438-4fd1-bee2-29eac32c7497\n",
      "7f3b2e8b-e4cf-46fa-8859-e46f3b561933\n",
      "dcc15809-6258-4339-ba2f-692ceaf73877\n",
      "9d9c1a12-8c9c-48fb-867a-e699fbc0e14b\n",
      "efe546a0-9909-46d9-b73b-3f1be5ee1365\n",
      "edae8e18-d18b-41c1-a070-4fc6d7ddf41e\n",
      "613d8697-b6ad-4fe6-895d-77ec86e49bde\n",
      "5dc36d93-53dc-4316-8594-532555829e5a\n",
      "0273e31f-11d3-483b-8271-d1ddf8b8001e\n",
      "db184991-cb97-4a80-b5ce-16d7f4af1e23\n",
      "ca6e7312-7f86-4829-a37b-e0b5c3944829\n",
      "29575767-fdd5-41d8-86e1-e6dcfacd35cc\n",
      "15fbf88f-2a78-4cb9-914e-174caa4726e5\n",
      "af4720de-bdb5-4b43-ade5-f2dbbb5747b1\n",
      "ca27fb40-2c93-4120-872e-def4cb2789e4\n",
      "4011770b-b2a5-4d36-a83a-929bfa64ccfe\n",
      "97ffe663-0460-47e3-bea1-58d8262da4fb\n",
      "1e78e2a7-4f95-4d72-b7e1-40e14778511c\n",
      "46f62e97-4b05-4cce-bd7b-c45c7d08c623\n",
      "95f641ef-6fa1-400b-a1c4-d1fb3a7ee61e\n",
      "b855adf8-858d-44a3-a458-63176437afa9\n",
      "34d5c75a-5dab-4ac4-a484-508326364916\n",
      "c25bbed3-b9d5-49a2-9108-c1110dc2af5c\n",
      "b4b8d701-8b53-4980-925d-08112d4a90b2\n",
      "52d94306-b5a3-4de1-a129-9d7fff0f9a1b\n",
      "e3282167-aa8e-4111-8155-8582f6a8e838\n",
      "ec5429cd-ba1b-4bb1-ae2e-3ac0b12cd64b\n",
      "6be354da-744c-4ad1-8413-38b6cbd0077f\n",
      "e12d697e-f414-48fe-a617-68276c3a99ab\n",
      "677debdc-077f-45e2-aeff-f71df3d92916\n",
      "4feb9753-2316-4588-8687-c75553900503\n",
      "69e7e061-20ec-4b0e-9d15-e0beaa3c6987\n",
      "4b92e261-ce43-48f8-b10a-e4838c158087\n",
      "8737271d-95eb-4ba8-afe0-089af73c20d6\n",
      "c6c86fee-e52a-44f1-bdef-8fe14d77b774\n",
      "08658b47-ea77-43c5-a278-8aba840742ca\n",
      "be879571-7dc8-4496-b4ec-2fe5764288c0\n",
      "8b6b1906-dd77-402b-9816-d88de4dfa38f\n",
      "838589be-66ae-40ff-9e36-fec39ca93839\n",
      "9c8e0536-93b8-4fdc-b006-e253d5dbb1a2\n",
      "09124382-ae1c-4ad3-b29a-0cc950351689\n",
      "fa15b8e5-6df7-4392-96bd-e73199f75d1b\n",
      "2bec1427-f32c-4ed6-ab5a-c9d06fb4577a\n",
      "679ed725-b9dc-4e3b-a2f9-cdf904796472\n",
      "4c028c20-91b0-49e5-8461-e9caffe2038d\n",
      "289e9f40-05a2-4ef8-91bb-c086f336ecef\n",
      "afe94bad-9ea1-4bfc-919c-f9e06c83fb46\n",
      "f4bf1fac-9933-4a0f-98f4-80d1c7d3793d\n",
      "71e496ba-0c2d-49fe-836e-36f062c4a3a7\n",
      "d00dcbee-59b5-45e5-896e-c7fd84a1f970\n",
      "a2ef078a-863b-4bce-a153-a6e420b5e221\n",
      "f5a40dfe-d9be-4240-9905-1faa7c4b71c7\n",
      "bca50d59-9090-4892-8fbd-651db1b8509c\n",
      "47022bf4-adc5-4e15-aac3-6303d59923a1\n",
      "e7c96e22-e49c-4f61-8748-9e672039018f\n",
      "ccad7291-f942-4d98-8af9-39624744a882\n",
      "ae1b801c-c716-45d2-af03-efb770390348\n",
      "11752c8b-7ad8-4151-a29e-da9f26c8d3af\n",
      "c0d108fb-7f11-4413-a653-39264a3f9618\n",
      "70d6b878-a403-4e24-a29c-c53284f07681\n",
      "cc62688b-8b20-4886-8317-02206cc5f0e2\n",
      "64914107-94aa-4aee-a0ac-55ab1426adac\n",
      "bdf9135e-656f-4476-8ad2-b26300c93f89\n",
      "4e0485f0-9d8f-4fcb-bdbb-b03ddd019077\n",
      "f320fbdb-0199-4fee-83b4-8bd44647926e\n",
      "545e58f2-2589-4b01-b0d3-9147e2a51308\n",
      "d7313004-afd2-4303-8478-2d522682b87f\n",
      "8b2246b8-132a-4c41-84a7-ffd9f74b9232\n",
      "8a62230c-e343-4d8c-b892-b3e14dae62ca\n",
      "05ed8226-c5f9-4d15-88f4-41a7a1479a75\n",
      "d8b43f3f-e736-48fc-bae2-c226bfba0619\n",
      "40f9bf4d-d63c-409c-81b8-316779972876\n",
      "0d12ece5-d23b-4ff9-9cf5-d6931dba24d0\n",
      "60574192-a47a-4579-8315-93401e0742e5\n",
      "b75d24c6-39ca-4943-92d6-19bc47871bc7\n",
      "9e65472a-4c1e-4b33-8d29-ead9f7c9f53f\n",
      "50d7a6b9-15ee-4e3f-9302-a899c3311637\n",
      "2f5ccc24-22a2-427c-8c9d-27df44997240\n",
      "ae3dd09d-91a0-4fcc-9175-40e8fb21c60e\n",
      "dc46e042-5310-4298-9718-ff10c7c5602d\n",
      "2f1dbd24-a8f4-4cfa-8db5-e42f79156b43\n",
      "5a2cb729-884e-4766-9528-3ef7445deb2b\n",
      "e38c3b94-f157-4f4e-8f57-4021a9abe93b\n",
      "2d4e3be0-0e6e-44ef-93f9-fcf0597e13b2\n",
      "17b95587-1d6b-4b18-8abe-02a35190833f\n",
      "fa2943ef-0d93-45f9-b3a3-97326484e478\n",
      "a042c109-4710-401c-bc00-9072be63a3c6\n",
      "b8d7389e-7722-4b6f-b6f9-1b3e633432ce\n",
      "b3b1b2f1-fa2f-4bc6-b291-59af05b3a222\n",
      "ebd379e2-bec7-4241-bd29-bbff0f394af9\n",
      "a6e45b7a-728c-43c7-9f70-d98398bc1e49\n",
      "86286e74-0007-46c1-a053-c77d62dacfff\n",
      "f2757e51-a87f-47bb-b5b5-b08a28414f92\n",
      "24a4ca4c-0216-4254-8b90-cb0f41f6afd2\n",
      "0beedb85-6913-440d-ae9b-ee0b83bac3ab\n",
      "d877e466-34cb-4c76-b96f-7357109f3875\n",
      "71034f1c-9700-47b6-9531-b3484c6a5081\n",
      "4a3c3d9e-67e3-4220-b3d0-d24961da10c1\n",
      "d03a48de-0714-4ff1-a322-d38d2b996f1f\n",
      "a63aace8-0c14-4e57-a50b-a49b03b9a70e\n",
      "b78c3560-b4de-4aa5-ae35-7637e2ccc8f1\n",
      "54324483-5570-4a0d-87cb-6b614c413308\n",
      "7be20318-25d0-4074-a893-3d36dd4731d1\n",
      "530512a7-49a6-4430-b68c-847b957e1d59\n",
      "fcb74deb-46c8-4b4d-8236-c4801b90c96f\n",
      "33e8c7f2-2ec3-4b49-8105-9a5df1266266\n",
      "d7aea09a-c0f8-4465-ab93-458027ca729a\n",
      "674eb43d-083b-46a9-a533-79468944fe21\n",
      "a0344afa-0e33-443b-959e-71ad68a701c4\n",
      "d413c432-53de-46d9-935b-c364d8753e6a\n",
      "2acfb572-55cb-4133-a518-84bc580211f9\n",
      "66981824-51bd-4776-9597-9451e3d09209\n",
      "a426eea9-1841-4ab8-bfa7-4ce0e2c7bdf2\n",
      "6a43f6a0-cc69-491c-98f6-c4217e11dcf4\n",
      "e32aec9a-e5c4-4209-b8c2-d3c799a2a369\n",
      "b20d7357-80b6-4095-b410-efc59b783d75\n",
      "6d1d2dce-6008-436c-9604-b86b4ed0fe0d\n",
      "cd155227-a488-4513-954b-7d71d0e5e740\n",
      "03059e9e-a2ad-4f42-9d3a-05851a3742b9\n",
      "077bbe26-2ff0-4d6a-8635-c2a116e8505f\n",
      "92953baf-cf5a-4d80-8a97-5f89ce64be26\n",
      "2227cd65-13d2-4355-8c6f-3f170a514e87\n",
      "5914510d-6417-425d-bc1d-388a86918807\n",
      "70a27edc-c2ec-4b5b-a02e-c596b739b68a\n",
      "db9df889-141f-4de5-bcd4-ab348144aca7\n",
      "3318963c-7888-4f4b-a23f-6dbb55a8ad76\n",
      "93ba061f-5cec-44fc-b1d1-9c98e65b541f\n",
      "9e7930b1-9087-4c4c-9f6f-ba8ddedd8d47\n",
      "f25b4cfc-f147-4c04-9385-894bebcd6e3f\n",
      "c786301d-33ca-4fd0-bf01-1f3a769980d2\n",
      "b37a8a52-16ac-4834-81b1-40867b5415e2\n",
      "a8c6e750-1da2-4f60-a58d-40f48cb26a13\n",
      "b0b0b719-9182-4091-a5ee-781238b58db9\n",
      "d3055343-0ba0-418b-9ded-18122a9fea10\n",
      "710be845-5d28-48e2-82d1-bf4872003b47\n",
      "a4558230-a647-4169-be82-cef20c34ddce\n",
      "2a8adf1f-633b-4800-8547-400f45d1f789\n",
      "b1a8b152-5281-47ba-ac86-6049fcf9c35a\n",
      "d0545495-9a33-4d05-9405-6ea02bbf4206\n",
      "ad79a6b1-d78d-4f1b-8167-e4b6d2b5a6d2\n",
      "2994c87e-b89f-46a2-9741-b9c111ffbaeb\n",
      "56dcd64a-368c-4b19-b42e-8a28f4bb1e35\n",
      "4fa52beb-0439-4752-9f2a-d18f2431c60d\n",
      "356a97ab-a08e-4cd4-a4da-e585ce741256\n",
      "5e860dab-d5a4-40c6-8fd1-459a2e235046\n",
      "397307d5-f1ab-4378-ac89-41f4b53d3ee4\n",
      "79cccef4-2914-45d3-b912-e7a7b33f3c0d\n",
      "69e7ae65-88a5-485b-8c56-d282ae647a3a\n",
      "ee911b98-12ee-42b7-9288-b0b092738dcd\n",
      "04ea75ce-ba52-480b-968d-bd4e58118d64\n",
      "094c0f43-8d0c-4765-be68-24678f620914\n",
      "e0cc6fdc-23ff-4a6f-817f-25e4b6e3d23d\n",
      "c611056a-0280-48c2-9c78-3fe83799a7dd\n",
      "41e3bca8-af41-4c48-bb0d-62819dbeb7e9\n",
      "14d5b0e9-08ce-4c56-9c45-1424324d82c0\n",
      "ecc3c91c-562a-43f0-9db7-d1e73e9c31f9\n",
      "f5d4d63f-b47f-41ab-9f97-ee5aa523350b\n",
      "9eb90268-ad2c-405e-96c5-51b15341a083\n",
      "515cc903-6c68-4a58-ad51-3984aa3ec8e0\n",
      "c6946e84-4fbd-4196-9f51-cb7d8a574f4a\n",
      "3e8250f9-8a8a-4e43-a923-c5f7a87a83b4\n",
      "633a15a9-7341-4caa-8922-c25fe4d52db3\n",
      "634ca005-c4f4-42e4-a6b5-e00924f96b8c\n",
      "9ee0be98-e750-4c4e-b8fb-b653733231c1\n",
      "057555ea-0a47-4fcc-8386-0b46fb3d4f50\n",
      "a5e4a2d2-41f3-497f-8a07-dcfd8f0d59eb\n",
      "5e7dfaf4-e04b-46d5-80e4-24004a075707\n",
      "3a6cebb8-91d3-4f71-b5c4-768a8c7dfe95\n",
      "42119570-6e4d-4e99-a8ee-e4d436462170\n",
      "843d73ec-d076-4459-9b25-085bfc5b49c0\n",
      "3fdc2eea-18ff-4430-b07a-0ff024886c96\n",
      "bd942a71-eeff-4430-be14-f1ff78724107\n",
      "28e538e9-c7d2-4c27-a448-9257133b069b\n",
      "34644c36-a307-4e24-8ada-9cafa5580539\n",
      "16bee63a-e397-4a6d-80e3-11900ecc6638\n",
      "adaecf0c-8727-4bf7-86e9-a39fa46f7bf6\n",
      "2040547f-8e0f-45df-89ac-0c8284ee5c0f\n",
      "515c3458-57d0-46b8-bf24-0500096d5a6d\n",
      "de8d30d3-0db6-481d-99a5-9e7da953f4ab\n",
      "0231522c-7894-4ef2-8eb7-81b039397cd2\n",
      "2c33b96e-39e5-4dc5-bb38-72a8c050922c\n",
      "7e2bf7d2-d02f-4818-8c5a-d1d40c48b8d4\n",
      "7d6e907e-b125-4398-b547-6cc1d4446841\n",
      "d177c872-9182-4995-901b-44e3dff108e6\n",
      "bacbdc5a-e960-4ab0-a44d-9b1f499851eb\n",
      "8c8a00ed-2b01-48f0-895f-f6cac79fe313\n",
      "b81f50f8-a530-46ac-9635-028b98c6dac9\n",
      "ebd2b292-c766-4cf7-8bf7-81fddfc23877\n",
      "a3c33090-f757-4e6e-8d05-4648a58c9770\n",
      "acd38ced-86a2-4182-918e-422a1f249b3a\n",
      "bcf17f11-76cf-4461-a67b-c4cfaefbe1cf\n",
      "df04d984-7ae0-4a93-8d30-7b37b23d8b41\n",
      "55855e34-aab4-40bb-abf4-f93ea2bda930\n",
      "26e1555f-70a5-4a6a-9839-fceb54bde416\n",
      "03494708-422a-461d-ba4d-d2e5254cacb0\n",
      "42778641-8dc3-47e6-a577-fee2ede698fc\n",
      "378bb0dd-cf35-41d6-97f6-1d2a6f2920c1\n",
      "d93a3fbb-e357-4a1d-8b44-0e6b5d414f97\n",
      "efef84d1-47d7-4509-913d-6bc743e0ef9c\n",
      "200ea199-acaf-4665-a96f-a6476bc82be0\n",
      "09f351ea-cd27-4a15-8aa6-bf8567f2c45f\n",
      "f3b668b0-f212-430a-84be-82afae7187d9\n",
      "36b2dd03-023e-4aa3-8fe7-75cb113ac71f\n",
      "c754a5c2-cb26-4dd3-96a4-663cbd94307e\n",
      "4e3aaa64-ec52-4344-9cbb-68c15658177b\n",
      "02942aa0-6d3e-49f0-9925-d35372bdcc34\n",
      "c79d84d2-ce87-48b6-a383-babbc45e3f69\n",
      "d9858e6f-ab33-4172-ad57-eb9dcb1b1e08\n",
      "6375e18d-df98-46c9-9598-223ed7e4954a\n",
      "2a2afa9d-70b4-498d-bdab-d35698480c2e\n",
      "6a227d2e-09a9-4c1f-8b0e-0ed1b2c036a9\n",
      "20299e91-4e16-4054-a061-702e1edcfad1\n",
      "284028cc-fcf8-454d-a4a3-01dd198c7f31\n",
      "ff6df495-5527-44f4-93bb-88b2109855a8\n",
      "2a5d70e4-11b9-43f3-a675-687b05a7f42a\n",
      "7990c7d2-c41b-403b-9811-7647adfd3df3\n",
      "6c6733b8-8943-45fe-b130-077e6a7b0314\n",
      "36010cc1-48ca-46ed-b0d5-16012ed3ffc3\n",
      "f18eacfe-fa81-4ce4-992a-43ec83d00e3c\n",
      "85d12ecd-9a61-473d-9124-e48e7fb2846d\n",
      "c677be69-04bf-4ec2-9e74-7897119dc3c5\n",
      "64bcac94-574c-4b2a-8b50-860f164b08f5\n",
      "3939b9e5-7503-4a57-aee8-82a62e675bcc\n",
      "3982ebd4-5406-41cd-83ab-c812d7faa026\n",
      "17899100-8b9b-48ce-8ed5-2a68e6f0ab48\n",
      "1d41f551-67d8-4995-9379-0fc6a50e84c5\n",
      "14f48c53-6109-4e94-9c51-576ccad7399d\n",
      "6dbd6bdf-d81b-48bd-a513-928affffc797\n",
      "00dcc045-fc0e-4b4e-8437-22cd332c1d7e\n",
      "cabaf4e5-6b2a-49aa-97a9-3f5bb34d0c2f\n",
      "d6b0d33d-62b1-43c6-a921-6e1e7467bc95\n",
      "76f2770a-6866-4fb3-b048-15b6725b4a52\n",
      "72b6a6d3-c4b7-4732-a70b-3530867df2ed\n",
      "2bfe7040-6fdf-4ace-a335-6ca169b14f7c\n",
      "579a47d4-1824-4285-94d3-1bacd9a4bb31\n",
      "60ad7c16-06e3-48d7-a79d-a0dff617154d\n",
      "62d1634a-59fd-4c44-8567-64a7d183ecb9\n",
      "9490a14a-fffb-4f06-b5c9-0a3b237f5f7b\n",
      "a8bc3646-4a25-4fd0-a775-6db8e2d8a429\n",
      "5904fca3-781a-4485-8d40-10bfc6040c4c\n",
      "364dab67-2159-4435-b2a9-fb6076c4d13f\n",
      "dfc9cd65-5a3c-48f6-8c50-ea814a1460e5\n",
      "66ed44a4-abba-4773-b6b3-7958159dfe2e\n",
      "3b4821e2-4efd-400a-8406-6e7f4d9039e5\n",
      "ab316992-5297-458d-bca9-80e967df1076\n",
      "36b09900-3b42-4a9a-bdad-6249a9cace86\n",
      "0618077f-bf3b-49b1-bb8c-69531bb4b3e1\n",
      "ebddff61-3f4d-4c80-932f-3f40152b0742\n",
      "52353964-c135-4339-a4a8-2a4fe744ebe4\n",
      "85fe502e-a83f-4156-977f-ae266f6e59c9\n",
      "ec9df66d-f1a6-4573-8f9f-fdb8113f87a3\n",
      "ded64295-e264-415d-b857-2828b90f0c25\n",
      "a6a5a3a8-6d98-48e8-ba6a-ab87c770137e\n",
      "b12b0f58-917b-4b3b-ba46-bf60bdc8ffd2\n",
      "caa9ed07-9017-4b90-a890-bc84b3ca7a4a\n",
      "623fb85c-e3c8-42c1-9845-0aebdf7a27de\n",
      "15676dff-b7a2-4725-90d0-f1c433855a17\n",
      "eaa0456e-2ddc-45d0-94d8-9600b8331719\n",
      "f45540d1-b3d4-4ffd-9470-78663e17ab28\n",
      "84b4adea-ede3-4ee9-8552-757ba9279f71\n",
      "cb408da0-d7e5-4711-b97d-24b2078b9016\n",
      "f7d4098d-8e07-43e8-bac3-79e31c1789a3\n",
      "dafda14b-91ae-4b41-844a-182d93955b90\n",
      "7306794a-59ae-428b-be47-1c57c7448928\n",
      "4afb7af1-fa1f-4add-8709-d12804a61fef\n",
      "596cebe6-b4e2-446a-a296-63a2163b073b\n",
      "f4b8893d-0797-41d0-b406-eeba420bec48\n",
      "e360a50a-35ac-4d11-9564-9ebacb0f459c\n",
      "cdc31bcd-c49e-4acc-909a-8231cc8815d9\n",
      "89d21328-061e-4635-a029-67cdb885d0ab\n",
      "414457ba-22c4-462e-96a6-95dc9d7cdabb\n",
      "2ef1b618-fdad-4e9d-8b2e-f1e5cdfb68f7\n",
      "2497a715-2777-49c8-9b68-64143305a52f\n",
      "db684314-ef33-47dc-bde4-9c4bacbffd46\n",
      "84f9ad60-109d-4a81-96bc-1da4cfb8006d\n",
      "e0b32e76-52a9-4b1e-b9db-e581e4464fb1\n",
      "5affc38a-403c-45ee-9f4d-4cacb2e19329\n",
      "4878edee-861f-44b4-a2e7-63f75629cc52\n",
      "9897dc71-a5f4-48ed-afb5-c40431b950a0\n",
      "818c73da-e144-4935-8d73-81ccb090dd9e\n",
      "0ec10483-584d-43d1-a46f-bcf22e9b071e\n",
      "561cd6f4-8c7f-414a-9ca0-db550e7d7155\n",
      "08f5108f-4209-4be7-a3b4-efbf4d10c48f\n",
      "864da2e1-3e70-4cab-96c8-de88d98d4b5f\n",
      "30d75ae3-b630-4fce-ba6a-a17be588d6e7\n",
      "db8b6951-9f0b-4811-a281-18558762474c\n",
      "b6849999-41f3-4d52-8c6e-b06ce26ad056\n",
      "d9da0334-c702-4bcb-835c-c2463f801ca6\n",
      "51257a5b-9c69-4be0-96c1-f0e698ea7d1c\n",
      "44754213-15cc-4395-b61b-6abc12be1c10\n",
      "986d77fc-1a8f-4f0b-817a-e46bcab115a4\n",
      "395af80e-01e2-4873-95e3-d42c851b527a\n",
      "ec5509b4-6d89-435b-b440-7cdc4dbee5b3\n",
      "97caef35-f58a-4536-aa66-2c3f080bdaef\n",
      "0df6f355-e5a1-405a-a732-c38dacb179e2\n",
      "b5ef6139-b52a-4fda-af4f-437b331eab1f\n",
      "c435d46b-037d-4544-9dbe-7e289a0e97e6\n",
      "9b5eca53-3475-4e04-bd39-aa2ad5df4ba6\n",
      "5ad69aaa-5c52-4eb3-8626-9641fc22e496\n",
      "82d76f36-60bc-4439-b38e-e9d38486c40c\n",
      "94c3c3ae-e817-41d0-95fd-c128efb2e02e\n",
      "99c18b56-5e61-47b7-bfb2-02c3b8204965\n",
      "3591a209-eb71-4622-96d1-4789ebd9484f\n",
      "b491d995-2bc6-42d3-b29d-b6be61286cfb\n",
      "1e9fffd5-f40a-4979-baa1-7dace1faf691\n",
      "c14ea7dd-84ba-4b94-b83a-5d6b6af29c13\n",
      "7b100af8-8c3c-4a67-affb-e50b44e826c1\n",
      "fdc2140a-8c9c-4cb4-b590-864e343a5cd3\n",
      "07fad080-89d7-4221-af22-731480ef6801\n",
      "4f010472-c93d-4ea4-a700-a1d5f7cc1580\n",
      "7b7657ad-f991-4918-8a92-6c20e5527ab3\n",
      "6cd7e36d-4e54-4d9c-9ebb-c2bb1c4c5789\n",
      "e2fe9c75-7e9a-4a52-9610-0c35d7bff9ad\n",
      "d545b915-fc10-4d68-9707-20a59058664c\n",
      "55ff49e4-2ece-4404-b735-7f20cd3da9b4\n",
      "977a341d-7af7-4d38-9b67-bb72d55d1e65\n",
      "ead388c5-cb84-4378-8a6b-c7292f375df9\n",
      "84f0c8a0-8515-4d39-bb93-b85bf97e8661\n",
      "2bb0ca87-6a3e-4c09-8dc4-872ea6acc5de\n",
      "27229b51-8553-41e8-a6ad-80fdeab370c5\n",
      "cc059ffc-fde5-4ab9-9bc5-5bcd86060ba4\n",
      "c79c25f7-75f0-4de1-8c1c-5bc841eafdce\n",
      "76c86a56-f483-4d84-89cc-485c5a8182cf\n",
      "68fd50f1-7c21-4db0-a57f-3472112e3fb9\n",
      "b19bfe63-4302-41e6-b854-e703fbc4268e\n",
      "b1c97754-9e56-4edd-938a-77cd91c0ae51\n",
      "63a25b4e-982e-4344-ba14-5faaa00fcadc\n",
      "e1d77aca-af9c-4cf0-944d-e35c5ddecb67\n",
      "c7f414eb-6b48-44da-8a5b-ed798394948e\n",
      "9f68cfd0-e1cb-43c8-8335-aaac0bbb34a1\n",
      "4e438a0f-cafb-41c3-a261-9dc1e90f4c33\n",
      "2c38a0b9-2414-4cd6-8c93-d0b79a5b8340\n",
      "9e2498d2-03a5-4633-b58d-244719b3279e\n",
      "b2c79020-7441-4a98-b5ae-8d4d3381fe32\n",
      "a013d647-fafa-4b39-a157-6025b8aee69b\n",
      "c74bb93a-ab1d-4695-a9e1-f49a1dbff6a3\n",
      "a6d1b932-9476-4f0e-97f3-7d916ac01a0c\n",
      "72c9732d-1e3e-41c9-b133-7b629f5235ef\n",
      "279b2727-a641-4fbf-86fb-4e190e380c10\n",
      "ec93f95c-9638-4451-9020-505313287d25\n",
      "187f4797-e703-4808-b0ef-730555654789\n",
      "62b7feed-6ed2-4aed-92c2-69e4f8b20c5e\n",
      "1beca427-7005-4f36-a1f5-afbe94eaf1d4\n",
      "da8ea9f8-2d93-40f2-b84f-362cf0dd62ce\n",
      "2573e2b0-775f-42e9-b9f9-ee74db1d15d7\n",
      "4094e261-6c69-4858-9ff5-748b388103a3\n",
      "54c3451e-9ba0-4c53-b8df-13457b260929\n",
      "99cbe541-07b3-4e1b-959e-a8c26f7d14e7\n",
      "757cc3a3-b25e-4722-8baf-313b0335168b\n",
      "e2d24b14-dde5-489a-9d62-ed73805ce176\n",
      "c7c29248-4e7b-4700-8299-b42896e07149\n",
      "75da37a9-d785-41f9-8b22-7b613091c152\n",
      "d77c72cc-e693-4dcb-a7d1-a9d58559af0a\n",
      "18707cf3-407a-43cd-a8ca-db750a2b0169\n",
      "e136487c-50a8-45b0-b2b3-596b7e7707ca\n",
      "c3661720-67da-4a61-8db7-60cb189fbe5c\n",
      "14328ca6-e72e-45e3-80ed-0832ac62a8e7\n",
      "de62a27c-8daa-4b00-99d3-3537765e9d36\n",
      "4c954a89-4930-4731-9647-17aa53e4f9b8\n",
      "9d8cfd65-697f-42ab-b6f1-91f7fa4c6847\n",
      "83609151-e9a5-40bc-b4b1-9d6da7bc2d0f\n",
      "6b8d779d-8fb2-4714-8516-e26e5f7818d0\n",
      "09aae222-ca2b-425c-bc70-0d9be3bd6176\n",
      "aac86ee7-0174-4992-a956-587c0f31e795\n",
      "e1b7d4a7-284f-492c-bf96-422bc9e81b01\n",
      "85056cbb-6d76-4a7c-b766-a0b865b290da\n",
      "c8381d27-6f1e-46cd-8f8e-937b3f765666\n",
      "32d4df4e-7012-49f4-8a7f-cc5967047870\n",
      "a3b304db-508e-48ac-9c8d-a66671a53a5e\n",
      "47373dbd-dc44-43bb-b126-0695953ecb2d\n",
      "e9a0d5b3-d464-4c9c-8b7e-99ec31e2cf87\n",
      "a63ce8f6-16de-4b19-b088-0e42148a0e8f\n",
      "6684319d-e44c-4eb7-846c-77bf7b501cb3\n",
      "95356d0e-4f1e-4a74-bc72-da7a6136d118\n",
      "587de074-b68e-4eaf-a8f1-889991fdb3d1\n",
      "d3068a3b-9dee-46c8-a4e0-8786f0fc40a1\n",
      "937f5cbc-5331-4b38-99c7-a3267058d17f\n",
      "573e3792-d31e-4665-977a-dd2fc6bb94e0\n",
      "157fa09b-593d-41e9-83fc-a02167ae89fb\n",
      "0f450672-232d-4649-910a-ce76471f273c\n",
      "bc3139db-a183-4ca2-8239-9ed39194bd55\n",
      "abf5c10f-f204-4e4f-a448-d12b5800a61a\n",
      "7478b97f-f0cb-4ae4-8929-a22df5dee4e1\n",
      "308ac137-1bb0-4533-b9bd-08e5c7fa75fe\n",
      "9d5d1f7f-3f29-444f-91a3-f10324a5f1d2\n",
      "856bc03b-2454-45e6-b73e-dd0579d60e25\n",
      "c01f7b39-443e-464d-b2e5-57810fb825f5\n",
      "186bd132-2e94-4c57-805e-7b8ca69bffdd\n",
      "92c5ce5f-566b-49b2-8f1c-9eda7c1f1f97\n",
      "68bea803-09bf-493b-928a-15c3304e7a09\n",
      "498df7e0-37db-4d73-acb0-ae2b00388c0c\n",
      "061d0654-ac1a-4e07-a822-c8985602d594\n",
      "f49d4051-96ff-47fa-ad59-8709e08a2d8d\n",
      "90ab384e-d641-4d7f-8eec-0e06ed21412b\n",
      "c7104324-54b3-4163-9663-2cf09992d2c8\n",
      "38a67afd-13fd-4c43-aef0-91297c603c97\n",
      "5ddf3864-7d24-464b-a164-d73855566d29\n",
      "ba1f66c0-d05e-42e9-b072-cfafc8e0f9e3\n",
      "767a463f-107b-4904-b2dc-9c562179dccf\n",
      "ec170c3f-7fe2-4ca4-9e36-3fa9b2e89d57\n",
      "10943437-704a-4387-a90a-8db1bee7d884\n",
      "51225b81-555a-4f56-b120-359399595e0b\n",
      "ebbe9c7d-9411-4840-b673-44a4594d9635\n",
      "e9b41a31-fe10-4a14-bdd1-9a9e302f086b\n",
      "ffee71dc-017e-4f21-b2d6-e97565efa6dc\n",
      "9e8ca0a2-e844-4015-be12-8693373d1a4c\n",
      "74277bf9-6d20-40cf-a51d-c35aadb9a0fa\n",
      "048d5a79-8d00-4a90-845e-1300ee67ec78\n",
      "73297e0d-9b7f-41c2-8372-cf6576fa3374\n",
      "a9a383c0-c8a4-4fe6-96a7-c331393d9cfb\n",
      "46f11250-f796-4103-a81a-0bb10d43f98f\n",
      "2dd35c7b-9a3b-41a6-9a48-cb57ead2d9f0\n",
      "4480a3a3-973e-4263-982a-738826841021\n",
      "b46dc098-b5cd-4a02-b5f6-7d87eb63c22c\n",
      "edfa40b2-0cb3-47ee-b50b-3ca017bb35d6\n",
      "7264c5db-3441-4ae1-80c0-91f2c562a354\n",
      "6ef68e57-5ef5-4dfc-b1dc-8652be74217d\n",
      "e69349f5-1e2e-4303-9d7d-6aee11121bbc\n",
      "469b68ad-08ba-48f5-b2ea-76b89d96b149\n",
      "97ff8fca-1755-4b63-be60-cb902ba004a1\n",
      "f847cd41-f48c-4ea5-99f6-0a4d5a35c998\n",
      "2cd71ce4-329c-4825-a5ae-35f58081a9dc\n",
      "4f4a47d8-ddaa-45ab-924f-fbc854e02c59\n",
      "f3d8abef-353f-4c65-be58-4ffbd3fc020a\n",
      "7a523fd5-4f06-4019-b817-0f8892a090f0\n",
      "768e44c4-6d44-4c3c-9f32-e46aca6484c1\n",
      "0b7fef30-0e08-4e61-9e46-fd2ef91cf60e\n",
      "b71962a2-7145-4ee6-92c7-0fd3f2225d99\n",
      "7eacf8b9-a435-4977-ac45-d2e01fc2fc4a\n",
      "9bb7cef7-2ac1-46fa-b80e-3150306323f5\n",
      "1ab72237-ca96-4248-bebf-e50b26d6e57f\n",
      "a166b921-bdee-4f61-aadf-b9bdf42891ba\n",
      "c171bc67-9a96-4ff4-a1a6-090dfdebaaff\n",
      "befc7d09-9acd-4426-b3bd-ee2310cee65c\n",
      "3a0fb012-3553-47b3-a387-f2ce7ca06923\n",
      "9f83d284-32e9-42db-a344-e15b6484be87\n",
      "b1e64900-4c60-43a1-9667-ab1d41a752c4\n",
      "4094468f-e66a-45ff-b1b3-3eede06c3cd0\n",
      "111c14eb-65c5-4ccf-8499-0a754f36e1a2\n",
      "6adf5617-3b89-4c30-9e3c-e3c66ca2e320\n",
      "8603b265-f190-4ebc-a82e-67562381eaa9\n",
      "c9c8d14a-7348-4ebf-8f70-e1c65486af7f\n",
      "1dc9573e-7b31-4636-960c-f547aec51422\n",
      "15eec36c-f793-489e-8a42-8712d2b9489a\n",
      "269f8d5f-f70d-43ee-a996-6961dccd4aac\n",
      "aa5540c1-0959-4a14-b3a8-4e01aadfd443\n",
      "a9339b73-35a2-4523-83a7-2b515e3db185\n",
      "3152d554-c5ae-4f28-86dd-35d4e8ff5c2d\n",
      "9f8ecdd7-61c0-43c8-8a14-ec5c6d8e3ac1\n",
      "1c1a5b98-a5bf-41a9-a7a8-d03e5b157a49\n",
      "8c2a1462-cb32-4f27-8387-a22b3ac27e93\n",
      "5ef310d2-3689-4e0f-9fa8-f432201152b5\n",
      "c6f549ea-e8fc-4143-bca4-b847e144c196\n",
      "07273d84-5208-4e8b-aff1-85fbaaebe263\n",
      "fbdc4d06-e3eb-4ab7-a402-a7e35add7bc2\n",
      "a45511e4-063d-437f-9c97-15b54c314ce2\n",
      "f25a9820-d31b-463f-a8a1-a12fabd8af4e\n",
      "76bbee22-6a78-427b-8b63-57670ad69bb2\n",
      "e1410d20-160f-4a9b-a53c-91fae27903ad\n",
      "cb696bfd-cccd-40a4-8933-8b4be6657176\n",
      "61f0d19d-309f-4c8e-aed9-d074f99f55e8\n",
      "d1f63476-c462-4831-b9e8-dbedc67e745b\n",
      "9aea5983-548d-4b08-9abf-d35e3fe76ca4\n",
      "cd07be39-5580-4847-97f4-b90bf76a6379\n",
      "2be7b6e4-9ea0-4999-a78b-3fa59a6b9c7a\n",
      "2a2b599b-d635-4d64-b8c6-645e0d5bf89c\n",
      "d954ad68-2ae2-4a7c-974d-1051b995ea71\n",
      "8b0e26ff-7e75-46f4-a99f-85782a2ccb6a\n",
      "c726cee8-97d7-44f1-8fdb-82e234e83544\n",
      "df4d7a22-f1ed-4150-9ddb-f285a5409618\n",
      "89a86840-27ca-4c99-bbc8-19c24446b2ea\n",
      "c5feaacc-b56e-4b91-8b14-7b3d61def57d\n",
      "3ac46050-f6ce-49bf-bc92-6f7271d93427\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for pro in bioprodict:\n",
    "    print(pro)\n",
    "    if pro is not None:\n",
    "        g.write(bioprodict[pro]['dc:identifier'] + '\\ta\\tgo:0008150 ;\\n\\tdc:identifier\\t' + bioprodict[pro]['dc:identifier'] + ' ;\\n\\tdc:title\\t' + bioprodict[pro]['dc:title'] + ' ;\\n\\tdc:source\\t' + bioprodict[pro]['dc:source'] + ' . \\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Biological Object triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for obj in bioobjdict:\n",
    "    if obj is not None and \"N/A\" not in bioobjdict[obj]['dc:identifier'] and 'TAIR' not in bioobjdict[obj]['dc:identifier']:\n",
    "        g.write(bioobjdict[obj]['dc:identifier'] + '\\ta\\tpato:0001241 ;\\n\\tdc:identifier\\t' + bioobjdict[obj]['dc:identifier'] + ' ;\\n\\tdc:title\\t' + bioobjdict[obj]['dc:title'] + ' ;\\n\\tdc:source\\t' + bioobjdict[obj]['dc:source'])\n",
    "        if bioobjdict[obj]['dc:identifier'] in prodict:\n",
    "            g.write(' ;\\n\\tskos:exactMatch\\t'+','.join(prodict[bioobjdict[obj]['dc:identifier']]))\n",
    "        g.write('. \\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Biological Action triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for act in bioactdict:\n",
    "    if act is not None:\n",
    "        if '\"' not in bioactdict[act]['dc:identifier']:\n",
    "            g.write(bioactdict[act]['dc:identifier'] + '\\ta\\tpato:0000001 ;\\n\\tdc:identifier\\t' + bioactdict[act]['dc:identifier'] + ' ;\\n\\tdc:title\\t' + bioactdict[act]['dc:title'] + ' ;\\n\\tdc:source\\t' + bioactdict[act]['dc:source'] + ' . \\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Cell term triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for item in cterm:\n",
    "    if '\"' not in item:\n",
    "        g.write(item + '\\ta\\taopo:CellTypeContext ;\\n\\tdc:identifier\\t' + item + ' ;\\n\\tdc:title\\t' + cterm[item]['dc:title'] + ' ;\\n\\tdc:source\\t' + cterm[item]['dc:source'] + ' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Organ term triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for item in oterm:\n",
    "    if '\"' not in item:\n",
    "        g.write(item + '\\ta\\taopo:OrganContext ;\\n\\tdc:identifier\\t' + item + ' ;\\n\\tdc:title\\t' + oterm[item]['dc:title'] + ' ;\\n\\tdc:source\\t' + oterm[item]['dc:source'] + ' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Chemical triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for che in chedict:\n",
    "    if 'dc:identifier' in chedict[che] and '\"' not in chedict[che]['dc:identifier']:\n",
    "        g.write(chedict[che]['dc:identifier'] + '\\n\\tdc:identifier\\t' + chedict[che]['dc:identifier'])\n",
    "        if 'cheminf:000446' in chedict[che]:\n",
    "            g.write(' ;\\n\\ta\\tcheminf:000000, cheminf:000446 ;\\n\\tcheminf:000446\\t' + chedict[che]['cheminf:000446'])\n",
    "        if not chedict[che]['cheminf:000059'] == 'inchikey:None':\n",
    "            g.write(' ;\\n\\tcheminf:000059\\t' + chedict[che]['cheminf:000059'])\n",
    "        if 'dc:title' in chedict[che]:\n",
    "            g.write(' ;\\n\\tdc:title\\t' + chedict[che]['dc:title'])\n",
    "        if 'cheminf:000568' in chedict[che]:\n",
    "            g.write(' ;\\n\\tcheminf:000568\\t' + str(chedict[che]['cheminf:000568']))\n",
    "        listofexactmatches = []\n",
    "        if 'cheminf:000407' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000407']))\n",
    "        if 'cheminf:000405' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000405']))\n",
    "        if 'cheminf:000567' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000567']))\n",
    "        if 'cheminf:000412' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000412']))\n",
    "        if 'cheminf:000140' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000140']))\n",
    "        if 'cheminf:000406' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000406']))\n",
    "        if 'cheminf:000408' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000408']))\n",
    "        if 'cheminf:000409' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000409']))\n",
    "        if 'cheminf:000564' in chedict[che]:\n",
    "            listofexactmatches.append(','.join(chedict[che]['cheminf:000564']))\n",
    "        if 'cheminf:000407' in chedict[che] or 'cheminf:000405' in chedict[che] or 'cheminf:000567' in chedict[che] or 'cheminf:000412' in chedict[che] or 'cheminf:000140' in chedict[che] or 'cheminf:000406' in chedict[che] or 'cheminf:000408' in chedict[che] or 'cheminf:000409' in chedict[che] or 'cheminf:000564' in chedict[che]:\n",
    "            g.write(' ;\\n\\tskos:exactMatch\\t'+','.join(listofexactmatches))\n",
    "        listofthings = []\n",
    "        if 'dcterms:alternative' in chedict[che]:\n",
    "            for alt in chedict[che]['dcterms:alternative']:\n",
    "                listofthings.append('\"' + alt + '\"')\n",
    "            g.write(' ;\\n\\tdcterms:alternative\\t' + ','.join(listofthings))\n",
    "        listofthings = []\n",
    "        for stressor in strdict:\n",
    "            if 'aopo:has_chemical_entity' in strdict[stressor]:\n",
    "                if che in strdict[stressor]['linktochemical']:\n",
    "                    listofthings.append(strdict[stressor]['dc:identifier'])\n",
    "        if not listofthings == []:\n",
    "            g.write(' ;\\n\\tdcterms:isPartOf\\t' + (','.join(listofthings)))\n",
    "        g.write(' .\\n\\n')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing mapped Chemical identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n",
      "817\n",
      "1229\n",
      "1660\n",
      "2079\n",
      "2495\n",
      "2840\n",
      "3256\n",
      "3472\n",
      "3786\n",
      "3820\n",
      "4242\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for cas in listofcas:\n",
    "    g.write(cas + '\\tdc:source\\t\"CAS\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for inchikey in listofinchikey:\n",
    "    g.write(inchikey + '\\tdc:source\\t\"InChIKey\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "    \n",
    "for comptox in listofcomptox:\n",
    "    g.write(comptox + '\\tdc:source\\t\"CompTox\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "\n",
    "for chebi in listofchebi:\n",
    "    g.write(chebi + '\\ta\\tcheminf:000407 ;\\n\\tcheminf:000407\\t\"'+chebi[6:]+'\";\\n\\tdc:identifier\\t\"'+chebi+'\";\\n\\tdc:source\\t\"ChEBI\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for chemspider in listofchemspider:\n",
    "    g.write(chemspider + '\\ta\\tcheminf:000405 ;\\n\\tcheminf:000405\\t\"'+chemspider[11:]+'\";\\n\\tdc:identifier\\t\"'+chemspider+'\";\\n\\tdc:source\\t\"ChemSpider\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for wd in listofwikidata:\n",
    "    g.write(wd + '\\ta\\tcheminf:000567 ;\\n\\tcheminf:000567\\t\"'+wd[9:]+'\";\\n\\tdc:identifier\\t\"'+wd+'\";\\n\\tdc:source\\t\"Wikidata\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for chembl in listofchembl:\n",
    "    g.write(chembl + '\\ta\\tcheminf:000412 ;\\n\\tcheminf:000412\\t\"'+chembl[16:]+'\";\\n\\tdc:identifier\\t\"'+chembl+'\";\\n\\tdc:source\\t\"ChEMBL\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for pubchem in listofpubchem:\n",
    "    g.write(pubchem + '\\ta\\tcheminf:000140 ;\\n\\tcheminf:000140\\t\"'+pubchem[17:]+'\";\\n\\tdc:identifier\\t\"'+pubchem+'\";\\n\\tdc:source\\t\"PubChem\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for drugbank in listofdrugbank:\n",
    "    g.write(drugbank + '\\ta\\tcheminf:000406 ;\\n\\tcheminf:000406\\t\"'+drugbank[9:]+'\";\\n\\tdc:identifier\\t\"'+drugbank+'\";\\n\\tdc:source\\t\"DrugBank\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for kegg in listofkegg:\n",
    "    g.write(kegg + '\\ta\\tcheminf:000409 ;\\n\\tcheminf:000409\\t\"'+kegg[14:]+'\";\\n\\tdc:identifier\\t\"'+kegg+'\";\\n\\tdc:source\\t\"KEGG\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for lipidmaps in listoflipidmaps:\n",
    "    g.write(lipidmaps + '\\ta\\tcheminf:000564 ;\\n\\tcheminf:000564\\t\"'+lipidmaps[10:]+'\";\\n\\tdc:identifier\\t\"'+lipidmaps+'\";\\n\\tdc:source\\t\"LIPID MAPS\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "for hmdb in listofhmdb:\n",
    "    g.write(hmdb + '\\ta\\tcheminf:000408 ;\\n\\tcheminf:000408\\t\"'+hmdb[5:]+'\";\\n\\tdc:identifier\\t\"'+hmdb+'\";\\n\\tdc:source\\t\"HMDB\".\\n\\n')\n",
    "    n += 1\n",
    "print(n)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing mapped Gene identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for hgnc in hgnclist:\n",
    "    g.write(hgnc + '\\ta\\tedam:data_2298, edam:data_1025 ;\\n\\tedam:data_2298\\t\"'+hgnc[5:]+'\";\\n\\tdc:identifier\\t\"'+hgnc+'\";\\n\\tdc:source\\t\"HGNC\".\\n\\n')\n",
    "\n",
    "for entrez in ncbigenelist:\n",
    "    g.write(entrez + '\\ta\\tedam:data_1027, edam:data_1025 ;\\n\\tedam:data_1027\\t\"'+entrez[9:]+'\";\\n\\tdc:identifier\\t\"'+entrez+'\";\\n\\tdc:source\\t\"Entrez Gene\".\\n\\n')\n",
    "\n",
    "for uniprot in uniprotlist:\n",
    "    g.write(uniprot + '\\ta\\tedam:data_2291, edam:data_1025 ;\\n\\trdfs:seeAlso <http://purl.uniprot.org/uniprot/' + uniprot[8:] + '>;\\n\\towl:sameAs <http://purl.uniprot.org/uniprot/' + uniprot[8:] + '>;\\n\\tedam:data_2291\\t\"'+uniprot[8:]+'\";\\n\\tdc:identifier\\t\"'+uniprot+'\";\\n\\tdc:source\\t\"UniProt\".\\n\\n')\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://rdfs.org/ns/void#Dataset&gt;</td>\n",
       "      <td>Dataset</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://edamontology.org/data_1027&gt;</td>\n",
       "      <td>Gene ID (NCBI)</td>\n",
       "      <td>An NCBI unique identifier of a gene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://edamontology.org/data_1025&gt;</td>\n",
       "      <td>Gene identifier</td>\n",
       "      <td>An identifier of a gene, such as a name/symbol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://edamontology.org/data_2298&gt;</td>\n",
       "      <td>Gene ID (HGNC)</td>\n",
       "      <td>Identifier for a gene approved by the HUGO Gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://purl.org/obo/owl/GO#0008150&gt;</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>A biological process represents a specific obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#CellTypeContext&gt;</td>\n",
       "      <td>Cell-term</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#OrganContext&gt;</td>\n",
       "      <td>Organ-term</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>ChEBI identifier</td>\n",
       "      <td>Database identifier used by ChEBI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>ChEMBL identifier</td>\n",
       "      <td>Identifier used by the ChEMBL database for com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>ChemSpider identifier</td>\n",
       "      <td>Database identifier used by ChemSpider.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>DrugBank identifier</td>\n",
       "      <td>Database identifier used by DrugBank.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>HMDB identifier</td>\n",
       "      <td>Database identifier used by Human Metabolome D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>KEGG identifier</td>\n",
       "      <td>Database identifier used by KEGG.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>LipidMaps identifier</td>\n",
       "      <td>Identifier used by the LipidMaps database, htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>PubChem compound identifier (CID)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>Wikidata identifier</td>\n",
       "      <td>Database identifier used by Wikidata.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;http://rdfs.org/ns/void#Linkset&gt;</td>\n",
       "      <td>Linkset</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#KeyEvent&gt;</td>\n",
       "      <td>Key Event</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#KeyEventRelatio...</td>\n",
       "      <td>Key Event Relationship</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;http://edamontology.org/data_1033&gt;</td>\n",
       "      <td>Ensembl gene ID</td>\n",
       "      <td>Unique identifier for a gene (or other feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...</td>\n",
       "      <td>Stressor</td>\n",
       "      <td>An agent, stimulus, activity, or event that ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;http://aopkb.org/aop_ontology#AdverseOutcomeP...</td>\n",
       "      <td>Adverse Outcome Pathway</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>chemical entity</td>\n",
       "      <td>A chemical entity is any molecular entity or c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;http://semanticscience.org/resource/CHEMINF_0...</td>\n",
       "      <td>CAS registry number</td>\n",
       "      <td>Identifier used by the Chemical Abstracts Serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;http://edamontology.org/data_2291&gt;</td>\n",
       "      <td>UniProt ID</td>\n",
       "      <td>An identifier of a polypeptide in the UniProt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;http://purl.bioontology.org/ontology/NCBITAXO...</td>\n",
       "      <td>cellular organisms</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;http://purl.obolibrary.org/obo/PATO_0001241&gt;</td>\n",
       "      <td>physical object quality</td>\n",
       "      <td>A quality which inheres in a continuant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URI  \\\n",
       "0                   <http://rdfs.org/ns/void#Dataset>   \n",
       "1                 <http://edamontology.org/data_1027>   \n",
       "2                 <http://edamontology.org/data_1025>   \n",
       "3                 <http://edamontology.org/data_2298>   \n",
       "4                <http://purl.org/obo/owl/GO#0008150>   \n",
       "5     <http://aopkb.org/aop_ontology#CellTypeContext>   \n",
       "6        <http://aopkb.org/aop_ontology#OrganContext>   \n",
       "7   <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "8   <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "9   <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "10  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "11  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "12  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "13  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "14  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "15  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "16                  <http://rdfs.org/ns/void#Linkset>   \n",
       "17           <http://aopkb.org/aop_ontology#KeyEvent>   \n",
       "18  <http://aopkb.org/aop_ontology#KeyEventRelatio...   \n",
       "19                <http://edamontology.org/data_1033>   \n",
       "20  <http://ncicb.nci.nih.gov/xml/owl/EVS/Thesauru...   \n",
       "21  <http://aopkb.org/aop_ontology#AdverseOutcomeP...   \n",
       "22  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "23  <http://semanticscience.org/resource/CHEMINF_0...   \n",
       "24                <http://edamontology.org/data_2291>   \n",
       "25  <http://purl.bioontology.org/ontology/NCBITAXO...   \n",
       "26      <http://purl.obolibrary.org/obo/PATO_0001241>   \n",
       "\n",
       "                                label  \\\n",
       "0                             Dataset   \n",
       "1                      Gene ID (NCBI)   \n",
       "2                     Gene identifier   \n",
       "3                      Gene ID (HGNC)   \n",
       "4                  biological_process   \n",
       "5                           Cell-term   \n",
       "6                          Organ-term   \n",
       "7                    ChEBI identifier   \n",
       "8                   ChEMBL identifier   \n",
       "9               ChemSpider identifier   \n",
       "10                DrugBank identifier   \n",
       "11                    HMDB identifier   \n",
       "12                    KEGG identifier   \n",
       "13               LipidMaps identifier   \n",
       "14  PubChem compound identifier (CID)   \n",
       "15                Wikidata identifier   \n",
       "16                            Linkset   \n",
       "17                          Key Event   \n",
       "18             Key Event Relationship   \n",
       "19                    Ensembl gene ID   \n",
       "20                           Stressor   \n",
       "21            Adverse Outcome Pathway   \n",
       "22                    chemical entity   \n",
       "23                CAS registry number   \n",
       "24                         UniProt ID   \n",
       "25                 cellular organisms   \n",
       "26            physical object quality   \n",
       "\n",
       "                                          description  \n",
       "0                                                   -  \n",
       "1                An NCBI unique identifier of a gene.  \n",
       "2   An identifier of a gene, such as a name/symbol...  \n",
       "3   Identifier for a gene approved by the HUGO Gen...  \n",
       "4   A biological process represents a specific obj...  \n",
       "5                                                   -  \n",
       "6                                                   -  \n",
       "7                  Database identifier used by ChEBI.  \n",
       "8   Identifier used by the ChEMBL database for com...  \n",
       "9             Database identifier used by ChemSpider.  \n",
       "10              Database identifier used by DrugBank.  \n",
       "11  Database identifier used by Human Metabolome D...  \n",
       "12                  Database identifier used by KEGG.  \n",
       "13  Identifier used by the LipidMaps database, htt...  \n",
       "14                                                  -  \n",
       "15              Database identifier used by Wikidata.  \n",
       "16                                                  -  \n",
       "17                                                  -  \n",
       "18                                                  -  \n",
       "19  Unique identifier for a gene (or other feature...  \n",
       "20  An agent, stimulus, activity, or event that ca...  \n",
       "21                                                  -  \n",
       "22  A chemical entity is any molecular entity or c...  \n",
       "23  Identifier used by the Chemical Abstracts Serv...  \n",
       "24  An identifier of a polypeptide in the UniProt ...  \n",
       "25                                                  -  \n",
       "26            A quality which inheres in a continuant  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(filepath + 'typelabels.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row,index in df.iterrows():\n",
    "    g.write('\\n\\n'+index['URI']+'\\trdfs:label\\t\"'+index['label'])\n",
    "    if index['description'] != '-':\n",
    "        g.write('\";\\n\\tdc:description\\t\"\"\"'+index['description']+'\"\"\".')\n",
    "    else:\n",
    "        g.write('\".')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AOP-Wiki RDF file is created!\n"
     ]
    }
   ],
   "source": [
    "g.close()\n",
    "print(\"The AOP-Wiki RDF file is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #5: Gene ID text-mapping (HGNC)</b>\n",
    "In order to identify genes present in the textual descriptions of Key Events (KEs) and Key Event Relationships (KERs), HGNC identifier mapping was performed. [Genenames.org](https://www.genenames.org/) is the curated online repository for HGNC nomenclature, and it allows custom downloads for all HGNC entries, including approved symbols and names, previous symbols and synonyms. \n",
    "\n",
    "## Step #5A - Parsing the custom HGNC file\n",
    "This starts with loading the custom download file, which was named `HGNCgenes.txt` and stored in the path defined in Step #2. Next, its contents are extracted and stored in a dictionary called `genedict1`, while variants are created for every gene name and gene symbol for more effective mapping of genes. These variants are stored in `genedict2`, which is used for more effective mapping of genes in Step #5B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNCfilename = 'HGNCgenes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Modified Time :  Tue Aug 20 08:51:09 2024\n"
     ]
    }
   ],
   "source": [
    "fileStatsObj = os.stat (filepath + HGNCfilename)\n",
    "HGNCmodificationTime = time.ctime ( fileStatsObj [ stat.ST_MTIME ] )\n",
    "print(\"Last Modified Time : \", HGNCmodificationTime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 41893 genes are included for mappings\n"
     ]
    }
   ],
   "source": [
    "HGNCgenes = open(filepath + HGNCfilename, 'r')\n",
    "symbols = [' ','(',')','[',']',',','.']\n",
    "genedict1 = {}\n",
    "genedict2 = {}\n",
    "b = 0\n",
    "for line in HGNCgenes:\n",
    "    if not 'HGNC ID\tApproved symbol\tApproved name\tPrevious symbols\tSynonyms\tAccession numbers\tEnsembl ID(supplied by Ensembl)'in line:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if not '@' in a[1]: #gene clusters contain a '@' in their symbol, which are filtered out\n",
    "            genedict1[a[1]] = []\n",
    "            genedict2[a[1]] = []\n",
    "            genedict1[a[1]].append(a[1])\n",
    "            if not a[2] == '':\n",
    "                genedict1[a[1]].append(a[2])\n",
    "            for item in a[3:]:\n",
    "                if not item == '':\n",
    "                    for name in item.split(', '):\n",
    "                        genedict1[a[1]].append(name)\n",
    "            for item in genedict1[a[1]]:\n",
    "                for s1 in symbols:\n",
    "                    for s2 in symbols:\n",
    "                        genedict2[a[1]].append((s1+item+s2))\n",
    "HGNCgenes.close()\n",
    "print(\"A total of \" + str(len(genedict2)) + \" genes are included for mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5B - HGNC identifier mapping\n",
    "Genes are mapped for descriptions of KEs and KERs, and for the biological plausibility and emperical support sections of KERs. First, these are screened for any overlap with all possible gene symbols and names captured in genedict1. Then, all positive matches are checked by mapping with all variants of those genes, ensuring the correct mapping. All matches are stored in the kedict and kerdict dictionaries. Also, all mapped genes are stored in a list called hgnclist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene mapping on Key Events is can take a minute...\n",
      "Done!\n",
      "In total, 943 genes were mapped to descriptions of Key Events\n"
     ]
    }
   ],
   "source": [
    "hgnclist = []\n",
    "keyhitcount = {}\n",
    "print(\"Gene mapping on Key Events is can take a minute...\")\n",
    "for ke in root.findall(aopxml + 'key-event'):\n",
    "    geneoverlapdict = {}\n",
    "    if ke.find(aopxml + 'description').text is not None:\n",
    "        geneoverlapdict[ke.get('id')] = []\n",
    "        for key in genedict2:\n",
    "            a = 0\n",
    "            for item in genedict1[key]:\n",
    "                if item in kedict[ke.get('id')]['dc:description']:\n",
    "                    a = 1\n",
    "            if a == 1:\n",
    "                for item in genedict2[key]:\n",
    "                    if item in kedict[ke.get('id')]['dc:description'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ke.get('id')]:\n",
    "                        geneoverlapdict[ke.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                        if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                            hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                        if item in keyhitcount:\n",
    "                            keyhitcount[item] += 1\n",
    "                        else:\n",
    "                            keyhitcount[item] = 1\n",
    "                            \n",
    "        if not geneoverlapdict[ke.get('id')]:\n",
    "            del geneoverlapdict[ke.get('id')]\n",
    "    if ke.get('id') in geneoverlapdict:\n",
    "        kedict[ke.get('id')]['edam:data_1025'] = geneoverlapdict[ke.get('id')]\n",
    "print(\"Done!\\nIn total, \" + str(len(hgnclist))+ \" genes were mapped to descriptions of Key Events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROS : 12 hits\n",
      " II : 41 hits\n",
      " B : 37 hits\n",
      "(ALP): 24 hits\n",
      "(ROS): 14 hits\n",
      " T3 : 11 hits\n",
      " TH : 18 hits\n",
      " G2 : 15 hits\n",
      " T : 35 hits\n",
      " AR : 12 hits\n",
      " E2 : 30 hits\n"
     ]
    }
   ],
   "source": [
    "for gene, count in keyhitcount.items():\n",
    "    if count > 10:\n",
    "        print(f\"{gene}: {count} hits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Event Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene mapping on Key Events is can take a couple of minutes...\n",
      "Done!\n",
      "In total, 1549 genes were mapped to descriptions of Key Events and Key Event Relationships\n"
     ]
    }
   ],
   "source": [
    "print(\"Gene mapping on Key Events is can take a couple of minutes...\")\n",
    "for ker in root.findall(aopxml + 'key-event-relationship'):\n",
    "    geneoverlapdict = {}\n",
    "    geneoverlapdict[ker.get('id')] = []\n",
    "    if ker.find(aopxml + 'description').text is not None:\n",
    "        for key in genedict2:\n",
    "            a = 0\n",
    "            for item in genedict1[key]:\n",
    "                if item in kerdict[ker.get('id')]['dc:description']:\n",
    "                    a = 1\n",
    "            if a == 1:\n",
    "                for item in genedict2[key]:\n",
    "                    if item in kerdict[ker.get('id')]['dc:description'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ker.get('id')]:\n",
    "                        geneoverlapdict[ker.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                        if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                            hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "    for weight in ker.findall(aopxml + 'weight-of-evidence'):\n",
    "        if weight.find(aopxml + 'biological-plausibility').text is not None:\n",
    "            for key in genedict2:\n",
    "                a = 0\n",
    "                for item in genedict1[key]:\n",
    "                    if item in kerdict[ker.get('id')]['nci:C80263']:\n",
    "                        a = 1\n",
    "                if a== 1:\n",
    "                    for item in genedict2[key]:\n",
    "                        if item in kerdict[ker.get('id')]['nci:C80263'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ker.get('id')]:\n",
    "                            geneoverlapdict[ker.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                            if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                                hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "        if weight.find(aopxml + 'emperical-support-linkage').text is not None:\n",
    "            for key in genedict2:\n",
    "                a = 0\n",
    "                for item in genedict1[key]:\n",
    "                    if item in kerdict[ker.get('id')]['edam:data_2042']:\n",
    "                        a = 1\n",
    "                if a== 1:\n",
    "                    for item in genedict2[key]:\n",
    "                        if item in kerdict[ker.get('id')]['edam:data_2042'] and not 'hgnc:' + genedict2[key][1][1:-1] in geneoverlapdict[ker.get('id')]:\n",
    "                            geneoverlapdict[ker.get('id')].append('hgnc:' + genedict2[key][1][1:-1])\n",
    "                            if 'hgnc:' + genedict2[key][1][1:-1] not in hgnclist:\n",
    "                                hgnclist.append('hgnc:' + genedict2[key][1][1:-1])\n",
    "    if not geneoverlapdict[ker.get('id')]:\n",
    "        del geneoverlapdict[ker.get('id')]\n",
    "    if ker.get('id') in geneoverlapdict:\n",
    "        kerdict[ker.get('id')]['edam:data_1025'] = geneoverlapdict[ker.get('id')]\n",
    "print(\"Done!\\nIn total, \" + str(len(hgnclist))+ \" genes were mapped to descriptions of Key Events and Key Event Relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5C - Identifier mapping for other databases\n",
    "BridgeDb was used to additional identifiers from other databases, including Entrez gene, Ensembl, and UniProt IDs. By a request call, identifiers are returned, which are stored in the dictionary called `geneiddict`. The BridgeDb service URL has already been defined in Step #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene identifiers mapped:\n",
      "1523 Entrez gene IDs\n",
      "7599 Uniprot IDs\n",
      "1521 Ensembl IDs\n"
     ]
    }
   ],
   "source": [
    "geneiddict = {}\n",
    "listofentrez = []\n",
    "listofensembl = []\n",
    "listofuniprot = []\n",
    "\n",
    "for gene in hgnclist:\n",
    "    a = requests.get(bridgedb + 'xrefs/H/' + gene[5:]).text.split('\\n')\n",
    "    dictionaryforgene = {}\n",
    "    if 'html' not in a:\n",
    "        for item in a:\n",
    "            b = item.split('\\t')\n",
    "            if len(b) == 2:\n",
    "                if b[1] not in dictionaryforgene:\n",
    "                    dictionaryforgene[b[1]] = []\n",
    "                    dictionaryforgene[b[1]].append(b[0])\n",
    "                else:\n",
    "                    dictionaryforgene[b[1]].append(b[0])\n",
    "    geneiddict[gene] = []\n",
    "    if 'Entrez Gene' in dictionaryforgene:\n",
    "        for entrez in dictionaryforgene['Entrez Gene']:\n",
    "            if 'ncbigene:'+entrez not in listofentrez:\n",
    "                listofentrez.append(\"ncbigene:\"+entrez)\n",
    "            geneiddict[gene].append(\"ncbigene:\"+entrez)\n",
    "    if 'Ensembl' in dictionaryforgene:\n",
    "        for ensembl in dictionaryforgene['Ensembl']:\n",
    "            if 'ensembl:' + ensembl not in listofensembl:\n",
    "                listofensembl.append(\"ensembl:\"+ensembl)\n",
    "            geneiddict[gene].append(\"ensembl:\"+ensembl)\n",
    "    if 'Uniprot-TrEMBL' in dictionaryforgene:\n",
    "        for uniprot in dictionaryforgene['Uniprot-TrEMBL']:\n",
    "            if 'uniprot:'+uniprot not in listofuniprot:\n",
    "                listofuniprot.append(\"uniprot:\"+uniprot)\n",
    "            geneiddict[gene].append(\"uniprot:\"+uniprot)\n",
    "print(\"Gene identifiers mapped:\\n\" + str(len(listofentrez)) + \" Entrez gene IDs\\n\" + str(len(listofuniprot)) + \" Uniprot IDs\\n\" + str(len(listofensembl)) + \" Ensembl IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5D - Writing output file\n",
    "The final step involves the writing of the RDF file in Turtle syntax. After writing the prefixes used for predicates and identifier types, all gene mapping links stored in the kedict and kerdict are written, followed by the HGNC IDs and matched IDs for other databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open(filepath + 'AOPWikiRDF-Genes.ttl', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.write('@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix aop.events: <https://identifiers.org/aop.events/> .\\n@prefix aop.relationships: <https://identifiers.org/aop.relationships/> .\\n@prefix skos: <http://www.w3.org/2004/02/skos/core#> . \\n@prefix ensembl: <https://identifiers.org/ensembl/> .\\n@prefix edam: <http://edamontology.org/> .\\n@prefix hgnc: <https://identifiers.org/hgnc/>.\\n@prefix ncbigene: <https://identifiers.org/ncbigene/>.\\n@prefix uniprot: <https://identifiers.org/uniprot/>.\\n@prefix owl: <http://www.w3.org/2002/07/owl#>.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event triples\n",
    "These triples only contain the mappings with genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Number of Key Events with genes mapped to their descriptions: 381\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for ke in kedict:\n",
    "    if 'edam:data_1025' in kedict[ke]:\n",
    "        n += 1\n",
    "        g.write(kedict[ke]['dc:identifier']+'\\tedam:data_1025\\t' + ','.join(kedict[ke]['edam:data_1025'])+' .\\n\\n')\n",
    "print(\"Done!\\n\\nNumber of Key Events with genes mapped to their descriptions: \" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Key Event Relationship triples\n",
    "These triples only contain the mappings with genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Number of Key Event Relationships with genes mapped to their descriptions: 591\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for ker in kerdict:\n",
    "    if 'edam:data_1025' in kerdict[ker]:\n",
    "        n += 1\n",
    "        g.write(kerdict[ker]['dc:identifier']+'\\tedam:data_1025\\t' + ','.join(kerdict[ker]['edam:data_1025'])+' .\\n\\n')\n",
    "print(\"Done!\\n\\nNumber of Key Event Relationships with genes mapped to their descriptions: \" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Gene identifier triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1549 HGNC triples written.\n",
      "1523 Entrez gene triples written.\n",
      "1521 Ensembl triples written.\n",
      "7599 UniProt triples written.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for hgnc in hgnclist:\n",
    "    g.write(hgnc + '\\ta\\tedam:data_2298, edam:data_1025 ;\\n\\tedam:data_2298\\t\"'+hgnc[5:]+'\";\\n\\tdc:identifier\\t\"'+hgnc+'\";\\n\\tdc:source\\t\"HGNC\"')\n",
    "    if not geneiddict[hgnc] == []:\n",
    "        g.write(' ;\\n\\tskos:exactMatch\\t'+','.join(geneiddict[hgnc]))\n",
    "    g.write('.\\n\\n')\n",
    "print(str(len(hgnclist))+\" HGNC triples written.\")\n",
    "for entrez in listofentrez:\n",
    "    g.write(entrez + '\\ta\\tedam:data_1027, edam:data_1025 ;\\n\\tedam:data_1027\\t\"'+entrez[9:]+'\";\\n\\tdc:identifier\\t\"'+entrez+'\";\\n\\tdc:source\\t\"Entrez Gene\".\\n\\n')\n",
    "print(str(len(listofentrez))+\" Entrez gene triples written.\")\n",
    "for ensembl in listofensembl:\n",
    "    g.write(ensembl + '\\ta\\tedam:data_1033, edam:data_1025 ;\\n\\tedam:data_1033\\t\"'+ensembl[8:]+'\";\\n\\tdc:identifier\\t\"'+ensembl+'\";\\n\\tdc:source\\t\"Ensembl\".\\n\\n')\n",
    "print(str(len(listofensembl))+ \" Ensembl triples written.\")\n",
    "for uniprot in listofuniprot:\n",
    "    g.write(uniprot + '\\ta\\tedam:data_2291, edam:data_1025 ;\\n\\tedam:data_2291\\t\"'+uniprot[8:]+'\";\\n\\tdc:identifier\\t\"'+uniprot+'\";\\n\\tdc:source\\t\"UniProt\".\\n\\n')\n",
    "print(str(len(listofuniprot))+ \" UniProt triples written.\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AOP-Wiki RDF Genes file is created!\n"
     ]
    }
   ],
   "source": [
    "g.close()\n",
    "print(\"The AOP-Wiki RDF Genes file is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step #6: Creating the VoID file</b>\n",
    "The last file contains the metadata of the original data, script, and tools used for the creation of the AOP-Wiki RDF files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of the BridgeDb mapping files: \n",
      " Gene/Proteins: Ensembl:108\n",
      " Chemicals: HMDB-CHEBI-WIKIDATA:HMDB5.0.20211102-CHEBI211-WIKIDATA20220707\n"
     ]
    }
   ],
   "source": [
    "a = requests.get(bridgedb + 'properties').text.split('\\n')\n",
    "info = {}\n",
    "for item in a:\n",
    "    if not item.split('\\t')[0] in info:\n",
    "        info[item.split('\\t')[0]] = []\n",
    "    if len(item.split('\\t')) == 2:\n",
    "        info[item.split('\\t')[0]].append(item.split('\\t')[1])\n",
    "print('The version of the BridgeDb mapping files: \\n Gene/Proteins: '\n",
    "      + str(info['DATASOURCENAME'][0]) + ':' + str(info['DATASOURCEVERSION'][0]) + '\\n Chemicals: '\n",
    "      + str(info['DATASOURCENAME'][5]) + ':' + str(info['DATASOURCEVERSION'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date: 2025-02-11 14:46:20.225426\n"
     ]
    }
   ],
   "source": [
    "x = datetime.datetime.now()\n",
    "print('The date: ' + str(x))\n",
    "y = str(x)\n",
    "y = y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VoID file is created!\n"
     ]
    }
   ],
   "source": [
    "g = open(filepath + 'AOPWikiRDF-Void.ttl', 'w', encoding='utf-8')\n",
    "g.write('@prefix : <https://aopwiki.rdf.bigcat-bioinformatics.org/> .\\n@prefix dc: <http://purl.org/dc/elements/1.1/> .\\n@prefix dcterms: <http://purl.org/dc/terms/> .\\n@prefix void:  <http://rdfs.org/ns/void#> .\\n@prefix pav:   <http://purl.org/pav/> .\\n@prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .\\n@prefix dcat:  <http://www.w3.org/ns/dcat#> .\\n@prefix foaf:  <http://xmlns.com/foaf/0.1/> .\\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n@prefix freq:  <http://purl.org/cld/freq/> .')\n",
    "g.write('\\n:AOPWikiRDF.ttl\\ta\\tvoid:Dataset ;\\n\\tdc:description\\t\"AOP-Wiki RDF data from the AOP-Wiki database\" ;\\n\\tpav:createdOn\\t\"' + y + '\"^^xsd:date;\\n\\tdcterms:modified\\t\"' + y +'\"^^xsd:date ;\\n\\tpav:createdWith\\t\"' + str(aopwikixmlfilename) + '\", :Promapping ;\\n\\tpav:createdBy\\t<https://zenodo.org/badge/latestdoi/146466058> ;\\n\\tfoaf:homepage\\t<https://aopwiki.org> ;\\n\\tdcterms:accuralPeriodicity  freq:quarterly ;\\n\\tdcat:downloadURL\\t<https://aopwiki.org/downloads/' + str(aopwikixmlfilename) + '> .\\n\\n:AOPWikiRDF-Genes.ttl\\ta\\tvoid:Dataset ;\\n\\tdc:description\\t\"AOP-Wiki RDF extension with gene mappings based on approved names and symbols\" ;\\n\\tpav:createdOn\\t\"' + str(x) + '\" ;\\n\\tpav:createdWith\\t\"' + str(aopwikixmlfilename) + '\", :HGNCgenes ;\\n\\tpav:createdBy\\t<https://zenodo.org/badge/latestdoi/146466058> ;\\n\\tdcterms:accuralPeriodicity  freq:quarterly ;\\n\\tfoaf:homepage\\t<https://aopwiki.org> ;\\n\\tdcat:downloadURL\\t<https://aopwiki.org/downloads/' + str(aopwikixmlfilename) + '>, <https://www.genenames.org/download/custom/> . \\n\\n:HGNCgenes.txt\\ta\\tvoid:Dataset, void:Linkset ;\\n\\tdc:description\\t\"HGNC approved symbols and names for genes\" ;\\n\\tdcat:downloadURL\\t<https://www.genenames.org/download/custom/> ;\\n\\tpav:importedOn\\t\"'+HGNCmodificationTime+'\" .\\n\\n<https://proconsortium.org/download/current/promapping.txt>\\ta\\tvoid:Dataset, void:Linkset;\\n\\tdc:description\\t\"PRotein ontology mappings to protein database identifiers\";\\n\\tdcat:downloadURL\\t<https://proconsortium.org/download/current/promapping.txt>;\\n\\tpav:importedOn\\t\"'+PromodificationTime+'\".')\n",
    "g.close()\n",
    "print(\"The VoID file is created!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
